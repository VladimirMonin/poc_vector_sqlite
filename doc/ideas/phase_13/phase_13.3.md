# üêõ Phase 13.3 ‚Äî –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä—è–º–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤

**–°—Ç–∞—Ç—É—Å:** üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ë–ê–ì  
**–û–±–Ω–∞—Ä—É–∂–µ–Ω:** 2025-12-05 –≤ —Ö–æ–¥–µ Phase 13.2 (Human-First Testing)  
**–í–ª–∏—è–Ω–∏–µ:** –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ª–æ–º–∞–Ω–∞

---

## 1. –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã

### 1.1 –°–∏–º–ø—Ç–æ–º—ã

–ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ CLI:

```bash
semantic ingest photo.jpg -e       # enrich_media=True
semantic ingest audio.ogg -e
semantic ingest video.mp4 -e
```

**–û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:**

- Vision/Audio/Video API –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è
- –í –ë–î —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ/—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
- –ü–æ–∏—Å–∫ –Ω–∞—Ö–æ–¥–∏—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –º–µ–¥–∏–∞

**–§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:**

- API –ù–ï –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è
- –í –ë–î —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ü–£–¢–¨ –∫ —Ñ–∞–π–ª—É –∫–∞–∫ —Ç–µ–∫—Å—Ç
- –ü–æ–∏—Å–∫ –Ω–∞—Ö–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ –ø—É—Ç—å, –∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ

### 1.2 –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –∏–∑ –ë–î

```
=== STATS ===
Document media types:    Chunk types:
   audio: 3              code: 13
   image: 9              text: 29  ‚Üê –í–°–Å –ú–ï–î–ò–ê = TEXT!
   video: 2              
                         image_ref: 0  ‚Üê –ù–û–õ–¨!
                         audio_ref: 0
                         video_ref: 0
```

–ü—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤:

```
Chunk 10 (doc=6): chunk_type=text, doc_media_type=video
   Content: C:\PY\poc_vector_sqlite\tests\asests\module_init_demo.mp4  ‚Üê –ü–£–¢–¨!

Chunk 11 (doc=7): chunk_type=text, doc_media_type=audio
   Content: C:\PY\poc_vector_sqlite\tests\asests\module_init_demo.ogg  ‚Üê –ü–£–¢–¨!
```

---

## 2. –ö–æ—Ä–Ω–µ–≤–∞—è –ø—Ä–∏—á–∏–Ω–∞

### 2.1 –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ `.jpg` –Ω–∞–ø—Ä—è–º—É—é

```
1. CLI: _create_document(path)
   ‚îú‚îÄ media_type = MediaType.IMAGE  ‚úì –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ
   ‚îî‚îÄ content = str(path.absolute())  ‚Üê "C:\...\photo.jpg"

2. SemanticCore.ingest(document, enrich_media=True)
   ‚îî‚îÄ SmartSplitter.split(document)
      ‚îî‚îÄ MarkdownNodeParser.parse("C:\...\photo.jpg")  
         ‚îî‚îÄ –í–∏–¥–∏—Ç –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç ‚Üí segment_type = TEXT

3. _enrich_media_chunks(chunks):
   for chunk in chunks:
       if chunk.chunk_type not in MEDIA_CHUNK_TYPES:
           continue  ‚Üê –ü–†–û–ü–£–°–ö–ê–ï–¢! TEXT ‚â† IMAGE_REF

4. –†–µ–∑—É–ª—å—Ç–∞—Ç: chunk.content = –ø—É—Ç—å, —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ –ø—É—Ç–∏
```

### 2.2 –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –ø—Ä–æ–±–ª–µ–º–æ–π

| –§–∞–π–ª | –°—Ç—Ä–æ–∫–∏ | –ü—Ä–æ–±–ª–µ–º–∞ |
|------|--------|----------|
| `semantic_core/cli/commands/ingest.py` | 61-68 | `content = str(path.absolute())` –¥–ª—è –º–µ–¥–∏–∞ |
| `semantic_core/processing/parsers/markdown_parser.py` | ‚Äî | –ü–∞—Ä—Å–∏—Ç –ø—É—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç |
| `semantic_core/processing/splitters/smart_splitter.py` | 100-125 | –¢–æ–ª—å–∫–æ `MEDIA_CHUNK_TYPES` –∏–∑–æ–ª–∏—Ä—É—é—Ç—Å—è |
| `semantic_core/pipeline.py` | 520-527 | `if chunk.chunk_type not in MEDIA_CHUNK_TYPES: continue` |

### 2.3 –ö–æ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç (markdown —Å–æ —Å—Å—ã–ª–∫–∞–º–∏)

```markdown
# –ú–æ—è —Å—Ç–∞—Ç—å—è
![–û–ø–∏—Å–∞–Ω–∏–µ](images/photo.jpg)   ‚Üê MarkdownNodeParser –≤–∏–¥–∏—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—Å!
```

1. –ü–∞—Ä—Å–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç `![](...)` ‚Üí `segment_type = IMAGE_REF`
2. –°–ø–ª–∏—Ç—Ç–µ—Ä —Å–æ–∑–¥–∞—ë—Ç `chunk_type = IMAGE_REF`
3. `_enrich_media_chunks()` –Ω–∞—Ö–æ–¥–∏—Ç —á–∞–Ω–∫
4. Vision API –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è
5. **–†–ê–ë–û–¢–ê–ï–¢!**

---

## 3. –í–∞—Ä–∏–∞–Ω—Ç—ã —Ä–µ—à–µ–Ω–∏—è

### 3.1 –í–∞—Ä–∏–∞–Ω—Ç A: –ü—Ä–æ–≤–µ—Ä–∫–∞ media_type –î–û —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞ (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

**–ò–¥–µ—è:** –ï—Å–ª–∏ `document.media_type` –Ω–µ TEXT, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é –±–µ–∑ –ø–∞—Ä—Å–µ—Ä–∞.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ `pipeline.py`:**

```python
def ingest(self, document: Document, ...):
    # NEW: –ü—Ä—è–º–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞-–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    if document.media_type in (MediaType.IMAGE, MediaType.AUDIO, MediaType.VIDEO):
        return self._ingest_direct_media(document, mode, enrich_media)
    
    # –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è TEXT
    chunks = self.splitter.split(document)
    ...
```

**–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ `_ingest_direct_media()`:**

```python
def _ingest_direct_media(self, document: Document, mode, enrich_media):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–µ–¥–∏–∞-—Ñ–∞–π–ª—ã –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ –ø–∞—Ä—Å–µ—Ä–∞)."""
    media_path = Path(document.content)  # content = –ø—É—Ç—å
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º chunk_type –ø–æ media_type
    chunk_type_map = {
        MediaType.IMAGE: ChunkType.IMAGE_REF,
        MediaType.AUDIO: ChunkType.AUDIO_REF,
        MediaType.VIDEO: ChunkType.VIDEO_REF,
    }
    chunk_type = chunk_type_map[document.media_type]
    
    # –ï—Å–ª–∏ enrich_media ‚Äî –≤—ã–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ä–∞–∑—É
    content = str(media_path)
    if enrich_media:
        result = self._analyze_media_for_chunk(chunk_type, media_path, "")
        if result:
            content = self._build_content_from_result(result)
    
    # –°–æ–∑–¥–∞—ë–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —á–∞–Ω–∫
    chunk = Chunk(
        content=content,
        chunk_index=0,
        chunk_type=chunk_type,
        metadata={"_original_path": str(media_path)},
    )
    
    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    ...
```

**–ü–ª—é—Å—ã:**

- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
- –ù–µ –ª–æ–º–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É markdown
- –ß–∏—Å—Ç—ã–π —Ä–æ—É—Ç–∏–Ω–≥ –ø–æ —Ç–∏–ø—É

**–ú–∏–Ω—É—Å—ã:**

- –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

### 3.2 –í–∞—Ä–∏–∞–Ω—Ç B: –°–æ–∑–¥–∞–Ω–∏–µ MediaSplitter

**–ò–¥–µ—è:** –ù–æ–≤—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä –¥–ª—è –º–µ–¥–∏–∞, –∫–æ—Ç–æ—Ä—ã–π —Å—Ä–∞–∑—É —Å–æ–∑–¥–∞—ë—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π chunk_type.

```python
class MediaSplitter(BaseSplitter):
    """–°–ø–ª–∏—Ç—Ç–µ—Ä –¥–ª—è –ø—Ä—è–º—ã—Ö –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤."""
    
    def split(self, document: Document) -> list[Chunk]:
        chunk_type = self._media_type_to_chunk_type(document.media_type)
        return [Chunk(
            content=document.content,  # –ü—É—Ç—å
            chunk_type=chunk_type,     # IMAGE_REF/AUDIO_REF/VIDEO_REF
            ...
        )]
```

**CLI –≤—ã–±–∏—Ä–∞–µ—Ç —Å–ø–ª–∏—Ç—Ç–µ—Ä –ø–æ media_type.**

**–ü–ª—é—Å—ã:**

- SOLID: –æ–¥–∏–Ω —Å–ø–ª–∏—Ç—Ç–µ—Ä ‚Äî –æ–¥–Ω–∞ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å
- –õ–µ–≥–∫–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å

**–ú–∏–Ω—É—Å—ã:**

- –ë–æ–ª—å—à–µ –∫–ª–∞—Å—Å–æ–≤
- CLI –¥–æ–ª–∂–µ–Ω –∑–Ω–∞—Ç—å –æ —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞—Ö

### 3.3 –í–∞—Ä–∏–∞–Ω—Ç C: –§–∏–∫—Å –≤ SmartSplitter

**–ò–¥–µ—è:** SmartSplitter –ø—Ä–æ–≤–µ—Ä—è–µ—Ç `document.media_type` –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º.

```python
def split(self, document: Document) -> list[Chunk]:
    # NEW: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç ‚Äî –º–µ–¥–∏–∞, –Ω–µ –ø–∞—Ä—Å–∏–º
    if document.media_type in (MediaType.IMAGE, MediaType.AUDIO, MediaType.VIDEO):
        return self._split_media_document(document)
    
    # –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
    segments = list(self.parser.parse(document.content))
    ...
```

**–ü–ª—é—Å—ã:**

- –û–¥–Ω–æ –º–µ—Å—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
- –°–ø–ª–∏—Ç—Ç–µ—Ä —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —É–º–Ω–µ–µ

**–ú–∏–Ω—É—Å—ã:**

- –°–º–µ—à–∏–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ (—Ç–µ–∫—Å—Ç + –º–µ–¥–∏–∞)
- SmartSplitter –∑–Ω–∞–µ—Ç –æ MediaType

---

## 4. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ: –í–∞—Ä–∏–∞–Ω—Ç A

### 4.1 –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

1. **`pipeline.py`**: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É `document.media_type` –≤ –Ω–∞—á–∞–ª–µ `ingest()`
2. **`pipeline.py`**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `_ingest_direct_media()`
3. **`pipeline.py`**: –î–æ–±–∞–≤–∏—Ç—å `_build_content_from_result()` –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
4. **–¢–µ—Å—Ç—ã**: –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç—ã –ø—Ä—è–º–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –≤ `tests/integration/`

### 4.2 –î–µ—Ç–∞–ª—å–Ω–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è `_ingest_direct_media()`

```python
def _ingest_direct_media(
    self,
    document: Document,
    mode: IngestionMode,
    enrich_media: bool,
) -> Document:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–µ–¥–∏–∞-—Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ –ø–∞—Ä—Å–µ—Ä–∞/—Å–ø–ª–∏—Ç—Ç–µ—Ä–∞).
    
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ document.media_type != TEXT.
    
    Args:
        document: –î–æ–∫—É–º–µ–Ω—Ç —Å content=–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É
        mode: sync –∏–ª–∏ async
        enrich_media: –í—ã–∑—ã–≤–∞—Ç—å –ª–∏ Vision/Audio/Video API
        
    Returns:
        –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π Document —Å ID
    """
    media_path = Path(document.content)
    
    # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º chunk_type
    chunk_type_map = {
        MediaType.IMAGE: ChunkType.IMAGE_REF,
        MediaType.AUDIO: ChunkType.AUDIO_REF,
        MediaType.VIDEO: ChunkType.VIDEO_REF,
    }
    chunk_type = chunk_type_map[document.media_type]
    
    # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —á–∞–Ω–∫–∞
    if enrich_media and mode == "sync":
        # –í—ã–∑—ã–≤–∞–µ–º API
        result = self._analyze_media_for_chunk(chunk_type, media_path, context_text="")
        if result:
            content = self._build_content_from_result(result)
            metadata = self._build_metadata_from_result(result, media_path)
        else:
            content = str(media_path)
            metadata = {"_original_path": str(media_path), "_media_error": "Analysis failed"}
    else:
        content = str(media_path)
        metadata = {"_original_path": str(media_path)}
    
    # 3. –°–æ–∑–¥–∞—ë–º —á–∞–Ω–∫
    chunk = Chunk(
        content=content,
        chunk_index=0,
        chunk_type=chunk_type,
        metadata=metadata,
    )
    
    # 4. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (–µ—Å–ª–∏ sync)
    if mode == "sync":
        vector_text = self.context_strategy.form_vector_text(chunk, document)
        embedding = self.embedder.embed_documents([vector_text])[0]
        chunk.embedding = embedding
    else:
        chunk.metadata["_vector_source"] = content
        chunk.metadata["_embedding_status"] = EmbeddingStatus.PENDING.value
    
    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º
    return self.store.save(document, [chunk])
```

### 4.3 –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã

```python
def _build_content_from_result(self, result: dict) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞."""
    media_type = result.get("type")
    
    if media_type == "image":
        return result.get("description", "")
    elif media_type == "audio":
        return result.get("transcription") or result.get("description", "")
    elif media_type == "video":
        # –î–ª—è –≤–∏–¥–µ–æ: –æ–ø–∏—Å–∞–Ω–∏–µ + —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
        parts = []
        if result.get("description"):
            parts.append(result["description"])
        if result.get("transcription"):
            parts.append(f"\n\nTranscription:\n{result['transcription']}")
        return "".join(parts)
    return ""

def _build_metadata_from_result(self, result: dict, media_path: Path) -> dict:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç metadata –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞."""
    metadata = {"_original_path": str(media_path)}
    media_type = result.get("type")
    
    if media_type == "image":
        metadata["_vision_alt"] = result.get("alt_text", "")
        metadata["_vision_keywords"] = result.get("keywords", [])
        if result.get("ocr_text"):
            metadata["_vision_ocr"] = result["ocr_text"]
            
    elif media_type == "audio":
        metadata["_audio_description"] = result.get("description", "")
        metadata["_audio_keywords"] = result.get("keywords", [])
        metadata["_audio_participants"] = result.get("participants", [])
        if result.get("duration_seconds"):
            metadata["_audio_duration"] = result["duration_seconds"]
            
    elif media_type == "video":
        metadata["_video_keywords"] = result.get("keywords", [])
        if result.get("transcription"):
            metadata["_video_transcription"] = result["transcription"]
        if result.get("ocr_text"):
            metadata["_video_ocr"] = result["ocr_text"]
        if result.get("duration_seconds"):
            metadata["_video_duration"] = result["duration_seconds"]
    
    return metadata
```

---

## 5. –¢–µ—Å—Ç-–∫–µ–π—Å—ã

### 5.1 Unit-—Ç–µ—Å—Ç—ã

```python
class TestDirectMediaIngestion:
    """–¢–µ—Å—Ç—ã –ø—Ä—è–º–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ–¥–∏–∞."""
    
    def test_image_creates_image_ref_chunk(self, core):
        """–ó–∞–≥—Ä—É–∑–∫–∞ .jpg —Å–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫ IMAGE_REF."""
        doc = Document(content="path/to/image.jpg", media_type=MediaType.IMAGE)
        result = core.ingest(doc, enrich_media=False)
        
        chunks = core.store.get_chunks(result.id)
        assert len(chunks) == 1
        assert chunks[0].chunk_type == ChunkType.IMAGE_REF
    
    def test_audio_creates_audio_ref_chunk(self, core):
        """–ó–∞–≥—Ä—É–∑–∫–∞ .ogg —Å–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫ AUDIO_REF."""
        doc = Document(content="path/to/audio.ogg", media_type=MediaType.AUDIO)
        result = core.ingest(doc, enrich_media=False)
        
        chunks = core.store.get_chunks(result.id)
        assert chunks[0].chunk_type == ChunkType.AUDIO_REF
    
    def test_video_creates_video_ref_chunk(self, core):
        """–ó–∞–≥—Ä—É–∑–∫–∞ .mp4 —Å–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫ VIDEO_REF."""
        ...
    
    def test_image_enrichment_calls_vision_api(self, core, mock_image_analyzer):
        """enrich_media=True –≤—ã–∑—ã–≤–∞–µ—Ç Vision API."""
        mock_image_analyzer.analyze.return_value = MediaAnalysisResult(
            description="A cat sitting on a couch",
            keywords=["cat", "couch", "pet"],
        )
        
        doc = Document(content="path/to/cat.jpg", media_type=MediaType.IMAGE)
        result = core.ingest(doc, enrich_media=True)
        
        chunks = core.store.get_chunks(result.id)
        assert "cat sitting" in chunks[0].content
        mock_image_analyzer.analyze.assert_called_once()
```

### 5.2 Integration-—Ç–µ—Å—Ç—ã

```python
class TestDirectMediaSearch:
    """–¢–µ—Å—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –º–µ–¥–∏–∞."""
    
    def test_search_finds_image_by_description(self, core, real_image_path):
        """–ü–æ–∏—Å–∫ –Ω–∞—Ö–æ–¥–∏—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é –æ—Ç Vision API."""
        doc = Document(
            content=str(real_image_path),
            media_type=MediaType.IMAGE,
        )
        core.ingest(doc, enrich_media=True)
        
        results = core.search("cat on couch")
        assert len(results) > 0
        assert "cat" in results[0].document.content.lower()
```

---

## 6. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏

- [ ] `semantic ingest photo.jpg -e` ‚Üí —á–∞–Ω–∫ —Ç–∏–ø–∞ `IMAGE_REF`
- [ ] `semantic ingest audio.ogg -e` ‚Üí —á–∞–Ω–∫ —Ç–∏–ø–∞ `AUDIO_REF`  
- [ ] `semantic ingest video.mp4 -e` ‚Üí —á–∞–Ω–∫ —Ç–∏–ø–∞ `VIDEO_REF`
- [ ] Vision/Audio/Video API –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ `enrich_media=True`
- [ ] –ü–æ–∏—Å–∫ –Ω–∞—Ö–æ–¥–∏—Ç –º–µ–¥–∏–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É (–æ–ø–∏—Å–∞–Ω–∏–µ/—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è)
- [ ] –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ `metadata._original_path`
- [ ] Markdown —Å `![](...)` –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)

---

## 7. –°—Å—ã–ª–∫–∏ –Ω–∞ –∫–æ–¥

- **CLI —Å–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:** `semantic_core/cli/commands/ingest.py:55-75`
- **SmartSplitter:** `semantic_core/processing/splitters/smart_splitter.py:56-185`
- **Markdown –ø–∞—Ä—Å–µ—Ä:** `semantic_core/processing/parsers/markdown_parser.py:1-100`
- **Pipeline.ingest:** `semantic_core/pipeline.py:137-207`
- **_enrich_media_chunks:** `semantic_core/pipeline.py:479-570`
- **Media Analyzers:** `semantic_core/infrastructure/gemini/`
