# ‚öôÔ∏è Phase 14.3: User Flexibility & Configuration

**–î–∞—Ç–∞:** 2025-12-06  
**–°—Ç–∞—Ç—É—Å:** Planning  
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** Phase 14.1 (ProcessingStep), Phase 14.2 (MediaService)  
**–¶–µ–ª—å:** –°–¥–µ–ª–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –≥–∏–±–∫–æ–π —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞

---

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–ú–æ—Ç–∏–≤–∞—Ü–∏—è ‚Äî –ø–æ—á–µ–º—É –Ω—É–∂–Ω–∞ –≥–∏–±–∫–æ—Å—Ç—å](#1-–º–æ—Ç–∏–≤–∞—Ü–∏—è--–ø–æ—á–µ–º—É-–Ω—É–∂–Ω–∞-–≥–∏–±–∫–æ—Å—Ç—å)
2. [–ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ –ø—Ä–æ–º–ø—Ç—ã —á–µ—Ä–µ–∑ TOML](#2-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ-–ø—Ä–æ–º–ø—Ç—ã-—á–µ—Ä–µ–∑-toml)
3. [Per-role chunk sizing](#3-per-role-chunk-sizing)
4. [Full rerun —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º](#4-full-rerun-—Å-–Ω–æ–≤—ã–º-–∞–Ω–∞–ª–∏–∑–æ–º)
5. [OCR parser mode –≤ –∫–æ–Ω—Ñ–∏–≥–µ](#5-ocr-parser-mode-–≤-–∫–æ–Ω—Ñ–∏–≥–µ)
6. [–ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#6-–ø–ª–∞–Ω-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)

---

## 1. –ú–æ—Ç–∏–≤–∞—Ü–∏—è ‚Äî –ø–æ—á–µ–º—É –Ω—É–∂–Ω–∞ –≥–∏–±–∫–æ—Å—Ç—å

### 1.1 –¢–µ–∫—É—â–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (–ø–æ—Å–ª–µ Phase 14.1-14.2)

**–ü—Ä–æ–±–ª–µ–º—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**

‚ùå **–ü—Ä–æ–º–ø—Ç—ã –∑–∞—Ö–∞—Ä–¥–∫–æ–∂–µ–Ω—ã** ‚Äî –Ω–µ–ª—å–∑—è –∏–∑–º–µ–Ω–∏—Ç—å —Å—Ç–∏–ª—å –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ –ø—Ä–∞–≤–∫–∏ –∫–æ–¥–∞  
‚ùå **Chunk size –µ–¥–∏–Ω—ã–π** ‚Äî transcript –∏ OCR –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä (1800 —Ç–æ–∫–µ–Ω–æ–≤)  
‚ùå **Rerun –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞—Ä—ã–π analysis** ‚Äî –Ω–µ–ª—å–∑—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å summary —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º  
‚ùå **Parser mode —Å—Ç–∞—Ç–∏—á–µ–Ω** ‚Äî OCRStep –≤—Å–µ–≥–¥–∞ "markdown", –Ω–µ–ª—å–∑—è –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –Ω–∞ "plain"

**–°—Ü–µ–Ω–∞—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã:**

1. **–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –¥–ª—è –¥–æ–º–µ–Ω–∞:**

   ```
   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –ª–µ–∫—Ü–∏–∏.
   –ù—É–∂–µ–Ω –ø—Ä–æ–º–ø—Ç: "Extract medical terms, dosages, and diagnoses"
   ```

2. **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å chunk sizing:**

   ```
   OCR –∏–∑ —Å–ª–∞–π–¥–æ–≤ ‚Üí –±–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏ (3000 —Ç–æ–∫–µ–Ω–æ–≤, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å –∫–æ–¥)
   Transcript —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ ‚Üí –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ (1000 —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏)
   ```

3. **–£–ª—É—á—à–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**

   ```
   Gemini –≤—ã–ø—É—Å—Ç–∏–ª –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å gemini-3.0-pro.
   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å summary –¥–ª—è –≤—Å–µ—Ö –≤–∏–¥–µ–æ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º.
   ```

### 1.2 –¶–µ–ª–µ–≤–æ–π user experience

**–ü–æ—Å–ª–µ Phase 14.3:**

```toml
# semantic.toml

[media.prompts]
audio_summary = """
You are analyzing a medical lecture. 
Extract: diagnoses, medications, dosages, contraindications.
"""

video_ocr = """
This is a coding tutorial video.
Preserve ALL code blocks verbatim with syntax highlighting hints.
"""

[media.chunk_sizes]
transcript = 1000  # –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
ocr = 3000         # –ë–æ–ª—å—à–∏–µ —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Å–ª–∞–π–¥—ã

[media.processing]
ocr_parser_mode = "markdown"  # "markdown" | "plain"
enable_timecodes = true
```

**–ö–æ–º–∞–Ω–¥–∞ CLI:**

```bash
# –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å summary —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
semantic reanalyze video_123 --prompt-override audio_summary

# Rerun —Ç–æ–ª—å–∫–æ OCR —à–∞–≥ —Å –Ω–æ–≤—ã–º parser mode
semantic rerun-step video_123 ocr --parser-mode plain
```

---

## 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ –ø—Ä–æ–º–ø—Ç—ã —á–µ—Ä–µ–∑ TOML

### 2.1 –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ:** `semantic_core/config.py`

```python
from pydantic import BaseModel, Field
from typing import Optional, Dict

class MediaPromptsConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è analyzers."""
    
    # Audio analyzer prompts
    audio_system_prompt: Optional[str] = Field(
        default=None,
        description="Custom system prompt for audio analysis. Overrides default.",
    )
    
    audio_summary_instructions: Optional[str] = Field(
        default=None,
        description="Additional instructions for audio summary generation.",
    )
    
    # Video analyzer prompts
    video_system_prompt: Optional[str] = None
    video_ocr_instructions: Optional[str] = None
    
    # Image analyzer prompts
    image_system_prompt: Optional[str] = None
    image_alt_text_instructions: Optional[str] = None


class MediaChunkSizesConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤ –ø–æ —Ä–æ–ª—è–º."""
    
    transcript_chunk_size: int = Field(
        default=1800,
        ge=500,
        le=5000,
        description="Chunk size for transcript text (tokens).",
    )
    
    ocr_chunk_size: int = Field(
        default=2000,
        ge=500,
        le=5000,
        description="Chunk size for OCR text (tokens).",
    )
    
    code_chunk_size: int = Field(
        default=2000,
        ge=500,
        le=5000,
        description="Chunk size for code blocks extracted from OCR.",
    )


class MediaProcessingConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞."""
    
    ocr_parser_mode: str = Field(
        default="markdown",
        pattern="^(markdown|plain)$",
        description="Parser mode for OCR text: 'markdown' (detects code blocks) or 'plain'.",
    )
    
    enable_timecodes: bool = Field(
        default=True,
        description="Enable timecode extraction from Gemini responses ([MM:SS] format).",
    )
    
    strict_timecode_ordering: bool = Field(
        default=False,
        description="Enforce ascending order for timecodes (warn if violated).",
    )
    
    max_timeline_items: int = Field(
        default=100,
        ge=10,
        le=500,
        description="Maximum number of timeline items to generate.",
    )


class MediaConfig(BaseModel):
    """–ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–µ–¥–∏–∞-–æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    
    prompts: MediaPromptsConfig = Field(default_factory=MediaPromptsConfig)
    chunk_sizes: MediaChunkSizesConfig = Field(default_factory=MediaChunkSizesConfig)
    processing: MediaProcessingConfig = Field(default_factory=MediaProcessingConfig)


class SemanticConfig(BaseSettings):
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è ...
    
    media: MediaConfig = Field(default_factory=MediaConfig)
```

### 2.2 –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ Analyzers

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è:** `semantic_core/infrastructure/gemini/audio_analyzer.py`

```python
class GeminiAudioAnalyzer:
    # DEFAULT_SYSTEM_PROMPT ‚Äî fallback
    DEFAULT_SYSTEM_PROMPT = """You are an audio analyst..."""
    
    def __init__(
        self,
        api_key: str,
        model_name: str = "gemini-2.5-flash",
        custom_system_prompt: Optional[str] = None,  # ‚Üê NEW
        summary_instructions: Optional[str] = None,  # ‚Üê NEW
    ):
        self.client = genai.Client(api_key=api_key)
        self.model_name = model_name
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        self.system_prompt = self._build_system_prompt(
            custom_system_prompt,
            summary_instructions,
        )
    
    def _build_system_prompt(
        self,
        custom_prompt: Optional[str],
        additional_instructions: Optional[str],
    ) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞."""
        if custom_prompt:
            # –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
            base_prompt = custom_prompt
        else:
            base_prompt = self.DEFAULT_SYSTEM_PROMPT
        
        if additional_instructions:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∫ –±–∞–∑–æ–≤–æ–º—É –ø—Ä–æ–º–ø—Ç—É
            return f"{base_prompt}\n\nADDITIONAL INSTRUCTIONS:\n{additional_instructions}"
        
        return base_prompt
    
    def analyze(self, audio_path: Path, language: str = "en") -> dict:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º self.system_prompt –≤–º–µ—Å—Ç–æ SYSTEM_PROMPT_TEMPLATE
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=[...],
            config=types.GenerateContentConfig(
                system_instruction=self.system_prompt.format(language=language),
                response_schema=AudioAnalysisResult,
            ),
        )
        ...
```

**–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ SemanticCore:**

```python
class SemanticCore:
    def __init__(self, config_path: Optional[str] = None, ...):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
        self.config = SemanticConfig.from_toml(config_path or "semantic.toml")
        
        # –°–æ–∑–¥–∞—ë–º analyzers —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
        if self.config.gemini.api_key:
            self.audio_analyzer = GeminiAudioAnalyzer(
                api_key=self.config.gemini.api_key,
                custom_system_prompt=self.config.media.prompts.audio_system_prompt,
                summary_instructions=self.config.media.prompts.audio_summary_instructions,
            )
            
            self.video_analyzer = GeminiVideoAnalyzer(
                api_key=self.config.gemini.api_key,
                custom_system_prompt=self.config.media.prompts.video_system_prompt,
                ocr_instructions=self.config.media.prompts.video_ocr_instructions,
            )
```

---

## 3. Per-role chunk sizing

### 3.1 –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π chunk size –≤ Steps

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è:** `semantic_core/processing/steps/transcription_step.py`

```python
class TranscriptionStep(BaseProcessingStep):
    def __init__(
        self,
        splitter: BaseSplitter,
        default_chunk_size: int = 1800,  # ‚Üê –ò–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        enable_timecodes: bool = True,
    ):
        self.splitter = splitter
        self.default_chunk_size = default_chunk_size
        self.enable_timecodes = enable_timecodes
    
    def process(self, context: MediaPipelineContext) -> MediaPipelineContext:
        # –í—Ä–µ–º–µ–Ω–Ω–æ –º–µ–Ω—è–µ–º chunk_size —É splitter
        original_chunk_size = self.splitter.chunk_size
        self.splitter.chunk_size = self.default_chunk_size
        
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            split_chunks = self.splitter.split(temp_doc)
            ...
        finally:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            self.splitter.chunk_size = original_chunk_size
        
        return context.with_chunks(transcript_chunks)
```

**–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ SemanticCore:**

```python
def _create_default_steps(self) -> List[BaseProcessingStep]:
    return [
        SummaryStep(),
        TranscriptionStep(
            splitter=self.splitter,
            default_chunk_size=self.config.media.chunk_sizes.transcript_chunk_size,
            enable_timecodes=self.config.media.processing.enable_timecodes,
        ),
        OCRStep(
            splitter=self.splitter,
            parser_mode=self.config.media.processing.ocr_parser_mode,
            default_chunk_size=self.config.media.chunk_sizes.ocr_chunk_size,
        ),
    ]
```

### 3.2 –ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**semantic.toml:**

```toml
[media.chunk_sizes]
transcript_chunk_size = 1000  # –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ search
ocr_chunk_size = 3000         # –ë–æ–ª—å—à–∏–µ —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Å–ª–∞–π–¥—ã
code_chunk_size = 2500        # –°—Ä–µ–¥–Ω–∏–µ –¥–ª—è code blocks
```

---

## 4. Full rerun —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º

### 4.1 –ü—Ä–æ–±–ª–µ–º–∞ —Ç–µ–∫—É—â–µ–≥–æ rerun_step()

**–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (Phase 14.1):**

```python
def rerun_step(self, step_name: str, document_id: str):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –°–¢–ê–†–´–ô analysis –∏–∑ –ë–î (MediaTaskModel)
    task = MediaTaskModel.get_or_none(result_document_id=document_id)
    analysis = {
        "description": task.result_description,  # ‚Üê –ò–ó –ö–≠–®–ê
        "transcription": task.result_transcription,
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —à–∞–≥ —Å —Ç–µ–º –∂–µ –∞–Ω–∞–ª–∏–∑–æ–º
    context = MediaPipelineContext(analysis=analysis, ...)
    new_context = step.process(context)
```

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ–ª—å–∑—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å summary —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ä–æ–µ description).

### 4.2 –†–µ—à–µ–Ω–∏–µ ‚Äî reanalyze()

**–ù–æ–≤—ã–π –º–µ—Ç–æ–¥:** `semantic_core/pipeline.py`

```python
def reanalyze(
    self,
    document_id: str,
    analyzer_override: Optional[str] = None,
    prompt_override: Optional[str] = None,
    delete_old_chunks: bool = True,
) -> str:
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç analysis –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–∞.
    
    Args:
        document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è re-analysis.
        analyzer_override: –ò–º—è analyzer'–∞ –¥–ª—è override ("audio" | "video" | "image").
        prompt_override: –ö–ª—é—á –∏–∑ config.media.prompts (–Ω–∞–ø—Ä–∏–º–µ—Ä, "audio_summary").
        delete_old_chunks: –£–¥–∞–ª—è—Ç—å –ª–∏ —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö.
    
    Returns:
        –ù–æ–≤—ã–π document_id (–∏–ª–∏ —Ç–æ—Ç –∂–µ, –µ—Å–ª–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º).
    
    Raises:
        ValueError: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ–¥–∏–∞.
    """
    # –ù–∞—Ö–æ–¥–∏–º –∑–∞–¥–∞—á—É
    task = MediaTaskModel.get_or_none(MediaTaskModel.result_document_id == document_id)
    if not task:
        raise ValueError(f"Media task not found for document {document_id}")
    
    media_path = Path(task.file_path)
    media_type = task.media_type
    
    logger.info(
        "Re-analyzing media file",
        document_id=document_id,
        media_path=str(media_path),
        prompt_override=prompt_override,
    )
    
    # –í—ã–±–∏—Ä–∞–µ–º analyzer
    analyzer = self._get_analyzer(media_type, analyzer_override)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º prompt override (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
    if prompt_override:
        self._apply_prompt_override(analyzer, prompt_override)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∑–∞–Ω–æ–≤–æ
    new_analysis = analyzer.analyze(media_path)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏
    if delete_old_chunks:
        deleted = (
            ChunkModel.delete()
            .where(ChunkModel.document_id == document_id)
            .execute()
        )
        logger.info(f"Deleted old chunks", count=deleted)
    
    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ —á–µ—Ä–µ–∑ MediaPipeline
    doc = self.store.get_document_by_id(document_id)
    chunks = self._media_pipeline.build_chunks(
        analysis=new_analysis,
        document=doc,
        media_path=media_path,
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    self.store.update_chunks(document_id, chunks)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É
    task.result_description = new_analysis.get("description")
    task.result_transcription = new_analysis.get("transcription")
    task.result_ocr_text = new_analysis.get("ocr_text")
    task.save()
    
    logger.info(
        "Re-analysis complete",
        document_id=document_id,
        new_chunks=len(chunks),
    )
    
    return document_id

def _apply_prompt_override(self, analyzer, prompt_key: str):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç prompt override –∫ analyzer."""
    prompts_config = self.config.media.prompts
    
    if prompt_key == "audio_summary":
        analyzer.system_prompt = prompts_config.audio_summary_instructions
    elif prompt_key == "video_ocr":
        analyzer.ocr_instructions = prompts_config.video_ocr_instructions
    # ... –¥—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
```

### 4.3 CLI –∫–æ–º–∞–Ω–¥–∞

**–§–∞–π–ª:** `semantic_core/cli/commands/reanalyze.py`

```python
import typer
from semantic_core import SemanticCore

app = typer.Typer(name="reanalyze", help="Re-analyze media with new prompts")


@app.command()
def media(
    document_id: str = typer.Argument(..., help="Document ID to re-analyze"),
    prompt_override: str = typer.Option(
        None,
        "--prompt",
        help="Prompt override key from semantic.toml (e.g., 'audio_summary')",
    ),
    keep_old_chunks: bool = typer.Option(
        False,
        "--keep-old",
        help="Keep old chunks (default: delete before re-analysis)",
    ),
):
    """Re-analyze media file with new prompt configuration."""
    core = SemanticCore()
    
    try:
        new_doc_id = core.reanalyze(
            document_id=document_id,
            prompt_override=prompt_override,
            delete_old_chunks=not keep_old_chunks,
        )
        
        typer.echo(f"‚úÖ Re-analysis complete: {new_doc_id}")
    except ValueError as e:
        typer.echo(f"‚ùå Error: {e}", err=True)
        raise typer.Exit(1)
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```bash
# Re-analyze —Å –ø—Ä–æ–º–ø—Ç–æ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
semantic reanalyze video_123 --prompt audio_summary

# Re-analyze –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏
semantic reanalyze video_123 --keep-old
```

---

## 5. OCR parser mode –≤ –∫–æ–Ω—Ñ–∏–≥–µ

### 5.1 –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ parser mode

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è:** `semantic_core/processing/steps/ocr_step.py`

```python
class OCRStep(BaseProcessingStep):
    def __init__(
        self,
        splitter: BaseSplitter,
        parser_mode: str = "markdown",  # ‚Üê –ò–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        default_chunk_size: int = 2000,
    ):
        self.splitter = splitter
        self.parser_mode = parser_mode
        self.default_chunk_size = default_chunk_size
    
    def process(self, context: MediaPipelineContext) -> MediaPipelineContext:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º media_type –¥–ª—è Document –Ω–∞ –æ—Å–Ω–æ–≤–µ parser_mode
        if self.parser_mode == "markdown":
            media_type = MediaType.TEXT  # SmartSplitter auto-detect Markdown
        else:
            media_type = MediaType.TEXT
        
        temp_doc = Document(
            content=ocr_text,
            media_type=media_type,
        )
        
        # SmartSplitter –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç MarkdownNodeParser –¥–ª—è TEXT
        split_chunks = self.splitter.split(temp_doc)
        ...
```

### 5.2 –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

**semantic.toml:**

```toml
[media.processing]
ocr_parser_mode = "markdown"  # "markdown" –¥–µ—Ç–µ–∫—Ç–∏—Ç code blocks | "plain" –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
```

---

## 6. –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### 6.1 –≠—Ç–∞–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

**Week 1: Configuration Infrastructure**

- [ ] –†–∞—Å—à–∏—Ä–∏—Ç—å `SemanticConfig` —Å `MediaConfig`
- [ ] –î–æ–±–∞–≤–∏—Ç—å `MediaPromptsConfig`, `MediaChunkSizesConfig`, `MediaProcessingConfig`
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `AudioAnalyzer`, `VideoAnalyzer`, `ImageAnalyzer` –¥–ª—è custom prompts
- [ ] Unit-—Ç–µ—Å—Ç—ã: –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ TOML

**Week 2: Per-role Chunk Sizing**

- [ ] –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å `TranscriptionStep`, `OCRStep` –¥–ª—è dynamic chunk size
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `SemanticCore._create_default_steps()` —Å –∫–æ–Ω—Ñ–∏–≥–æ–º
- [ ] E2E —Ç–µ—Å—Ç: OCR chunks = 3000 —Ç–æ–∫–µ–Ω–æ–≤, transcript = 1000

**Week 3: Reanalyze Feature**

- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `SemanticCore.reanalyze()`
- [ ] –î–æ–±–∞–≤–∏—Ç—å `_apply_prompt_override()` helper
- [ ] –°–æ–∑–¥–∞—Ç—å CLI –∫–æ–º–∞–Ω–¥—É `semantic reanalyze`
- [ ] E2E —Ç–µ—Å—Ç: reanalyze ‚Üí –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ —Å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–º summary

**Week 4: Polish & Documentation**

- [ ] –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ TOML –∫–æ–Ω—Ñ–∏–≥–æ–≤
- [ ] –î–æ–±–∞–≤–∏—Ç—å migration guide –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç—å—é 76: "User Flexibility —á–µ—Ä–µ–∑ Configuration"
- [ ] –û–±–Ω–æ–≤–∏—Ç—å Flask UI –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è custom prompts (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

### 6.2 –ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π

**–ü—Ä–∏–º–µ—Ä 1: –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –ª–µ–∫—Ü–∏–∏**

```toml
[media.prompts]
audio_summary_instructions = """
Extract the following from medical lectures:
- Diagnoses mentioned
- Medications and dosages
- Contraindications
- Key medical terms
Format as structured list.
"""

[media.chunk_sizes]
transcript_chunk_size = 1200  # –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
```

**–ü—Ä–∏–º–µ—Ä 2: Coding tutorials**

```toml
[media.prompts]
video_ocr_instructions = """
This is a programming tutorial video.
CRITICAL: Preserve ALL code blocks verbatim.
Include syntax highlighting hints (language name).
"""

[media.chunk_sizes]
ocr_chunk_size = 3500      # –ë–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏ —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏
code_chunk_size = 3000

[media.processing]
ocr_parser_mode = "markdown"  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è code detection
```

**–ü—Ä–∏–º–µ—Ä 3: –õ—ë–≥–∫–∏–π —Ä–µ–∂–∏–º (–±–µ–∑ code detection)**

```toml
[media.processing]
ocr_parser_mode = "plain"      # –û—Ç–∫–ª—é—á–∏—Ç—å Markdown –ø–∞—Ä—Å–∏–Ω–≥
enable_timecodes = false       # –û—Ç–∫–ª—é—á–∏—Ç—å timecode extraction

[media.chunk_sizes]
transcript_chunk_size = 2000   # –ö—Ä—É–ø–Ω–µ–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
ocr_chunk_size = 2500
```

### 6.3 Success Metrics

**Configuration:**

- ‚úÖ –í—Å–µ –ø—Ä–æ–º–ø—Ç—ã –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ TOML
- ‚úÖ Chunk sizes —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –¥–ª—è transcript/OCR/code
- ‚úÖ `reanalyze()` –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫–∏ —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º

**User Experience:**

- ‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –∫–∞—Å—Ç–æ–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–µ–∑ –ø—Ä–∞–≤–∫–∏ –∫–æ–¥–∞
- ‚úÖ CLI –∫–æ–º–∞–Ω–¥–∞ `semantic reanalyze` —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å 5+ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–Ω—Ñ–∏–≥–æ–≤

**Performance:**

- ‚úÖ Reanalyze 10-–º–∏–Ω—É—Ç–Ω–æ–≥–æ –≤–∏–¥–µ–æ < 60 —Å–µ–∫—É–Ω–¥
- ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ—Ç overhead (< 10ms)

---

**End of Phase 14.3 Plan**  
**Estimated Duration:** 1-2 weeks  
**Team:** 1 engineer
