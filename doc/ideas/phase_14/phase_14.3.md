# ‚öôÔ∏è Phase 14.3: User Flexibility & Configuration

**–î–∞—Ç–∞:** 2025-12-06  
**–°—Ç–∞—Ç—É—Å:** In Progress  
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** Phase 14.1 (ProcessingStep), Phase 14.2 (MediaService)  
**–¶–µ–ª—å:** –°–¥–µ–ª–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –≥–∏–±–∫–æ–π —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:**

- ‚úÖ **SRP:** `MediaService.reprocess_document()` –≤–º–µ—Å—Ç–æ `SemanticCore.reanalyze()`
- ‚úÖ **Single Source of Truth:** `Document.metadata["source"]` –≤–º–µ—Å—Ç–æ `MediaTaskModel.file_path`
- ‚úÖ **Template Injection:** Placeholders –≤–º–µ—Å—Ç–æ string concatenation

---

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–ú–æ—Ç–∏–≤–∞—Ü–∏—è ‚Äî –ø–æ—á–µ–º—É –Ω—É–∂–Ω–∞ –≥–∏–±–∫–æ—Å—Ç—å](#1-–º–æ—Ç–∏–≤–∞—Ü–∏—è--–ø–æ—á–µ–º—É-–Ω—É–∂–Ω–∞-–≥–∏–±–∫–æ—Å—Ç—å)
2. [–ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ –ø—Ä–æ–º–ø—Ç—ã —á–µ—Ä–µ–∑ TOML](#2-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ-–ø—Ä–æ–º–ø—Ç—ã-—á–µ—Ä–µ–∑-toml)
3. [Per-role chunk sizing](#3-per-role-chunk-sizing)
4. [Full rerun —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º](#4-full-rerun-—Å-–Ω–æ–≤—ã–º-–∞–Ω–∞–ª–∏–∑–æ–º)
5. [OCR parser mode –≤ –∫–æ–Ω—Ñ–∏–≥–µ](#5-ocr-parser-mode-–≤-–∫–æ–Ω—Ñ–∏–≥–µ)
6. [–ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#6-–ø–ª–∞–Ω-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)

---

## 1. –ú–æ—Ç–∏–≤–∞—Ü–∏—è ‚Äî –ø–æ—á–µ–º—É –Ω—É–∂–Ω–∞ –≥–∏–±–∫–æ—Å—Ç—å

### 1.1 –¢–µ–∫—É—â–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (–ø–æ—Å–ª–µ Phase 14.1-14.2)

**–ü—Ä–æ–±–ª–µ–º—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**

‚ùå **–ü—Ä–æ–º–ø—Ç—ã –∑–∞—Ö–∞—Ä–¥–∫–æ–∂–µ–Ω—ã** ‚Äî –Ω–µ–ª—å–∑—è –∏–∑–º–µ–Ω–∏—Ç—å —Å—Ç–∏–ª—å –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ –ø—Ä–∞–≤–∫–∏ –∫–æ–¥–∞  
‚ùå **Chunk size –µ–¥–∏–Ω—ã–π** ‚Äî transcript –∏ OCR –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä (1800 —Ç–æ–∫–µ–Ω–æ–≤)  
‚ùå **Rerun –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞—Ä—ã–π analysis** ‚Äî –Ω–µ–ª—å–∑—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å summary —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º  
‚ùå **Parser mode —Å—Ç–∞—Ç–∏—á–µ–Ω** ‚Äî OCRStep –≤—Å–µ–≥–¥–∞ "markdown", –Ω–µ–ª—å–∑—è –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –Ω–∞ "plain"

**–°—Ü–µ–Ω–∞—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã:**

1. **–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –¥–ª—è –¥–æ–º–µ–Ω–∞:**

   ```
   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –ª–µ–∫—Ü–∏–∏.
   –ù—É–∂–µ–Ω –ø—Ä–æ–º–ø—Ç: "Extract medical terms, dosages, and diagnoses"
   ```

2. **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å chunk sizing:**

   ```
   OCR –∏–∑ —Å–ª–∞–π–¥–æ–≤ ‚Üí –±–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏ (3000 —Ç–æ–∫–µ–Ω–æ–≤, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å –∫–æ–¥)
   Transcript —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ ‚Üí –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ (1000 —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏)
   ```

3. **–£–ª—É—á—à–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**

   ```
   Gemini –≤—ã–ø—É—Å—Ç–∏–ª –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å gemini-3.0-pro.
   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å summary –¥–ª—è –≤—Å–µ—Ö –≤–∏–¥–µ–æ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º.
   ```

### 1.2 –¶–µ–ª–µ–≤–æ–π user experience

**–ü–æ—Å–ª–µ Phase 14.3:**

```toml
# semantic.toml

[media.prompts]
audio_summary = """
You are analyzing a medical lecture. 
Extract: diagnoses, medications, dosages, contraindications.
"""

video_ocr = """
This is a coding tutorial video.
Preserve ALL code blocks verbatim with syntax highlighting hints.
"""

[media.chunk_sizes]
transcript = 1000  # –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
ocr = 3000         # –ë–æ–ª—å—à–∏–µ —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Å–ª–∞–π–¥—ã

[media.processing]
ocr_parser_mode = "markdown"  # "markdown" | "plain"
enable_timecodes = true
```

**–ö–æ–º–∞–Ω–¥–∞ CLI:**

```bash
# –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å summary —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
semantic reanalyze video_123 --prompt-override audio_summary

# Rerun —Ç–æ–ª—å–∫–æ OCR —à–∞–≥ —Å –Ω–æ–≤—ã–º parser mode
semantic rerun-step video_123 ocr --parser-mode plain
```

---

## 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ –ø—Ä–æ–º–ø—Ç—ã —á–µ—Ä–µ–∑ TOML

### 2.1 –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ:** `semantic_core/config.py`

```python
from pydantic import BaseModel, Field
from typing import Optional, Dict

class MediaPromptsConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è analyzers."""
    
    # Audio analyzer prompts
    audio_system_prompt: Optional[str] = Field(
        default=None,
        description="Custom system prompt for audio analysis. Overrides default.",
    )
    
    audio_summary_instructions: Optional[str] = Field(
        default=None,
        description="Additional instructions for audio summary generation.",
    )
    
    # Video analyzer prompts
    video_system_prompt: Optional[str] = None
    video_ocr_instructions: Optional[str] = None
    
    # Image analyzer prompts
    image_system_prompt: Optional[str] = None
    image_alt_text_instructions: Optional[str] = None


class MediaChunkSizesConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤ –ø–æ —Ä–æ–ª—è–º."""
    
    transcript_chunk_size: int = Field(
        default=1800,
        ge=500,
        le=5000,
        description="Chunk size for transcript text (tokens).",
    )
    
    ocr_chunk_size: int = Field(
        default=2000,
        ge=500,
        le=5000,
        description="Chunk size for OCR text (tokens).",
    )
    
    code_chunk_size: int = Field(
        default=2000,
        ge=500,
        le=5000,
        description="Chunk size for code blocks extracted from OCR.",
    )


class MediaProcessingConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞."""
    
    ocr_parser_mode: str = Field(
        default="markdown",
        pattern="^(markdown|plain)$",
        description="Parser mode for OCR text: 'markdown' (detects code blocks) or 'plain'.",
    )
    
    enable_timecodes: bool = Field(
        default=True,
        description="Enable timecode extraction from Gemini responses ([MM:SS] format).",
    )
    
    strict_timecode_ordering: bool = Field(
        default=False,
        description="Enforce ascending order for timecodes (warn if violated).",
    )
    
    max_timeline_items: int = Field(
        default=100,
        ge=10,
        le=500,
        description="Maximum number of timeline items to generate.",
    )


class MediaConfig(BaseModel):
    """–ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–µ–¥–∏–∞-–æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    
    prompts: MediaPromptsConfig = Field(default_factory=MediaPromptsConfig)
    chunk_sizes: MediaChunkSizesConfig = Field(default_factory=MediaChunkSizesConfig)
    processing: MediaProcessingConfig = Field(default_factory=MediaProcessingConfig)


class SemanticConfig(BaseSettings):
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è ...
    
    media: MediaConfig = Field(default_factory=MediaConfig)
```

### 2.2 –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ Analyzers

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è:** `semantic_core/infrastructure/gemini/audio_analyzer.py`

**–ö–†–ò–¢–ò–ß–ù–û:** –ò—Å–ø–æ–ª—å–∑—É–µ–º **template injection** –≤–º–µ—Å—Ç–æ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏!

```python
class GeminiAudioAnalyzer:
    # DEFAULT_SYSTEM_PROMPT —Å placeholders
    DEFAULT_SYSTEM_PROMPT = """You are an audio analyst creating descriptions for semantic search indexing.
Response language: {language}

{custom_instructions}

Return a JSON with the following structure:
{{
  "description": "Brief 2-3 sentence summary...",
  ...
}}

CRITICAL INSTRUCTIONS FOR TRANSCRIPTION FIELD:
- Use Markdown formatting...
"""
    
    def __init__(
        self,
        api_key: str,
        model_name: str = "gemini-2.5-flash",
        custom_instructions: Optional[str] = None,  # ‚Üê NEW
        output_language: str = "Russian",
    ):
        self.client = genai.Client(api_key=api_key)
        self.model_name = model_name
        self.output_language = output_language
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ template injection
        self.system_prompt = self._build_system_prompt(
            custom_instructions=custom_instructions,
            language=output_language,
        )
    
    def _build_system_prompt(
        self,
        custom_instructions: Optional[str],
        language: str,
    ) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ template injection.
        
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤—Å—Ç–∞–≤–ª—è–µ—Ç custom_instructions –ü–ï–†–ï–î –æ–ø–∏—Å–∞–Ω–∏–µ–º JSON-—Å—Ö–µ–º—ã.
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–ª–æ–∫ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
        instructions_block = ""
        if custom_instructions:
            instructions_block = f"""
ADDITIONAL INSTRUCTIONS:
{custom_instructions}
"""
        
        # Template injection ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω–æ!
        return self.DEFAULT_SYSTEM_PROMPT.format(
            language=language,
            custom_instructions=instructions_block,
        )
    
    def analyze(self, audio_path: Path) -> dict:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º self.system_prompt
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=[...],
            config=types.GenerateContentConfig(
                system_instruction=self.system_prompt,
                response_schema=AudioAnalysisResult,
            ),
        )
        ...
```

**–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ SemanticCore:**

```python
class SemanticCore:
    def __init__(self, config_path: Optional[str] = None, ...):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
        self.config = SemanticConfig.from_toml(config_path or "semantic.toml")
        
        # –°–æ–∑–¥–∞—ë–º analyzers —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
        if self.config.gemini.api_key:
            self.audio_analyzer = GeminiAudioAnalyzer(
                api_key=self.config.gemini.api_key,
                custom_instructions=self.config.media.prompts.audio_summary_instructions,
                output_language=self.config.media.analysis.language,
            )
            
            self.video_analyzer = GeminiVideoAnalyzer(
                api_key=self.config.gemini.api_key,
                custom_instructions=self.config.media.prompts.video_ocr_instructions,
                output_language=self.config.media.analysis.language,
            )
```

---

## 3. Per-role chunk sizing

### 3.1 –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π chunk size –≤ Steps

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è:** `semantic_core/processing/steps/transcription_step.py`

```python
class TranscriptionStep(BaseProcessingStep):
    def __init__(
        self,
        splitter: BaseSplitter,
        default_chunk_size: int = 1800,  # ‚Üê –ò–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        enable_timecodes: bool = True,
    ):
        self.splitter = splitter
        self.default_chunk_size = default_chunk_size
        self.enable_timecodes = enable_timecodes
    
    def process(self, context: MediaPipelineContext) -> MediaPipelineContext:
        # –í—Ä–µ–º–µ–Ω–Ω–æ –º–µ–Ω—è–µ–º chunk_size —É splitter
        original_chunk_size = self.splitter.chunk_size
        self.splitter.chunk_size = self.default_chunk_size
        
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            split_chunks = self.splitter.split(temp_doc)
            ...
        finally:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            self.splitter.chunk_size = original_chunk_size
        
        return context.with_chunks(transcript_chunks)
```

**–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ SemanticCore:**

```python
def _create_default_steps(self) -> List[BaseProcessingStep]:
    return [
        SummaryStep(),
        TranscriptionStep(
            splitter=self.splitter,
            default_chunk_size=self.config.media.chunk_sizes.transcript_chunk_size,
            enable_timecodes=self.config.media.processing.enable_timecodes,
        ),
        OCRStep(
            splitter=self.splitter,
            parser_mode=self.config.media.processing.ocr_parser_mode,
            default_chunk_size=self.config.media.chunk_sizes.ocr_chunk_size,
        ),
    ]
```

### 3.2 –ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**semantic.toml:**

```toml
[media.chunk_sizes]
transcript_chunk_size = 1000  # –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ search
ocr_chunk_size = 3000         # –ë–æ–ª—å—à–∏–µ —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Å–ª–∞–π–¥—ã
code_chunk_size = 2500        # –°—Ä–µ–¥–Ω–∏–µ –¥–ª—è code blocks
```

---

## 4. Full rerun —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º

### 4.1 –ü—Ä–æ–±–ª–µ–º–∞ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∞

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –æ—à–∏–±–∫–∞:** `MediaTaskModel` –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã –¥–ª—è reanalyze.

```python
# –ü–õ–û–•–û ‚Äî MediaTaskModel –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å
task = MediaTaskModel.get(result_document_id=document_id)
media_path = Path(task.file_path)  # ‚Üê –ß—Ç–æ –µ—Å–ª–∏ task —É–¥–∞–ª—ë–Ω?
```

**–ü—Ä–æ–±–ª–µ–º–∞:** `MediaTask` ‚Äî —ç—Ç–æ **Queue Item** (–æ—á–µ—Ä–µ–¥—å). –ï—Å–ª–∏ —á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ tasks:

```sql
DELETE FROM media_tasks WHERE processed_at < NOW() - INTERVAL '30 days';
```

‚Üí **–ü–æ—Ç–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å reanalyze** (–Ω–µ—Ç –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É)!

**–†–µ—à–µ–Ω–∏–µ:** `Document.metadata["source"]` –£–ñ–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É—Ç—å –∫ –º–µ–¥–∏–∞:

```python
# semantic_core/pipeline.py line 680, 709, 838...
metadata = {"source": str(path)}  # ‚Üê Single Source of Truth!
```

### 4.2 –†–µ—à–µ–Ω–∏–µ ‚Äî MediaService.reprocess_document()

**–ö–†–ò–¢–ò–ß–ù–û:** –õ–æ–≥–∏–∫–∞ –≤ `MediaService`, –ù–ï –≤ `SemanticCore` (SRP)!

**–ù–æ–≤—ã–π –º–µ—Ç–æ–¥:** `semantic_core/services/media_service.py`

```python
class MediaService:
    def __init__(
        self,
        store: BaseVectorStore,
        embedder: BaseEmbedder,
        splitter: BaseSplitter,
        media_pipeline: MediaPipeline,
    ):
        self.store = store
        self.embedder = embedder
        self.splitter = splitter
        self.media_pipeline = media_pipeline
    
    def reprocess_document(
        self,
        document_id: str,
        new_analysis: dict,
        delete_old_chunks: bool = True,
    ) -> str:
        """–ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫–∏ –¥–ª—è –º–µ–¥–∏–∞-–¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º.
        
        Args:
            document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
            new_analysis: –ù–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç analyzer.analyze().
            delete_old_chunks: –£–¥–∞–ª—è—Ç—å –ª–∏ —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö.
        
        Returns:
            ID –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
        
        Raises:
            ValueError: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ–¥–∏–∞.
            FileNotFoundError: –ï—Å–ª–∏ –º–µ–¥–∏–∞-—Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
        """
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º Document –∏–∑ –ë–î
        doc_model = DocumentModel.get_by_id(document_id)
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –º–µ–¥–∏–∞
        if doc_model.media_type not in ("image", "audio", "video"):
            raise ValueError(f"Document {document_id} is not a media file")
        
        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∏–∑ Document.metadata (Single Source of Truth!)
        metadata = json.loads(doc_model.metadata)
        media_path = Path(metadata["source"])
        
        # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not media_path.exists():
            raise FileNotFoundError(f"Media file not found: {media_path}")
        
        logger.info(
            "Reprocessing media document",
            document_id=document_id,
            media_path=str(media_path),
        )
        
        # 5. –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏
        if delete_old_chunks:
            deleted = (
                ChunkModel.delete()
                .where(ChunkModel.document == document_id)
                .execute()
            )
            logger.info("Deleted old chunks", count=deleted)
        
        # 6. –°–æ–∑–¥–∞—ë–º domain Document
        document = Document(
            content=str(media_path),
            metadata=metadata,
            media_type=MediaType(doc_model.media_type),
            id=document_id,
        )
        
        # 7. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ —á–µ—Ä–µ–∑ MediaPipeline
        context = MediaContext(
            media_path=media_path,
            document=document,
            analysis=new_analysis,
        )
        
        final_context = self.media_pipeline.build_chunks(context)
        new_chunks = final_context.chunks
        
        # 8. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        chunk_texts = [chunk.content for chunk in new_chunks]
        embeddings = self.embedder.embed_documents(chunk_texts)
        
        for chunk, embedding in zip(new_chunks, embeddings):
            chunk.embedding = embedding
        
        # 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
        self.store.save(document, new_chunks)
        
        logger.info(
            "Reprocessing complete",
            document_id=document_id,
            new_chunks_count=len(new_chunks),
        )
        
        return document_id
```

**SemanticCore ‚Äî —Ç–æ–Ω–∫–∏–π proxy:**

```python
class SemanticCore:
    def __init__(self, ...):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MediaService
        self.media_service = MediaService(
            store=self.store,
            embedder=self.embedder,
            splitter=self.splitter,
            media_pipeline=self._create_media_pipeline(),
        )
    
    def reanalyze(
        self,
        document_id: str,
        analyzer_type: Optional[str] = None,
        custom_instructions: Optional[str] = None,
        delete_old_chunks: bool = True,
    ) -> str:
        """–ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç analysis –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–∞.
        
        Thin proxy –¥–ª—è MediaService.reprocess_document().
        
        Args:
            document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è re-analysis.
            analyzer_type: –¢–∏–ø analyzer ("audio" | "video" | "image").
            custom_instructions: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
            delete_old_chunks: –£–¥–∞–ª—è—Ç—å –ª–∏ —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏.
        
        Returns:
            ID –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
        """
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞
        doc_model = DocumentModel.get_by_id(document_id)
        metadata = json.loads(doc_model.metadata)
        media_path = Path(metadata["source"])
        media_type = doc_model.media_type
        
        # 2. –í—ã–±–∏—Ä–∞–µ–º analyzer
        analyzer = self._get_analyzer_for_type(
            media_type,
            override_type=analyzer_type,
            custom_instructions=custom_instructions,
        )
        
        # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        logger.info("Running new analysis", media_path=str(media_path))
        new_analysis = analyzer.analyze(media_path)
        
        # 4. –î–µ–ª–µ–≥–∏—Ä—É–µ–º MediaService
        return self.media_service.reprocess_document(
            document_id=document_id,
            new_analysis=new_analysis,
            delete_old_chunks=delete_old_chunks,
        )
    
    def _get_analyzer_for_type(
        self,
        media_type: str,
        override_type: Optional[str] = None,
        custom_instructions: Optional[str] = None,
    ):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç analyzer —Å —É—á—ë—Ç–æ–º override."""
        target_type = override_type or media_type
        
        if target_type == "audio":
            # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π analyzer —Å custom instructions
            if custom_instructions:
                return GeminiAudioAnalyzer(
                    api_key=self.config.gemini.api_key,
                    custom_instructions=custom_instructions,
                )
            return self.audio_analyzer
        
        elif target_type == "video":
            if custom_instructions:
                return GeminiVideoAnalyzer(
                    api_key=self.config.gemini.api_key,
                    custom_instructions=custom_instructions,
                )
            return self.video_analyzer
        
        # ... –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è image
```

### 4.3 CLI –∫–æ–º–∞–Ω–¥–∞

**–§–∞–π–ª:** `semantic_core/cli/commands/reanalyze.py`

```python
import typer
from semantic_core import SemanticCore

app = typer.Typer(name="reanalyze", help="Re-analyze media with new prompts")


@app.command()
def media(
    document_id: str = typer.Argument(..., help="Document ID to re-analyze"),
    prompt_override: str = typer.Option(
        None,
        "--prompt",
        help="Prompt override key from semantic.toml (e.g., 'audio_summary')",
    ),
    keep_old_chunks: bool = typer.Option(
        False,
        "--keep-old",
        help="Keep old chunks (default: delete before re-analysis)",
    ),
):
    """Re-analyze media file with new prompt configuration."""
    core = SemanticCore()
    
    try:
        new_doc_id = core.reanalyze(
            document_id=document_id,
            prompt_override=prompt_override,
            delete_old_chunks=not keep_old_chunks,
        )
        
        typer.echo(f"‚úÖ Re-analysis complete: {new_doc_id}")
    except ValueError as e:
        typer.echo(f"‚ùå Error: {e}", err=True)
        raise typer.Exit(1)
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```bash
# Re-analyze —Å –ø—Ä–æ–º–ø—Ç–æ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
semantic reanalyze video_123 --prompt audio_summary

# Re-analyze –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏
semantic reanalyze video_123 --keep-old
```

---

## 5. OCR parser mode –≤ –∫–æ–Ω—Ñ–∏–≥–µ

### 5.1 –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ parser mode

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è:** `semantic_core/processing/steps/ocr_step.py`

```python
class OCRStep(BaseProcessingStep):
    def __init__(
        self,
        splitter: BaseSplitter,
        parser_mode: str = "markdown",  # ‚Üê –ò–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        default_chunk_size: int = 2000,
    ):
        self.splitter = splitter
        self.parser_mode = parser_mode
        self.default_chunk_size = default_chunk_size
    
    def process(self, context: MediaPipelineContext) -> MediaPipelineContext:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º media_type –¥–ª—è Document –Ω–∞ –æ—Å–Ω–æ–≤–µ parser_mode
        if self.parser_mode == "markdown":
            media_type = MediaType.TEXT  # SmartSplitter auto-detect Markdown
        else:
            media_type = MediaType.TEXT
        
        temp_doc = Document(
            content=ocr_text,
            media_type=media_type,
        )
        
        # SmartSplitter –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç MarkdownNodeParser –¥–ª—è TEXT
        split_chunks = self.splitter.split(temp_doc)
        ...
```

### 5.2 –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

**semantic.toml:**

```toml
[media.processing]
ocr_parser_mode = "markdown"  # "markdown" –¥–µ—Ç–µ–∫—Ç–∏—Ç code blocks | "plain" –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
```

---

## 6. –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### 6.1 –≠—Ç–∞–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

**Phase 14.3.1: Configuration Infrastructure** ‚úÖ CRITICAL

- [ ] –†–∞—Å—à–∏—Ä–∏—Ç—å `SemanticConfig` —Å `MediaPromptsConfig`, `MediaChunkSizesConfig`, `MediaProcessingConfig`
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `AudioAnalyzer`, `VideoAnalyzer` –¥–ª—è custom instructions —á–µ—Ä–µ–∑ template injection
- [ ] Unit-—Ç–µ—Å—Ç—ã: –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ TOML, template placeholders

**Phase 14.3.2: Per-role Chunk Sizing**

- [ ] –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å `TranscriptionStep`, `OCRStep` –¥–ª—è dynamic chunk size
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `SemanticCore._create_default_steps()` —Å –∫–æ–Ω—Ñ–∏–≥–æ–º
- [ ] E2E —Ç–µ—Å—Ç: OCR chunks = 3000 —Ç–æ–∫–µ–Ω–æ–≤, transcript = 1000

**Phase 14.3.3: MediaService.reprocess_document()** ‚úÖ CRITICAL

- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `MediaService.reprocess_document()`
- [ ] `SemanticCore.reanalyze()` –∫–∞–∫ thin proxy
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `Document.metadata["source"]` (Single Source of Truth)
- [ ] Unit-—Ç–µ—Å—Ç—ã: reprocess —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

**Phase 14.3.4: CLI Integration**

- [ ] –°–æ–∑–¥–∞—Ç—å CLI –∫–æ–º–∞–Ω–¥—É `semantic reanalyze`
- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ `--custom-instructions`, `--keep-old`
- [ ] E2E —Ç–µ—Å—Ç: reanalyze ‚Üí –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ —Å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–º summary

**Phase 14.3.5: Total E2E Testing**
- [ ] –ü–æ–ª–Ω—ã–π E2E —Ç–µ—Å—Ç: –∑–∞–≥—Ä—É–∑–∫–∞ –º–µ–¥–∏–∞ ‚Üí –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç ‚Üí per-role chunk sizing ‚Üí reanalyze -> –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–∞–Ω–∫–æ–≤ –∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ (–∏–∑ –ë–î)
–í–∞–∂–Ω–æ. –ù–∞ –≤—Ö–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ê—Å—Å–µ—Ç–æ–≤. –ï—Å–ª–∏ –Ω—É–∂–Ω—ã –±–æ–ª–µ–µ –æ–±—ä–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–∫–∞–∂–∏. –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–µ–ª—å–Ω—ã–π .env –∫–ª—é—á - –æ–Ω —Ç–∞–º –µ—Å—Ç—å.
–ë–µ—Ä–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—É—é –ë–î. –ù–∏–∫–∞–∫–∏—Ö –ø–æ–¥–º–µ–Ω, –º–æ–∫–æ–≤, —É—Å–∫–æ—Ä–µ–Ω–∏–π. –ü–û–õ–ù–´–ï –ü–†–í–û–ï–†–ö–ò –≤–æ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö. –ß—Ç–æ–±—ã –ø–æ—Ç–æ–º –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –¥–Ω–∏ –Ω–∞ —Ä—É—á–Ω–æ–µ —Ç–µ—Å—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ.

**Phase 14.4: Polish & Documentation**

- [ ] –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ TOML –∫–æ–Ω—Ñ–∏–≥–æ–≤
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç—å—é 82: "User Flexibility —á–µ—Ä–µ–∑ Configuration"
- [ ] Migration guide –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

### 6.2 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –≥–∞—Ä–∞–Ω—Ç–∏–∏

**Code Smells Prevention:**

1. ‚úÖ **SRP:** `MediaService.reprocess_document()` –≤–º–µ—Å—Ç–æ `SemanticCore.reanalyze()`
2. ‚úÖ **Template Injection:** `{custom_instructions}` placeholder –≤–º–µ—Å—Ç–æ `+` –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏
3. ‚úÖ **Single Source of Truth:** `Document.metadata["source"]` –≤–º–µ—Å—Ç–æ `MediaTaskModel.file_path`

**MediaTaskModel –º–æ–∂–µ—Ç —á–∏—Å—Ç–∏—Ç—å—Å—è:**

```sql
-- –ë–µ–∑–æ–ø–∞—Å–Ω–æ! Reanalyze –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Document.metadata
DELETE FROM media_tasks WHERE processed_at < NOW() - INTERVAL '30 days';
```

### 6.2 –ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π

**–ü—Ä–∏–º–µ—Ä 1: –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –ª–µ–∫—Ü–∏–∏**

```toml
[media.prompts]
audio_summary_instructions = """
Extract the following from medical lectures:
- Diagnoses mentioned
- Medications and dosages
- Contraindications
- Key medical terms
Format as structured list.
"""

[media.chunk_sizes]
transcript_chunk_size = 1200  # –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
```

**–ü—Ä–∏–º–µ—Ä 2: Coding tutorials**

```toml
[media.prompts]
video_ocr_instructions = """
This is a programming tutorial video.
CRITICAL: Preserve ALL code blocks verbatim.
Include syntax highlighting hints (language name).
"""

[media.chunk_sizes]
ocr_chunk_size = 3500      # –ë–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏ —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏
code_chunk_size = 3000

[media.processing]
ocr_parser_mode = "markdown"  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è code detection
```

**–ü—Ä–∏–º–µ—Ä 3: –õ—ë–≥–∫–∏–π —Ä–µ–∂–∏–º (–±–µ–∑ code detection)**

```toml
[media.processing]
ocr_parser_mode = "plain"      # –û—Ç–∫–ª—é—á–∏—Ç—å Markdown –ø–∞—Ä—Å–∏–Ω–≥
enable_timecodes = false       # –û—Ç–∫–ª—é—á–∏—Ç—å timecode extraction

[media.chunk_sizes]
transcript_chunk_size = 2000   # –ö—Ä—É–ø–Ω–µ–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
ocr_chunk_size = 2500
```

### 6.3 Success Metrics

**Configuration:**

- ‚úÖ –í—Å–µ –ø—Ä–æ–º–ø—Ç—ã –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ TOML
- ‚úÖ Chunk sizes —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –¥–ª—è transcript/OCR/code
- ‚úÖ `MediaService.reprocess_document()` –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫–∏ —Å –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
- ‚úÖ `Document.metadata["source"]` ‚Äî Single Source of Truth (–Ω–µ MediaTaskModel)

**User Experience:**

- ‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –∫–∞—Å—Ç–æ–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–µ–∑ –ø—Ä–∞–≤–∫–∏ –∫–æ–¥–∞
- ‚úÖ CLI –∫–æ–º–∞–Ω–¥–∞ `semantic reanalyze` —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å 5+ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–Ω—Ñ–∏–≥–æ–≤

**Architecture:**

- ‚úÖ `SemanticCore` –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–Ω–∫–∏–º —Ñ–∞—Å–∞–¥–æ–º (SRP)
- ‚úÖ Template injection –≤–º–µ—Å—Ç–æ string concatenation (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
- ‚úÖ MediaTaskModel –º–æ–∂–Ω–æ —á–∏—Å—Ç–∏—Ç—å –±–µ–∑ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π

**Performance:**

- ‚úÖ Reanalyze 10-–º–∏–Ω—É—Ç–Ω–æ–≥–æ –≤–∏–¥–µ–æ < 60 —Å–µ–∫—É–Ω–¥
- ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ—Ç overhead (< 10ms)

---

**End of Phase 14.3 Plan (REVISED)**  
**Estimated Duration:** 1-2 weeks  
**Critical Path:** MediaService.reprocess_document() + Template Injection
