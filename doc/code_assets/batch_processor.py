"""–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–∞–∫–µ—Ç–Ω—ã—Ö –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ Google Batch API.

–§—É–Ω–∫—Ü–∏–∏:
    submit_pending_batches(db) -> int
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç PENDING –∑–∞–¥–∞—á–∏ –≤ Google Batch API.
    poll_active_batches(db) -> int
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å—ã –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.
    retrieve_completed_batches(db) -> int
        –°–∫–∞—á–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.
"""

import base64
import json
import logging
import os
import tempfile
from pathlib import Path

import google.genai as genai
from google.genai import types

from config import GEMINI_API_KEY, get_batch_model

logger = logging.getLogger("gemini-media-mcp.worker.batch_processor")

ENABLE_BATCH_API = os.getenv("ENABLE_BATCH_API", "true").lower() == "true"

client = None
if ENABLE_BATCH_API:
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        logger.info("‚úÖ Google Batch API client –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Google Batch API client: {e}")
        logger.warning("‚ö†Ô∏è –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –≤ MOCK —Ä–µ–∂–∏–º")
        ENABLE_BATCH_API = False
        client = None
else:
    logger.info("‚ÑπÔ∏è ENABLE_BATCH_API=false ‚Üí MOCK —Ä–µ–∂–∏–º")


def submit_pending_batches(db) -> int:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç PENDING –∑–∞–¥–∞—á–∏ –≤ Google Batch API.

    Args:
        db: DatabaseManager instance.

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.
    """
    pending_batches = db.get_pending_batches()

    batch_mode_batches = []
    for batch in pending_batches:
        all_batch_tasks = db.get_tasks_by_batch(batch["id"])
        tasks_in_batch = [t for t in all_batch_tasks if t.get("status") == "PENDING"]

        if not tasks_in_batch:
            logger.warning(f"‚ö†Ô∏è Batch {batch['id']} –Ω–µ –∏–º–µ–µ—Ç PENDING –∑–∞–¥–∞—á, –ø—Ä–æ–ø—É—Å–∫")
            continue

        first_task = tasks_in_batch[0]
        op_type = db.get_operation_type(first_task["operation_type"])

        if op_type["execution_mode"] == "batch":
            batch_mode_batches.append({"batch": batch, "tasks": tasks_in_batch})

    submitted_count = 0

    for item in batch_mode_batches:
        batch = item["batch"]
        tasks = item["tasks"]
        batch_id = batch["id"]

        logger.info(f"üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ batch {batch_id} —Å {len(tasks)} –∑–∞–¥–∞—á–∞–º–∏")

        try:
            if not ENABLE_BATCH_API:
                fake_google_id = f"batches/mock_{batch_id[:8]}"
                logger.info(f"üß™ [MOCK] –°–æ–∑–¥–∞–Ω batch: {fake_google_id}")

                db.update_batch_status(batch_id, "SUBMITTED", fake_google_id)

                for task in tasks:
                    db.update_task_status(task["id"], "SUBMITTED")

                submitted_count += 1
            else:
                tasks.sort(key=lambda t: (t["created_at"], t["id"]))

                jsonl_lines = []
                for task in tasks:
                    input_payload = task.get("input_payload", {})

                    if isinstance(input_payload, str):
                        input_payload = json.loads(input_payload)

                    prompt = input_payload.get("prompt", "")

                    request_obj = {
                        "key": task["id"],
                        "request": {
                            "contents": [{"parts": [{"text": prompt}], "role": "user"}],
                            "generation_config": {
                                "responseModalities": ["TEXT", "IMAGE"]
                            },
                        },
                    }
                    jsonl_lines.append(json.dumps(request_obj))

                # –ó–∞–ø–∏—Å–∞—Ç—å JSONL –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ File API
                jsonl_content = "\n".join(jsonl_lines)

                with tempfile.NamedTemporaryFile(
                    mode="w", suffix=".jsonl", delete=False, encoding="utf-8"
                ) as f:
                    f.write(jsonl_content)
                    temp_file_path = f.name

                try:
                    # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –≤ Google File API
                    uploaded_file = client.files.upload(
                        file=temp_file_path,
                        config=types.UploadFileConfig(
                            display_name=f"batch-{batch_id[:8]}",
                            mime_type="application/jsonl",
                        ),
                    )
                    logger.info(f"üì§ Uploaded JSONL: {uploaded_file.name}")

                    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ operation_type
                    operation_type = tasks[0]["operation_type"]
                    first_payload = tasks[0].get("input_payload", {})
                    if isinstance(first_payload, str):
                        first_payload = json.loads(first_payload)
                    model = get_batch_model(operation_type, first_payload)

                    logger.info(
                        f"Selected model: {model} (operation: {operation_type})"
                    )

                    # –í—ã–∑—ã–≤–∞–µ–º Batch API —Å file-based source
                    result = client.batches.create(
                        model=model,
                        src=uploaded_file.name,
                        config={"display_name": f"batch-{batch_id[:8]}"},
                    )

                    google_batch_id = result.name  # "batches/abc123xyz..."
                    logger.info(f"Batch submitted: {google_batch_id}")

                    # –£–¥–∞–ª–∏—Ç—å –≤—Ö–æ–¥–Ω–æ–π JSONL —Ñ–∞–π–ª –∏–∑ Google Cloud
                    # (—Ñ–∞–π–ª—ã —Ö—Ä–∞–Ω—è—Ç—Å—è 48—á –∏ –∑–∞–Ω–∏–º–∞—é—Ç –∫–≤–æ—Ç—É 20GB –Ω–∞ –ø—Ä–æ–µ–∫—Ç)
                    try:
                        client.files.delete(name=uploaded_file.name)
                        logger.debug(f"Deleted input file: {uploaded_file.name}")
                    except Exception as e:
                        logger.warning(
                            f"Failed to delete input file {uploaded_file.name}: {e}"
                        )

                    # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –ø–∞–∫–µ—Ç–∞
                    db.update_batch_status(batch_id, "SUBMITTED", google_batch_id)

                    # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å—ã –≤—Å–µ—Ö –∑–∞–¥–∞—á –≤ –ø–∞–∫–µ—Ç–µ
                    for task in tasks:
                        db.update_task_status(task["id"], "SUBMITTED")

                    submitted_count += 1

                finally:
                    # –£–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    try:
                        os.unlink(temp_file_path)
                    except Exception:
                        pass

        except Exception as e:
            logger.error(f"‚ùå Failed to submit batch {batch_id}: {e}")
            # –ü–æ–º–µ—Ç–∏—Ç—å –ø–∞–∫–µ—Ç –∫–∞–∫ FAILED (error message –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω –≤—ã—à–µ)
            db.update_batch_status(batch_id, "FAILED")

    logger.info(f"Submitted {submitted_count}/{len(batch_mode_batches)} batches")
    return submitted_count


def poll_active_batches(db) -> int:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å—ã –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –≤ Google Batch API.

    Args:
        db: DatabaseManager instance.

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤.
    """
    batches = db.get_pending_batches()
    active_batches = [
        b
        for b in batches
        if b.get("google_batch_id") and b["status"] in ["SUBMITTED", "PROCESSING"]
    ]

    if not active_batches:
        return 0

    logger.info(f"üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ {len(active_batches)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤")

    STATUS_MAP = {
        "JOB_STATE_PENDING": "SUBMITTED",
        "JOB_STATE_RUNNING": "PROCESSING",
        "JOB_STATE_SUCCEEDED": "COMPLETED",
        "JOB_STATE_FAILED": "FAILED",
        "JOB_STATE_CANCELLED": "FAILED",
        "STATE_UNSPECIFIED": "SUBMITTED",
    }

    processed_count = 0

    for batch in active_batches:
        batch_id = batch["id"]
        google_batch_id = batch["google_batch_id"]
        current_status = batch["status"]

        try:
            # 3. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å
            new_status = None

            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: Mock ID (–∏–∑ Step 1)
            if google_batch_id.startswith("batches/mock_"):
                # Mock —Ä–µ–∂–∏–º: —ç–º—É–ª–∏—Ä—É–µ–º –±—ã—Å—Ç—Ä–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
                if not ENABLE_BATCH_API:
                    # –ü–µ—Ä–µ—Ö–æ–¥: SUBMITTED ‚Üí PROCESSING ‚Üí COMPLETED
                    if current_status == "SUBMITTED":
                        new_status = "PROCESSING"
                    elif current_status == "PROCESSING":
                        new_status = "COMPLETED"

                    logger.debug(
                        f"üß™ [MOCK] Batch {batch_id[:8]} emulated: {current_status} ‚Üí {new_status}"
                    )
                else:
                    # –ï—Å–ª–∏ ENABLE_BATCH_API=true, –Ω–æ ID mock ‚Üí –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                    logger.warning(
                        f"‚ö†Ô∏è Batch {batch_id[:8]} has mock ID but ENABLE_BATCH_API=true. "
                        f"Skipping (inconsistent state)"
                    )
                    continue

            # Real API —Ä–µ–∂–∏–º
            elif ENABLE_BATCH_API and client:
                # –ó–∞–ø—Ä–æ—Å –∫ Google Batch API
                google_batch = client.batches.get(name=google_batch_id)

                # –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä: "JOB_STATE_RUNNING")
                google_state = google_batch.state

                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –Ω–∞—à —Å—Ç–∞—Ç—É—Å
                new_status = STATUS_MAP.get(google_state, "SUBMITTED")

                logger.debug(
                    f"üì° Batch {batch_id[:8]}: Google state={google_state} ‚Üí DB status={new_status}"
                )

            else:
                # ENABLE_BATCH_API=false –∏ –Ω–µ mock ID ‚Üí –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                logger.warning(
                    f"‚ö†Ô∏è Batch {batch_id[:8]} has real ID but ENABLE_BATCH_API=false. "
                    f"Cannot poll without API access"
                )
                continue

            # 4. –û–±–Ω–æ–≤–∏—Ç—å –ë–î —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–∏–ª—Å—è (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
            if new_status and new_status != current_status:
                db.update_batch_status(batch_id, new_status)
                logger.info(
                    f"‚úÖ Batch {batch_id[:8]} status updated: {current_status} ‚Üí {new_status}"
                )
            elif new_status == current_status:
                logger.debug(
                    f"‚è∏Ô∏è Batch {batch_id[:8]} status unchanged: {current_status}"
                )

            processed_count += 1

        except Exception as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫: 404, rate limits, network issues
            logger.error(f"‚ùå Failed to poll batch {batch_id[:8]}: {e}")

            # –ù–ï –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ FAILED –ø—Ä–∏ –æ—à–∏–±–∫–µ polling
            # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ (—Å–µ—Ç—å, rate limit)
            # –ü–æ–≤—Ç–æ—Ä–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ü–∏–∫–ª–µ

            # –û–¥–Ω–∞–∫–æ –µ—Å–ª–∏ —ç—Ç–æ 404 NOT_FOUND, –º–æ–∂–Ω–æ –ø–æ–º–µ—Ç–∏—Ç—å –∫–∞–∫ FAILED
            error_str = str(e).lower()
            if "404" in error_str or "not found" in error_str:
                logger.warning(
                    f"‚ö†Ô∏è Batch {batch_id[:8]} not found in Google API. "
                    f"Possible causes: expired, deleted, or invalid ID"
                )
                # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –º–æ–∂–Ω–æ –ø–æ–º–µ—Ç–∏—Ç—å –∫–∞–∫ FAILED –ø–æ—Å–ª–µ N –ø–æ–ø—ã—Ç–æ–∫
                # –ù–æ –¥–ª—è MVP –æ—Å—Ç–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—É—â–µ–º —Å—Ç–∞—Ç—É—Å–µ –¥–ª—è retry

    logger.info(
        f"üìä Polling complete: {processed_count}/{len(active_batches)} batches processed"
    )
    return processed_count


def retrieve_completed_batches(db) -> int:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã COMPLETED –ø–∞–∫–µ—Ç–æ–≤.

    Args:
        db: DatabaseManager instance.

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π.
    """
    all_batches = db.get_pending_batches()

    try:
        completed_status_batches = db._batches.get_by_status("COMPLETED")
        all_batches.extend(completed_status_batches)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—Ä–æ—Å–∏—Ç—å COMPLETED –±–∞—Ç—á–∏: {e}")

    completed_batches = [
        b
        for b in all_batches
        if b["status"] == "COMPLETED" and b.get("google_batch_id")
    ]

    if not completed_batches:
        return 0

    logger.info(
        f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ {len(completed_batches)} –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤"
    )

    processed_count = 0

    for batch in completed_batches:
        batch_id = batch["id"]
        google_batch_id = batch["google_batch_id"]

        try:
            # 2. Mock —Ä–µ–∂–∏–º: —ç–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if google_batch_id.startswith("batches/mock_"):
                if not ENABLE_BATCH_API:
                    # –ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –±–∞—Ç—á–∞ –≤ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
                    tasks = db.get_tasks_by_batch(batch_id)
                    tasks.sort(key=lambda t: (t["created_at"], t["id"]))

                    logger.info(
                        f"üß™ [MOCK] Processing batch {batch_id[:8]} with {len(tasks)} tasks"
                    )

                    # –≠–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
                    for task in tasks:
                        # Mock: —Å–æ–∑–¥–∞—Ç—å —Ñ–µ–π–∫–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (1x1 –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π PNG)
                        mock_png_base64 = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg=="

                        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å —à–∞—Ä–¥–∏–Ω–≥–æ–º
                        local_path = _save_image(
                            batch_id,
                            task["id"],
                            mock_png_base64,
                            task.get("target_path"),
                        )

                        # –û–±–Ω–æ–≤–∏—Ç—å –ë–î
                        db.update_task_completed(task["id"], local_path=local_path)
                        logger.debug(
                            f"‚úÖ [MOCK] Task {task['id'][:8]} completed: {local_path}"
                        )

                    # –ó–∞–∫—Ä—ã—Ç—å –±–∞—Ç—á
                    db.update_batch_completed(batch_id)
                    logger.info(f"‚úÖ [MOCK] Batch {batch_id[:8]} completed")
                    processed_count += 1
                    continue
                else:
                    # –†–µ–∂–∏–º –¥–ª—è —Ç–µ—Å—Ç–æ–≤: mock ID –Ω–æ ENABLE_BATCH_API=true
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Real API path —Å mock client (–ø–∞—Ç—á–µ–Ω–Ω—ã–π –≤ —Ç–µ—Å—Ç–∞—Ö)
                    pass  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤–Ω–∏–∑ –∫ Real API —Ä–µ–∂–∏–º—É

            # 3. Real API —Ä–µ–∂–∏–º (file-based)
            if not ENABLE_BATCH_API or not client:
                logger.warning(
                    f"Batch {batch_id[:8]} has real ID but ENABLE_BATCH_API=false"
                )
                continue

            # –ü–æ–ª—É—á–∏—Ç—å –æ–±—ä–µ–∫—Ç –±–∞—Ç—á–∞ –∏–∑ Google
            google_batch = client.batches.get(name=google_batch_id)

            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –±–∞—Ç—á–∞ (state –º–æ–∂–µ—Ç –±—ã—Ç—å enum –∏–ª–∏ string)
            batch_state = google_batch.state
            batch_state_str = str(batch_state)
            if "SUCCEEDED" not in batch_state_str:
                logger.warning(
                    f"Batch {batch_id[:8]} not ready yet. State: {batch_state}"
                )
                continue

            # File-based —Ä–µ–∂–∏–º: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ dest.file_name (JSONL —Ñ–∞–π–ª)
            dest = getattr(google_batch, "dest", None)
            if dest is None:
                logger.error(
                    f"Batch {batch_id[:8]} has no dest attribute. Cannot retrieve results."
                )
                continue

            output_file = getattr(dest, "file_name", None)
            if not output_file:
                # –ü–æ–ø—Ä–æ–±—É–µ–º inlined_responses –∫–∞–∫ fallback
                inlined = getattr(dest, "inlined_responses", None)
                if inlined:
                    logger.warning(
                        f"Batch {batch_id[:8]} has inlined_responses but we expected file_name. "
                        f"This shouldn't happen with file-based submission."
                    )
                logger.error(
                    f"Batch {batch_id[:8]} has no file_name in dest. Attrs: {dir(dest)}"
                )
                continue

            logger.info(f"Downloading results from: {output_file}")

            # –°–∫–∞—á–∞—Ç—å JSONL —Ñ–∞–π–ª —á–µ—Ä–µ–∑ Files API
            try:
                file_content_bytes = client.files.download(file=output_file)
                file_content = file_content_bytes.decode("utf-8")
            except Exception as e:
                logger.error(
                    f"Failed to download results file for batch {batch_id[:8]}: {e}"
                )
                continue

            # –ü–∞—Ä—Å–∏—Ç—å JSONL ‚Äî –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç {"key": "task_id", "response": {...}}
            # –∏–ª–∏ {"key": "task_id", "error": {...}}
            results_by_key = {}
            for line in file_content.strip().split("\n"):
                if not line.strip():
                    continue
                try:
                    parsed = json.loads(line)
                    key = parsed.get("key")
                    if key:
                        results_by_key[key] = parsed
                    else:
                        logger.warning(f"Result line without key: {line[:100]}")
                except json.JSONDecodeError as e:
                    logger.warning(f"Invalid JSON in result line: {e}")

            logger.info(
                f"Parsed {len(results_by_key)} results for batch {batch_id[:8]}"
            )

            # –ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –±–∞—Ç—á–∞
            tasks = db.get_tasks_by_batch(batch_id)

            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É –ø–æ –µ—ë key (task_id)
            success_count = 0
            fail_count = 0

            for task in tasks:
                task_id = task["id"]
                result = results_by_key.get(task_id)

                if not result:
                    logger.warning(f"No result found for task {task_id[:8]}")
                    db.update_task_failed(task_id, error="No result in batch response")
                    fail_count += 1
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫—É –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
                if "error" in result:
                    error_msg = result["error"].get("message", str(result["error"]))
                    logger.warning(f"Task {task_id[:8]} failed: {error_msg}")
                    db.update_task_failed(task_id, error=error_msg)
                    fail_count += 1
                elif "response" in result:
                    # –£—Å–ø–µ—Ö: –∏–∑–≤–ª–µ—á—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    try:
                        base64_data = _extract_image_data_from_dict(result["response"])
                        local_path = _save_image(
                            batch_id, task_id, base64_data, task.get("target_path")
                        )
                        db.update_task_completed(task_id, local_path=local_path)
                        logger.debug(f"Task {task_id[:8]} completed: {local_path}")
                        success_count += 1
                    except Exception as e:
                        logger.error(f"Failed to save task {task_id[:8]}: {e}")
                        db.update_task_failed(task_id, error=f"Save error: {e}")
                        fail_count += 1
                else:
                    logger.warning(f"Task {task_id[:8]} has no response or error")
                    db.update_task_failed(task_id, error="Empty result")
                    fail_count += 1

            # –ó–∞–∫—Ä—ã—Ç—å –±–∞—Ç—á
            db.update_batch_completed(batch_id)
            logger.info(
                f"Batch {batch_id[:8]} completed: {success_count} success, {fail_count} failed"
            )
            processed_count += 1

        except Exception as e:
            logger.error(f"Failed to retrieve batch {batch_id[:8]}: {e}")
            # –ù–ï –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ FAILED –ø—Ä–∏ –æ—à–∏–±–∫–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å transient)
            # –ü–æ–≤—Ç–æ—Ä–∏–º –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ü–∏–∫–ª–µ

    logger.info(
        f"Retrieval complete: {processed_count}/{len(completed_batches)} batches processed"
    )
    return processed_count


def _extract_image_data_from_dict(response: dict) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç base64 –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ Google Batch API.

    Args:
        response: Dict —Å –æ—Ç–≤–µ—Ç–æ–º –∏–∑ JSONL —Ñ–∞–π–ª–∞.

    Returns:
        Base64 —Å—Ç—Ä–æ–∫–∞.

    Raises:
        ValueError: –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –æ—Ç–≤–µ—Ç–µ.
    """
    try:
        candidate = response["candidates"][0]
        parts = candidate["content"]["parts"]

        for part in parts:
            inline_data = part.get("inlineData") or part.get("inline_data")
            if inline_data:
                data = inline_data.get("data")
                if data:
                    return data

        raise ValueError("No image data found in any part")

    except (KeyError, IndexError, TypeError) as e:
        raise ValueError(f"Failed to extract image data from response: {e}")


def _save_image(
    batch_id: str, task_id: str, base64_data: str, target_path: str = None
) -> str:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ base64 —Å —Ñ–∞–π–ª–æ–≤—ã–º —à–∞—Ä–¥–∏–Ω–≥–æ–º.

    Args:
        batch_id: UUID –±–∞—Ç—á–∞.
        task_id: UUID –∑–∞–¥–∞—á–∏.
        base64_data: Base64 —Å—Ç—Ä–æ–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        target_path: –ü—É—Ç—å –∏–∑ –∑–∞–¥–∞—á–∏.

    Returns:
        –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É.

    Raises:
        IOError: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª.
    """
    image_bytes = base64.b64decode(base64_data)
    if target_path:
        try:
            local_path = Path(target_path)
            local_path.parent.mkdir(parents=True, exist_ok=True)

            with open(local_path, "wb") as f:
                f.write(image_bytes)

            logger.debug(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ target_path: {local_path}")
            return str(local_path.absolute())
        except (IOError, OSError) as e:
            logger.warning(
                f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ {target_path}: {e}. –ò—Å–ø–æ–ª—å–∑—É—é fallback."
            )

    output_dir = Path("media") / "generated" / batch_id
    output_dir.mkdir(parents=True, exist_ok=True)

    local_path = output_dir / f"{task_id}.png"

    with open(local_path, "wb") as f:
        f.write(image_bytes)

    logger.debug(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ fallback: {local_path}")
    return str(local_path.absolute())
