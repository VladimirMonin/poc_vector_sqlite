"""–ö–ª–∏–µ–Ω—Ç Google Gemini API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç–∞.

–ö–ª–∞—Å—Å—ã:
    GeminiClient
        –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Gemini API.

        –ú–µ—Ç–æ–¥—ã:
            generate_content(prompt: str, ...) -> str
                –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å –º–µ–¥–∏–∞.
            generate_text(prompt: str) -> str
                –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–æ–º–ø—Ç—É.
            generate_content_multi_image(prompt: str, images: Sequence) -> str
                –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
"""

import json
from typing import Optional, Union, List, Sequence

from PIL import Image
from google.genai import types, Client

from config import GEMINI_API_KEY, DEFAULT_GEMINI_MODEL
from models.analysis import ImageAnalysisResponse, ErrorResponse
from utils.logger import get_logger

logger = get_logger(__name__)


class GeminiClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini API.

    Attributes:
        model_name: –ò–º—è –º–æ–¥–µ–ª–∏ Gemini.
        client: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Google Gemini API.
    """

    def __init__(self, model_name: str = DEFAULT_GEMINI_MODEL):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç Gemini."""
        self.model_name = model_name
        self.client = Client(api_key=GEMINI_API_KEY)
        logger.info(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω GeminiClient: {model_name}")

    def generate_content(
        self,
        prompt: str,
        image_path: Optional[str] = None,
        media_bytes: Optional[bytes] = None,
        mime_type: Optional[str] = None,
        system_instruction: Optional[str] = None,
        response_schema=None,
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å –º–µ–¥–∏–∞ —á–µ—Ä–µ–∑ Gemini API.

        Args:
            prompt: –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç.
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
            media_bytes: –ú–µ–¥–∏–∞-–¥–∞–Ω–Ω—ã–µ –≤ –±–∞–π—Ç–∞—Ö.
            mime_type: MIME-—Ç–∏–ø –º–µ–¥–∏–∞.
            system_instruction: –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.
            response_schema: Pydantic –º–æ–¥–µ–ª—å –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.

        Returns:
            –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏.
        """
        try:
            media_part = None
            if image_path:
                media_part = Image.open(image_path)
                logger.debug(f"Loaded image: {image_path}")
            elif media_bytes and mime_type:
                media_part = types.Part.from_bytes(
                    data=media_bytes, mime_type=mime_type
                )
                logger.debug(f"Loaded media bytes with MIME type: {mime_type}")

            contents = [prompt, media_part] if media_part else [prompt]

            config_params = {
                "temperature": 0.7,
                "max_output_tokens": 4096,
                "safety_settings": [
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                ],
            }

            if system_instruction:
                config_params["system_instruction"] = system_instruction
            if response_schema:
                config_params["response_mime_type"] = "application/json"
                # Pass Pydantic model directly - library handles conversion
                config_params["response_schema"] = response_schema

            config = types.GenerateContentConfig(**config_params)

            logger.info("üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤ Gemini")
            response = self.client.models.generate_content(
                model=self.model_name, contents=contents, config=config
            )

            if hasattr(response, "text"):
                return response.text or ""

            if hasattr(response, "prompt_feedback") and response.prompt_feedback:
                feedback = response.prompt_feedback
                if hasattr(feedback, "block_reason") and feedback.block_reason:
                    logger.warning(f"‚ö†Ô∏è –ó–∞–ø—Ä–æ—Å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω: {feedback.block_reason}")
                    raise ValueError(
                        f"Request blocked by safety filters: {feedback.block_reason}"
                    )

            raise ValueError("Failed to get a valid response from Gemini model.")

        except Exception as e:
            logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            raise

    def generate_text(self, prompt: str, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞."""
        logger.debug(f"Generating text for prompt: {prompt[:50]}...")
        response = self.client.models.generate_content(
            model=self.model_name, contents=prompt, **kwargs
        )
        return response.text or ""

    def generate_content_multi_image(
        self,
        prompt: str,
        images: Sequence[Union[str, Image.Image, types.Part]],
        system_instruction: Optional[str] = None,
        response_schema=None,
        temperature: float = 0.7,
        max_output_tokens: int = 4096,
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.

        Args:
            prompt: –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
            images: –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø—É—Ç–∏, PIL Image –∏–ª–∏ types.Part).
            system_instruction: –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.
            response_schema: Pydantic –º–æ–¥–µ–ª—å –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0-2.0).
            max_output_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ.

        Returns:
            –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏.
        """
        try:
            # Convert all images to appropriate format
            content_parts = [prompt]

            for i, img in enumerate(images):
                if isinstance(img, str):
                    # File path - load as PIL Image
                    pil_img = Image.open(img)
                    content_parts.append(pil_img)
                    logger.debug(f"Image {i + 1}: Loaded from path {img}")

                elif isinstance(img, Image.Image):
                    # Already PIL Image
                    content_parts.append(img)
                    logger.debug(f"Image {i + 1}: PIL Image {img.size}")

                elif isinstance(img, types.Part):
                    # File API reference
                    content_parts.append(img)
                    logger.debug(f"Image {i + 1}: File API Part")

                else:
                    raise ValueError(f"Unsupported image type: {type(img)}")

            # Configure request
            config_params = {
                "temperature": temperature,
                "max_output_tokens": max_output_tokens,
                "safety_settings": [
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
                    ),
                ],
            }

            if system_instruction:
                config_params["system_instruction"] = system_instruction
            if response_schema:
                config_params["response_mime_type"] = "application/json"
                config_params["response_schema"] = response_schema

            config = types.GenerateContentConfig(**config_params)

            logger.info(f"üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ Gemini ({self.model_name})")
            response = self.client.models.generate_content(
                model=self.model_name, contents=content_parts, config=config
            )

            if hasattr(response, "text"):
                return response.text or ""

            if hasattr(response, "prompt_feedback") and response.prompt_feedback:
                feedback = response.prompt_feedback
                if hasattr(feedback, "block_reason") and feedback.block_reason:
                    logger.warning(f"‚ö†Ô∏è –ó–∞–ø—Ä–æ—Å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω: {feedback.block_reason}")
                    raise ValueError(
                        f"Request blocked by safety filters: {feedback.block_reason}"
                    )

            raise ValueError("Failed to get a valid response from Gemini model.")

        except Exception as e:
            logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {e}")
            raise
