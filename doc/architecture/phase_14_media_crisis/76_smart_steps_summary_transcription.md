# 76. Smart Steps Implementation: Summary & Transcription

> **Commits:** `f38bbdd`, `1441594`  
> **–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ (Phase 14.1.1)  
> **–î–∞—Ç–∞:** 06.12.2025

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö —à–∞–≥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç–∞: `SummaryStep` –∏ `TranscriptionStep`. –≠—Ç–∏ —à–∞–≥–∏ –∑–∞–º–µ–Ω—è—é—Ç –º–æ–Ω–æ–ª–∏—Ç–Ω—É—é –ª–æ–≥–∏–∫—É `_build_content_from_analysis()` –∏ `_split_transcription_into_chunks()` –∏–∑ legacy `pipeline.py`.

---

## üìå –ß—Ç–æ —ç—Ç–æ —Ç–∞–∫–æ–µ?

**SummaryStep** –∏ **TranscriptionStep** ‚Äî –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ `BaseProcessingStep`, –∫–æ—Ç–æ—Ä—ã–µ –∏–∑–≤–ª–µ–∫–∞—é—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏–∞ (analysis dict –æ—Ç Gemini API).

**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**

- üéØ **Focused Responsibility**: –∫–∞–∂–¥—ã–π —à–∞–≥ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ–¥–Ω—É –æ–ø–µ—Ä–∞—Ü–∏—é
- üîß **Constructor Injection**: –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (splitter) –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä
- üìä **Conditional Execution**: `should_run()` –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- üîí **Immutability**: —Ä–∞–±–æ—Ç–∞ —á–µ—Ä–µ–∑ `MediaContext.with_chunks()`

---

## üéØ –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ?

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–æ–Ω–æ–ª–∏—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤ `pipeline.py`

**Legacy –∫–æ–¥** (Phase 14.0):

```python
def _build_content_from_analysis(self, result: dict) -> str:
    """60 —Å—Ç—Ä–æ–∫ —Å–º–µ—à–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–∏ –¥–ª—è summary, transcript, OCR."""
    media_type = result.get("type", "unknown")
    
    if media_type == "image":
        return result.get("description", "")
    elif media_type == "audio":
        # –¢–æ–ª—å–∫–æ description, transcription –±—É–¥–µ—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —á–∞–Ω–∫–∞—Ö
        return result.get("description", "")
    # ... –µ—â–µ 40 —Å—Ç—Ä–æ–∫
```

**–ü—Ä–æ–±–ª–µ–º—ã:**

1. ‚ùå **–°–º–µ—à–∞–Ω–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å**: summary + transcript + OCR –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ
2. ‚ùå **–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å**: —Ö–∞—Ä–¥–∫–æ–¥ –ª–æ–≥–∏–∫–∏
3. ‚ùå **–ù–µ—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏**: –º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Å–ª–æ–∂–Ω–æ –º–æ–∫–∞—Ç—å
4. ‚ùå **–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ**: `_split_transcription_into_chunks()` –∏ `_split_ocr_into_chunks()` –ø–æ—á—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã (48 vs 35 —Å—Ç—Ä–æ–∫)

### –†–µ—à–µ–Ω–∏–µ: –ú–æ–¥—É–ª—å–Ω—ã–µ —à–∞–≥–∏

```mermaid
graph LR
    A[MediaContext] --> B[SummaryStep]
    B --> C[TranscriptionStep]
    C --> D[Updated Context]
    
    style B fill:#a8d5ba
    style C fill:#a8d5ba
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**

‚úÖ **–ò–∑–æ–ª—è—Ü–∏—è –ª–æ–≥–∏–∫–∏**: –∫–∞–∂–¥—ã–π —à–∞–≥ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å  
‚úÖ **–ì–∏–±–∫–æ—Å—Ç—å**: –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å  
‚úÖ **–¢–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å**: unit-—Ç–µ—Å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞  
‚úÖ **–ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: splitter –∏–Ω–∂–µ–∫—Ç–∏—Ç—Å—è —á–µ—Ä–µ–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä

---

## üîç –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?

### 1. SummaryStep ‚Äî –°–æ–∑–¥–∞–Ω–∏–µ summary chunk

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**

- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ `description` –∏–∑ analysis
- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ metadata (keywords, alt_text, participants)
- –°–æ–∑–¥–∞–Ω–∏–µ single chunk —Å `role='summary'`

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**

```python
step = SummaryStep(include_keywords=True)
```

**–¢–∏–ø—ã –º–µ–¥–∏–∞ –∏ ChunkType:**

| Media Type | ChunkType     | Metadata Keys                          |
|------------|---------------|----------------------------------------|
| `image`    | `IMAGE_REF`   | `_vision_alt`, `_vision_keywords`, `_vision_ocr` |
| `audio`    | `AUDIO_REF`   | `_audio_description`, `_audio_keywords`, `_audio_participants`, `_audio_action_items` |
| `video`    | `VIDEO_REF`   | `_video_keywords`, `_video_duration`   |

**–ü–æ—á–µ–º—É –ù–ï –≤–∫–ª—é—á–∞–µ–º transcription –≤ summary?**

> Summary chunk –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—ã–º (< 2k tokens). –ü–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∏–¥—ë—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞–Ω–∫–∏ —á–µ—Ä–µ–∑ `TranscriptionStep`.

---

### 2. TranscriptionStep ‚Äî –†–∞–∑–±–∏–≤–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**

- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è `transcription` –≤ analysis
- –†–∞–∑–±–∏–≤–∫–∞ —á–µ—Ä–µ–∑ `BaseSplitter` (–æ–±—ã—á–Ω–æ SmartSplitter)
- –û–±–æ–≥–∞—â–µ–Ω–∏–µ metadata: `role='transcript'`, `parent_media_path`

**Constructor Injection:**

```python
from semantic_core.processing.splitters.smart import SmartSplitter

splitter = SmartSplitter(...)
step = TranscriptionStep(splitter=splitter)
```

**–õ–æ–≥–∏–∫–∞ should_run():**

```python
def should_run(self, context: MediaContext) -> bool:
    """–ó–∞–ø—É—Å–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å transcription –≤ analysis."""
    return bool(context.analysis.get("transcription"))
```

**–ó–∞—á–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∞?**

> –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –∏–º–µ—é—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ‚Äî —à–∞–≥ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –≠—Ç–æ —ç–∫–æ–Ω–æ–º–∏—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –∏–∑–±–µ–≥–∞–µ—Ç –æ—à–∏–±–æ–∫.

---

## üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### SummaryStep ‚Äî 14 unit-—Ç–µ—Å—Ç–æ–≤

**Test classes:**

1. **TestSummaryStepBasic** (3 —Ç–µ—Å—Ç–∞)
   - `test_step_name`: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏ —à–∞–≥–∞
   - `test_is_optional_false`: SummaryStep –∫—Ä–∏—Ç–∏—á–µ–Ω
   - `test_should_run_always_true`: –≤—Å–µ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è

2. **TestSummaryStepImage** (3 —Ç–µ—Å—Ç–∞)
   - `test_image_summary_with_keywords`: –ø–æ–ª–Ω—ã–µ metadata
   - `test_image_summary_without_keywords`: –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ keywords
   - `test_image_summary_missing_fields`: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –ø–æ–ª–µ–π

3. **TestSummaryStepAudio** (2 —Ç–µ—Å—Ç–∞)
   - `test_audio_summary_with_keywords`: participants, action_items, duration
   - `test_audio_summary_without_keywords`: —Ç–æ–ª—å–∫–æ description

4. **TestSummaryStepVideo** (2 —Ç–µ—Å—Ç–∞)
   - `test_video_summary_with_keywords`: keywords, duration
   - `test_video_summary_without_keywords`: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ metadata

5. **TestSummaryStepEdgeCases** (4 —Ç–µ—Å—Ç–∞)
   - `test_empty_description`: –ø—É—Å—Ç–æ–π description
   - `test_unknown_media_type`: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø ‚Üí ChunkType.TEXT
   - `test_base_index_increments_correctly`: –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
   - `test_context_immutability`: –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

```
14 passed in 0.08s
```

---

### TranscriptionStep ‚Äî 11 unit-—Ç–µ—Å—Ç–æ–≤

**Test classes:**

1. **TestTranscriptionStepShouldRun** (3 —Ç–µ—Å—Ç–∞)
   - `test_should_run_with_transcription`: –µ—Å—Ç—å transcription ‚Üí True
   - `test_should_run_without_transcription`: –Ω–µ—Ç transcription ‚Üí False
   - `test_should_run_with_empty_transcription`: –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Üí False

2. **TestTranscriptionStepBasic** (2 —Ç–µ—Å—Ç–∞)
   - `test_step_name`: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏
   - `test_is_optional_false`: –∫—Ä–∏—Ç–∏—á–Ω—ã–π —à–∞–≥

3. **TestTranscriptionStepProcessing** (4 —Ç–µ—Å—Ç–∞)
   - `test_single_chunk_transcription`: –∫–æ—Ä–æ—Ç–∫–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è ‚Üí 1 chunk
   - `test_multi_chunk_transcription`: –¥–ª–∏–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è ‚Üí 3 chunks, –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
   - `test_metadata_enrichment`: –ø—Ä–æ–≤–µ—Ä–∫–∞ `role='transcript'`, `parent_media_path`
   - `test_metadata_no_overwrite_original_path`: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö metadata

4. **TestTranscriptionStepEdgeCases** (2 —Ç–µ—Å—Ç–∞)
   - `test_context_immutability`: immutability —á–µ—Ä–µ–∑ frozen dataclass
   - `test_video_transcription`: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

```
11 passed in 0.09s
```

---

## ‚öôÔ∏è –î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### SummaryStep: include_keywords —Ñ–ª–∞–≥

**–ó–∞—á–µ–º –Ω—É–∂–µ–Ω?**

–î–ª—è **—ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞ –≤ –ë–î** –≤ production. Keywords –ø–æ–ª–µ–∑–Ω—ã –¥–ª—è search, –Ω–æ –∑–∞–Ω–∏–º–∞—é—Ç –º–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –≤ metadata.

**–ö–æ–≥–¥–∞ –æ—Ç–∫–ª—é—á–∞—Ç—å:**

```python
# Development: –≤–∫–ª—é—á–∞–µ–º –≤—Å—ë
step = SummaryStep(include_keywords=True)

# Production: —ç–∫–æ–Ω–æ–º–∏–º –º–µ—Å—Ç–æ
step = SummaryStep(include_keywords=False)
```

**–ß—Ç–æ —Ç–µ—Ä—è–µ–º –ø—Ä–∏ `include_keywords=False`:**

- `_vision_keywords` (image)
- `_audio_keywords` (audio)
- `_video_keywords` (video)

> **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞**: —Ö—Ä–∞–Ω–∏—Ç—å keywords –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ —Å foreign key.

---

### TranscriptionStep: Constructor Injection

**–ü–æ—á–µ–º—É –Ω–µ Service Locator?**

```python
# ‚ùå Service Locator (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ MediaContext)
context.get_service("splitter")

# ‚úÖ Constructor Injection (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ TranscriptionStep)
step = TranscriptionStep(splitter=my_splitter)
```

**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:**

1. **Splitter –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω**: TranscriptionStep –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –Ω–µ–≥–æ
2. **–Ø–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**: –≤–∏–¥–Ω—ã –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ
3. **–¢–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å**: –ª–µ–≥–∫–æ –º–æ–∫–∞—Ç—å —á–µ—Ä–µ–∑ `MagicMock()`

**Service Locator –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤:**

- User instructions processor
- Retry parsers
- Timecode extractors

---

## üîó –°–≤—è–∑—å —Å MediaPipeline

**–ö–∞–∫ —à–∞–≥–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è:**

```python
# MediaPipeline (–∏–∑ —Å—Ç–∞—Ç—å–∏ 75)
pipeline = MediaPipeline(steps=[
    SummaryStep(include_keywords=True),
    TranscriptionStep(splitter=smart_splitter),
])

context = MediaContext(
    media_path=Path("podcast.mp3"),
    document=doc,
    analysis=analysis,
    chunks=[],
    base_index=0,
)

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
chunks = pipeline.build_chunks(context)
```

**–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–∑–æ–≤–æ–≤:**

```mermaid
sequenceDiagram
    participant P as MediaPipeline
    participant S as SummaryStep
    participant T as TranscriptionStep
    participant C as MediaContext
    
    P->>S: should_run(context)?
    S-->>P: True
    P->>S: process(context)
    S->>C: with_chunks([summary])
    C-->>S: new_context (base_index=1)
    S-->>P: new_context
    
    P->>T: should_run(new_context)?
    T-->>P: True (–µ—Å—Ç—å transcription)
    P->>T: process(new_context)
    T->>C: with_chunks([chunk1, chunk2, chunk3])
    C-->>T: final_context (base_index=4)
    T-->>P: final_context
```

---

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –Ω—é–∞–Ω—Å—ã

### 1. Windows Path Compatibility

**–ü—Ä–æ–±–ª–µ–º–∞:**

```python
# –¢–µ—Å—Ç –Ω–∞ Linux/Mac
assert chunk.metadata["_original_path"] == "/data/audio.mp3"

# –†–µ–∞–ª—å–Ω–æ—Å—Ç—å –Ω–∞ Windows
# AssertionError: assert '\\data\\audio.mp3' == '/data/audio.mp3'
```

**–†–µ—à–µ–Ω–∏–µ:**

```python
# ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º Path –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
assert chunk.metadata["_original_path"] == str(Path("/data/audio.mp3"))
```

---

### 2. Metadata –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è

**–õ–æ–≥–∏–∫–∞ `_build_summary_metadata()` –∏ `process()`:**

```python
meta.setdefault("_original_path", str(context.media_path))
```

**–ó–∞—á–µ–º `setdefault`?**

–ï—Å–ª–∏ splitter —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–∏–ª `_original_path` (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ –∫–∞—Å—Ç–æ–º–Ω—É—é –ª–æ–≥–∏–∫—É), –º—ã –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º. –≠—Ç–æ –¥–∞—ë—Ç –≥–∏–±–∫–æ—Å—Ç—å –¥–ª—è advanced use cases.

---

### 3. base_index –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç `with_chunks()`:**

```python
def with_chunks(self, new_chunks: list[Chunk]) -> "MediaContext":
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —á–∞–Ω–∫–∞–º–∏."""
    return replace(
        self,
        chunks=self.chunks + new_chunks,
        base_index=self.base_index + len(new_chunks),
    )
```

**–ü—Ä–∏–º–µ—Ä:**

```python
context = MediaContext(..., base_index=0, chunks=[])

# SummaryStep –¥–æ–±–∞–≤–ª—è–µ—Ç 1 chunk
new_context = context.with_chunks([summary_chunk])
# new_context.base_index == 1

# TranscriptionStep –¥–æ–±–∞–≤–ª—è–µ—Ç 3 chunks
final_context = new_context.with_chunks([t1, t2, t3])
# final_context.base_index == 4
```

**–ò–Ω–¥–µ–∫—Å—ã —á–∞–Ω–∫–æ–≤:** 0, 1, 2, 3 (–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å).

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥

**Phase 14.1.1 –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è:** OCRStep —Å Markdown parsing –∏ code detection  
‚Üí [–°—Ç–∞—Ç—å—è 77: OCR Step](77_smart_step_ocr.md)



### 3.1 –ó–∞—á–µ–º –Ω—É–∂–µ–Ω OCRStep?

**–ü—Ä–æ–±–ª–µ–º–∞:** –í–∏–¥–µ–æ-—Å–∫—Ä–∏–Ω–∫–∞—Å—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–¥ –≤ frames ‚Üí OCR –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–º–µ—à–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (UI + code) ‚Üí –Ω—É–∂–Ω–æ –∏–∑–æ–ª–∏—Ä–æ–≤–∞—Ç—å code blocks.

**–ü—Ä–∏–º–µ—Ä OCR –∏–∑ –≤–∏–¥–µ–æ –ø–æ Python:**

```
# UI —Ç–µ–∫—Å—Ç
Welcome to Python Tutorial

# –ö–æ–¥ –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# UI —Ç–µ–∫—Å—Ç
Press Run to execute
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:** Code blocks –¥–æ–ª–∂–Ω—ã –ø–æ–ø–∞–¥–∞—Ç—å –≤ `ChunkType.CODE`, UI —Ç–µ–∫—Å—Ç ‚Äî –≤ `ChunkType.TEXT`.

### 3.2 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ OCRStep

```mermaid
graph TD
    A[MediaContext + analysis] --> B{should_run?}
    B -->|ocr_text exists| C[OCRStep.process]
    B -->|no ocr_text| D[Skip]
    
    C --> E[Create temp Document]
    E --> F{parser_mode?}
    F -->|markdown| G[SmartSplitter via MarkdownNodeParser]
    F -->|plain| H[SimpleSplitter]
    
    G --> I[Chunks with CODE/TEXT types]
    H --> J[Chunks with TEXT type]
    
    I --> K[Enrich metadata: role=ocr, parent_media_path]
    J --> K
    
    K --> L[Monitor code_ratio]
    L -->|> 50%| M[WARNING: false positives?]
    L -->|< 50%| N[OK]
    
    M --> O[Return new MediaContext]
    N --> O
```

**–ö–ª—é—á–µ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è:**

1. **Constructor Injection:** `splitter: BaseSplitter` –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è —Å–Ω–∞—Ä—É–∂–∏
2. **Configurable Parsing:** `parser_mode: Literal["markdown", "plain"]`
   - `"markdown"` ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `SmartSplitter` —Å `MarkdownNodeParser` (code detection)
   - `"plain"` ‚Üí –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥
3. **Code Ratio Monitoring:** –ø–æ–¥—Å—á—ë—Ç `ChunkType.CODE` —á–∞–Ω–∫–æ–≤ ‚Üí WARNING –µ—Å–ª–∏ > 50%
4. **MediaType.TEXT Bug Fix:** –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ `MediaType.MARKDOWN`

### 3.3 –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–°–∏–≥–Ω–∞—Ç—É—Ä–∞:**

```python
class OCRStep(BaseProcessingStep):
    def __init__(
        self,
        splitter: BaseSplitter,
        parser_mode: Literal["markdown", "plain"] = "markdown",
    ):
        self.splitter = splitter
        self.parser_mode = parser_mode
```

**–õ–æ–≥–∏–∫–∞ process():**

```mermaid
sequenceDiagram
    participant Ctx as MediaContext
    participant OCR as OCRStep
    participant Split as BaseSplitter
    participant Log as Logger
    
    Ctx->>OCR: process(context)
    OCR->>OCR: Extract ocr_text from analysis
    OCR->>OCR: Create temp Document (MediaType.TEXT)
    OCR->>Split: split(temp_doc)
    Split-->>OCR: List[Chunk]
    
    loop Each chunk
        OCR->>OCR: Update chunk_index
        OCR->>OCR: Enrich metadata (role, parent_media_path)
    end
    
    OCR->>OCR: Calculate code_ratio
    alt code_ratio > 0.5
        OCR->>Log: WARNING false positives?
    end
    
    OCR->>Ctx: with_chunks(ocr_chunks)
    Ctx-->>OCR: new MediaContext
```

**–û–±–æ–≥–∞—â–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö:**

```python
for idx, chunk in enumerate(split_chunks):
    meta = dict(chunk.metadata or {})
    meta.setdefault("_original_path", str(context.media_path))
    meta["role"] = "ocr"
    meta["parent_media_path"] = str(context.media_path)
    
    chunk.chunk_index = context.base_index + idx
    chunk.metadata = meta
```

**Code Ratio Monitoring:**

```python
code_chunks = sum(1 for c in ocr_chunks if c.chunk_type == ChunkType.CODE)
code_ratio = code_chunks / len(ocr_chunks) if ocr_chunks else 0

if code_ratio > 0.5:
    logger.warning(
        f"[{self.step_name}] High code ratio detected (might be false positives)",
        code_ratio=f"{code_ratio:.1%}",
        code_chunks=code_chunks,
        total_chunks=len(ocr_chunks),
        suggestion="Consider using parser_mode='plain' if OCR text is mostly UI",
    )
```

**–ó–∞—á–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥?** UI —Ç–µ–∫—Å—Ç –∏–∑ —Å–∫—Ä–∏–Ω–∫–∞—Å—Ç–æ–≤ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ `File > Open`, –∫–æ—Ç–æ—Ä—ã–µ `MarkdownNodeParser` —Å–ø—É—Ç–∞–µ—Ç —Å –∫–æ–¥–æ–º ‚Üí —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ `ChunkType.CODE` ‚Üí warning –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

### 3.4 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

**15 unit-—Ç–µ—Å—Ç–æ–≤** (5 –∫–ª–∞—Å—Å–æ–≤):

| –ö–ª–∞—Å—Å | –ö–æ–ª-–≤–æ | –ß—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è |
|-------|--------|-----------------|
| `TestOCRStepShouldRun` | 3 | –£—Å–ª–æ–≤–∏–µ –∑–∞–ø—É—Å–∫–∞ (with/without/empty ocr_text) |
| `TestOCRStepBasic` | 4 | –ò–º—è —à–∞–≥–∞, is_optional=False, parser_mode getters |
| `TestOCRStepProcessing` | 4 | Single/multi chunk, parser_mode –≤–ª–∏—è–µ—Ç –Ω–∞ –ø–∞—Ä—Å–∏–Ω–≥, metadata enrichment |
| `TestOCRStepCodeRatioMonitoring` | 2 | Low code_ratio (no warning), high code_ratio (WARNING logged) |
| `TestOCRStepEdgeCases` | 2 | Context immutability, metadata –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç _original_path |

**–ü—Ä–∏–º–µ—Ä —Ç–µ—Å—Ç–∞ code_ratio:**

```python
def test_high_code_ratio_triggers_warning(self):
    """High code_ratio (> 50%) ‚Üí WARNING –≤ –ª–æ–≥–∞—Ö."""
    # 3 CODE chunks –∏–∑ 5 ‚Üí 60% code_ratio
    mock_chunks = [
        Chunk(content="code1", chunk_type=ChunkType.CODE, ...),
        Chunk(content="code2", chunk_type=ChunkType.CODE, ...),
        Chunk(content="code3", chunk_type=ChunkType.CODE, ...),
        Chunk(content="text1", chunk_type=ChunkType.TEXT, ...),
        Chunk(content="text2", chunk_type=ChunkType.TEXT, ...),
    ]
    
    with patch("semantic_core.utils.logger.logger") as mock_logger:
        step.process(context)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–∑–æ–≤ warning
        mock_logger.warning.assert_called_once()
        args = mock_logger.warning.call_args
        assert "High code ratio detected" in args[0][0]
        assert args[1]["code_ratio"] == "60.0%"
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

```bash
$ pytest tests/unit/processing/steps/test_ocr_step.py -v
========== 15 passed in 0.09s ==========
```

### 3.5 MediaType.MARKDOWN Bug Fix

**–ü—Ä–æ–±–ª–µ–º–∞:** –ò–∑–Ω–∞—á–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞:

```python
# ‚ùå BROKEN
media_type = MediaType.MARKDOWN if self.parser_mode == "markdown" else MediaType.TEXT
```

**MediaType enum** (–∏–∑ `domain/document.py`):

```python
class MediaType(str, Enum):
    TEXT = "text"
    IMAGE = "image"
    VIDEO = "video"
    AUDIO = "audio"
    # ‚ùå MARKDOWN –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!
```

**–û—à–∏–±–∫–∞:**

```
AttributeError: type object 'MediaType' has no attribute 'MARKDOWN'
7/15 —Ç–µ—Å—Ç–æ–≤ –ø–∞–¥–∞–ª–∏
```

**–†–µ—à–µ–Ω–∏–µ:**

```python
# ‚úÖ CORRECT
media_type = MediaType.TEXT  # –í—Å–µ–≥–¥–∞ TEXT –¥–ª—è OCR
# parser_mode –≤–ª–∏—è–µ—Ç –Ω–∞ SmartSplitter, –∞ –Ω–µ –Ω–∞ Document.media_type
```

**–ü–æ—á–µ–º—É TEXT –ø—Ä–∞–≤–∏–ª—å–Ω–æ?** OCR –∏–∑–≤–ª–µ–∫–∞–µ—Ç **—Ç–µ–∫—Å—Ç** –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/–≤–∏–¥–µ–æ. Markdown ‚Äî —ç—Ç–æ —Ñ–æ—Ä–º–∞—Ç —Ä–∞–∑–º–µ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞, –Ω–æ –Ω–µ —Ç–∏–ø –º–µ–¥–∏–∞. `parser_mode` –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç, –∫–∞–∫ `SmartSplitter` –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç, –Ω–æ —Å–∞–º –¥–æ–∫—É–º–µ–Ω—Ç –≤—Å–µ–≥–¥–∞ `TEXT`.

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥

**Phase 14.1.2:** Advanced Features ‚Äî FrameDescriptionStep, TimecodeParser, user_instructions  
‚Üí [–ü–ª–∞–Ω—ã Phase 14.1](../../ideas/phase_14/phase_14.1.md)

**–°—Ç–∞—Ç—å—è 77 (–ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è):** OCR Step ‚Äî Markdown parsing, code detection, false positives monitoring
