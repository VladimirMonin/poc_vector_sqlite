# ‚úÇÔ∏è Smart Splitting Strategy

> **Phase 4, –°–µ—Ä–∏—è 2**: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏

---

## üéØ –ü—Ä–æ–±–ª–µ–º–∞: SimpleSplitter —Ä–µ–∂–µ—Ç "–≥–ª—É–ø–æ"

### –î–æ Phase 4: Naive –ø–æ–¥—Ö–æ–¥

**SimpleSplitter** —Ä–µ–∑–∞–ª —Ç–µ–∫—Å—Ç –ø–æ —Å–∏–º–≤–æ–ª–∞–º –±–µ–∑ —É—á—ë—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:

```python
def split_text(text: str, chunk_size: int) -> list[str]:
    chunks = []
    for i in range(0, len(text), chunk_size):
        chunks.append(text[i:i + chunk_size])
    return chunks
```

**–ü—Ä–∏–º–µ—Ä:**

```markdown
Input (100 —Å–∏–º–≤–æ–ª–æ–≤):
"# User Model\nThe User model represents authenticated users.\n```python\nclass User:\n    pass\n```"

Output:
Chunk 1: "# User Model\nThe User model represents authenticated users.\n```pyt"
Chunk 2: "hon\nclass User:\n    pass\n```"
```

**–ü—Ä–æ–±–ª–µ–º—ã:**

‚ùå –ö–æ–¥ —Ä–∞–∑—Ä–µ–∑–∞–Ω –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ (```pyt | hon)  
‚ùå –ö–ª–∞—Å—Å —Ä–∞–∑–æ—Ä–≤–∞–Ω –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏  
‚ùå –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç–¥–µ–ª—ë–Ω –æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞  
‚ùå Markdown fence markers –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã  

### –ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—â–µ—Ç "Python class User"

**–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç:**

1. Chunk 1 —Å–æ–¥–µ—Ä–∂–∏—Ç "```pyt" ‚Üí —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω
2. Chunk 2 —Å–æ–¥–µ—Ä–∂–∏—Ç "hon\nclass User" ‚Üí –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ "User Model"
3. –û–±–∞ —á–∞–Ω–∫–∞ –∏–º–µ—é—Ç –Ω–∏–∑–∫—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
4. –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞: ‚ùå –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ

---

## üí° –†–µ—à–µ–Ω–∏–µ: SmartSplitter

### –ü—Ä–∏–Ω—Ü–∏–ø—ã —É–º–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è

**1. –ò–∑–æ–ª—è—Ü–∏—è –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞**

```mermaid
graph LR
    A[TEXT: 300 chars] --> B[Flush to Chunk]
    B --> C[CODE: 500 chars]
    C --> D[Isolate as separate Chunk]
    D --> E[TEXT: 200 chars]
    E --> F[Start new buffer]
```

**–ü—Ä–∞–≤–∏–ª–æ:** CODE –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–º–µ—à–∏–≤–∞–µ—Ç—Å—è —Å TEXT

**2. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –º–µ–ª–∫–∏—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤**

```
Paragraph 1: 100 chars
Paragraph 2: 150 chars
Paragraph 3: 200 chars
‚Üí –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –≤ 1 chunk (450 < chunk_size=1000)
```

**3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö**

–ö–∞–∂–¥—ã–π chunk –Ω–∞—Å–ª–µ–¥—É–µ—Ç:
- `headers` (breadcrumbs)
- `language` (–¥–ª—è CODE)
- `chunk_index` (–ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä)

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ SmartSplitter

### –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

```python
class SmartSplitter(BaseSplitter):
    def __init__(
        self,
        parser: DocumentParser,
        chunk_size: int = 1000,
        code_chunk_size: int = 2000,
        preserve_code: bool = True,
    ):
        self.parser = parser
        self.chunk_size = chunk_size
        self.code_chunk_size = code_chunk_size
        self.preserve_code = preserve_code
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**

- `parser`: –≠–∫–∑–µ–º–ø–ª—è—Ä MarkdownNodeParser (–∏–∑ —Å–µ—Ä–∏–∏ 15)
- `chunk_size`: –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä TEXT —á–∞–Ω–∫–∞ (default: 1000)
- `code_chunk_size`: –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä CODE —á–∞–Ω–∫–∞ (default: 2000)
- `preserve_code`: –ò–∑–æ–ª–∏—Ä–æ–≤–∞—Ç—å CODE –±–ª–æ–∫–∏ (default: True)

**–ó–∞—á–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã?**

- **TEXT**: 1000 —Å–∏–º–≤–æ–ª–æ–≤ ‚âà 200 —Ç–æ–∫–µ–Ω–æ–≤ ‚Üí –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ –¥–ª—è —á—Ç–µ–Ω–∏—è
- **CODE**: 2000 —Å–∏–º–≤–æ–ª–æ–≤ ‚Üí —Ü–µ–ª–∞—è —Ñ—É–Ω–∫—Ü–∏—è/–∫–ª–∞—Å—Å –±–µ–∑ —Ä–∞–∑—Ä—ã–≤–æ–≤

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```mermaid
graph TD
    A[Document] --> B[Parser.parse]
    B --> C[List ParsingSegment]
    C --> D{SmartSplitter}
    D --> E[Buffer Management]
    E --> F{Segment Type?}
    F -->|TEXT| G[Add to text_buffer]
    F -->|CODE| H[Flush text_buffer]
    H --> I[Create CODE chunk]
    I --> J[Increment chunk_index]
    G --> K{Buffer full?}
    K -->|Yes| L[Flush buffer]
    K -->|No| M[Continue accumulating]
```

---

## üîß –õ–æ–≥–∏–∫–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏

### Buffer Management

**State:**

```python
text_buffer: list[ParsingSegment] = []  # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ TEXT
chunk_index: int = 0                    # –°—á—ë—Ç—á–∏–∫ —á–∞–Ω–∫–æ–≤
```

**–ê–ª–≥–æ—Ä–∏—Ç–º:**

```
FOR EACH segment IN segments:
    IF segment.type == CODE AND preserve_code:
        1. Flush text_buffer ‚Üí —Å–æ–∑–¥–∞—Ç—å TEXT chunks
        2. Create CODE chunk(s) ‚Üí –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ
        3. Increment chunk_index
    
    ELSE IF segment.type IN (TEXT, IMAGE_REF):
        1. Add segment to text_buffer
        2. IF buffer_size >= chunk_size:
            a. Flush buffer ‚Üí —Å–æ–∑–¥–∞—Ç—å chunks
            b. Clear buffer
            c. Increment chunk_index

# –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
IF text_buffer not empty:
    Flush remaining buffer
```

### Flush —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –±—É—Ñ–µ—Ä–∞

**–ó–∞–¥–∞—á–∞:** –ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ chunks

```python
def _flush_text_buffer(
    buffer: list[ParsingSegment],
    chunk_index: int
) -> list[Chunk]:
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
    combined_content = "\n\n".join(seg.content for seg in buffer)
    
    # –°–æ–∑–¥–∞—ë–º –µ–¥–∏–Ω—ã–π chunk
    chunk = Chunk(
        content=combined_content,
        chunk_type=ChunkType.TEXT,
        chunk_index=chunk_index,
        metadata={
            "headers": buffer[0].metadata.get("headers", [])
        }
    )
    
    return [chunk]
```

**–í–∞–∂–Ω–æ:** –í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –±—É—Ñ–µ—Ä–µ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ `headers` (–∏–∑ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞)

---

## üß© –û–±—Ä–∞–±–æ—Ç–∫–∞ CODE –±–ª–æ–∫–æ–≤

### –ò–∑–æ–ª—è—Ü–∏—è –∫–æ–¥–∞

**–ü—Ä–∞–≤–∏–ª–æ:** CODE –≤—Å–µ–≥–¥–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º chunk

**–ü—Ä–∏–º–µ—Ä:**

```
TEXT segment: "The User model has the following methods:"
CODE segment: "class User:\n    def login(self):\n        ..."
TEXT segment: "The login method authenticates users."

‚Üí 3 chunks:
  1. TEXT chunk (index=0)
  2. CODE chunk (index=1)
  3. TEXT chunk (index=2)
```

### –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–¥–∞

**–ü—Ä–æ–±–ª–µ–º–∞:** CODE –±–ª–æ–∫ 5000 —Å–∏–º–≤–æ–ª–æ–≤ > code_chunk_size (2000)

**–†–µ—à–µ–Ω–∏–µ:** –ü–æ—Å—Ç—Ä–æ—á–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ

```python
def _create_code_chunks(
    segment: ParsingSegment,
    chunk_index: int
) -> list[Chunk]:
    if len(segment.content) <= self.code_chunk_size:
        # –í–µ—Å—å –∫–æ–¥ –≤ –æ–¥–∏–Ω chunk
        return [create_single_chunk(segment, chunk_index)]
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    lines = segment.content.split("\n")
    chunks = []
    current_lines = []
    current_size = 0
    
    for line in lines:
        if current_size + len(line) > self.code_chunk_size:
            # Flush –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            chunks.append(create_chunk(current_lines, chunk_index + len(chunks)))
            current_lines = [line]
            current_size = len(line)
        else:
            current_lines.append(line)
            current_size += len(line) + 1  # +1 –¥–ª—è \n
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–π chunk
    if current_lines:
        chunks.append(create_chunk(current_lines, chunk_index + len(chunks)))
    
    return chunks
```

**–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è:**

- –í—Å–µ chunks –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π `language`
- –í—Å–µ chunks –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ `headers`
- `chunk_index` –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è: 5, 6, 7...

---

## üìä –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã

### Input –¥–æ–∫—É–º–µ–Ω—Ç

```markdown
# Database Models

## User Model

The User model represents authenticated users.

### Authentication

Users can log in using email and password.

```python
class User(Model):
    email = CharField(unique=True)
    password = CharField()
    
    def authenticate(self, password):
        return check_password(password, self.password)
```

### Registration

New users are created via the register endpoint.

```python
def register(email, password):
    user = User.create(email=email, password=hash_password(password))
    return user
```
```

### –ü–∞—Ä—Å–∏–Ω–≥ (—Å–µ—Ä–∏—è 15)

**ParsingSegments:**

```python
[
    ParsingSegment(
        content="The User model represents authenticated users.",
        segment_type=TEXT,
        metadata={"headers": ["Database Models", "User Model"]}
    ),
    ParsingSegment(
        content="Users can log in using email and password.",
        segment_type=TEXT,
        metadata={"headers": ["Database Models", "User Model", "Authentication"]}
    ),
    ParsingSegment(
        content="class User(Model):\n    email = CharField(unique=True)...",
        segment_type=CODE,
        metadata={"headers": ["Database Models", "User Model", "Authentication"], "language": "python"}
    ),
    ParsingSegment(
        content="New users are created via the register endpoint.",
        segment_type=TEXT,
        metadata={"headers": ["Database Models", "User Model", "Registration"]}
    ),
    ParsingSegment(
        content="def register(email, password):...",
        segment_type=CODE,
        metadata={"headers": ["Database Models", "User Model", "Registration"], "language": "python"}
    )
]
```

### Splitting

**–ü—Ä–æ—Ü–µ—Å—Å:**

```
1. TEXT segment (47 chars) ‚Üí add to buffer
2. TEXT segment (45 chars) ‚Üí add to buffer (total: 92)
3. CODE segment ‚Üí FLUSH buffer!
   ‚Üí Chunk 0: "The User model... Users can log in..." (TEXT, index=0)
   ‚Üí Chunk 1: "class User(Model):..." (CODE, index=1, language=python)
4. TEXT segment (48 chars) ‚Üí new buffer
5. CODE segment ‚Üí FLUSH buffer!
   ‚Üí Chunk 2: "New users are created..." (TEXT, index=2)
   ‚Üí Chunk 3: "def register(email, password):..." (CODE, index=3, language=python)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**

```python
[
    Chunk(
        content="The User model represents...\n\nUsers can log in...",
        chunk_type=TEXT,
        chunk_index=0,
        metadata={"headers": ["Database Models", "User Model", "Authentication"]}
    ),
    Chunk(
        content="class User(Model):\n    email = CharField...",
        chunk_type=CODE,
        chunk_index=1,
        language="python",
        metadata={"headers": ["Database Models", "User Model", "Authentication"]}
    ),
    Chunk(
        content="New users are created via the register endpoint.",
        chunk_type=TEXT,
        chunk_index=2,
        metadata={"headers": ["Database Models", "User Model", "Registration"]}
    ),
    Chunk(
        content="def register(email, password):\n    user = User.create...",
        chunk_type=CODE,
        chunk_index=3,
        language="python",
        metadata={"headers": ["Database Models", "User Model", "Registration"]}
    )
]
```

---

## üî¢ Chunk Index: –ü–æ—Ä—è–¥–∫–æ–≤–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è

### –ó–∞—á–µ–º –Ω—É–∂–µ–Ω chunk_index?

**1. –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞**

```python
# –ë–µ–∑ chunk_index: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ distance
results = search_chunks(query="authentication")
‚Üí [chunk_3, chunk_1, chunk_0]  # –•–∞–æ—Ç–∏—á–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫

# –° chunk_index: –º–æ–∂–Ω–æ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –ø–æ–∑–∏—Ü–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
results_sorted = sorted(results, key=lambda r: r.chunk_index)
‚Üí [chunk_0, chunk_1, chunk_3]  # –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
```

**2. –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É**

```python
# "–ü–æ–∫–∞–∂–∏ —Å–ª–µ–¥—É—é—â–∏–π chunk –ø–æ—Å–ª–µ —Ç–µ–∫—É—â–µ–≥–æ"
current_chunk_index = 1
next_chunk = get_chunk_by_index(document_id, current_chunk_index + 1)
```

**3. –û—Ç–ª–∞–¥–∫–∞ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**

```python
assert chunks[0].chunk_index == 0
assert chunks[1].chunk_index == 1
assert chunks[2].chunk_index == 2
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```

### –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç –ª–æ–≥–∏–∫–∞

**–ü—Ä–∞–≤–∏–ª–æ:** –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç –ü–û–°–õ–ï –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö chunks –∏–∑ –æ–¥–Ω–æ–≥–æ flush

```python
# WRONG ‚ùå
for segment in segments:
    chunk = create_chunk(segment)
    chunks.append(chunk)
    chunk_index += 1  # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç —Å—Ä–∞–∑—É

# RIGHT ‚úÖ
for segment in segments:
    new_chunks = process_segment(segment, chunk_index)
    chunks.extend(new_chunks)
    chunk_index += len(new_chunks)  # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö
```

**–ü—Ä–∏–º–µ—Ä:**

```
–°–µ–≥–º–µ–Ω—Ç 1 ‚Üí 1 chunk  ‚Üí index=0
–°–µ–≥–º–µ–Ω—Ç 2 ‚Üí 1 chunk  ‚Üí index=1
–°–µ–≥–º–µ–Ω—Ç 3 ‚Üí 3 chunks ‚Üí index=2, 3, 4  (–¥–ª–∏–Ω–Ω—ã–π CODE —Ä–∞–∑–±–∏—Ç)
–°–µ–≥–º–µ–Ω—Ç 4 ‚Üí 1 chunk  ‚Üí index=5
```

---

## üé® Metadata Propagation

### Headers (Breadcrumbs)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü—Ä–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ chunk, –∫–∞–∫–∏–µ headers –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?

**–†–µ—à–µ–Ω–∏–µ:** –ë–µ—Ä—ë–º headers –∏–∑ **–ø–µ—Ä–≤–æ–≥–æ** —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ –±—É—Ñ–µ—Ä–µ

```python
def _flush_text_buffer(buffer: list[ParsingSegment]) -> list[Chunk]:
    # –í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –±—É—Ñ–µ—Ä–µ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ headers (–∏–∑ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞)
    headers = buffer[0].metadata.get("headers", [])
    
    chunk = Chunk(
        content=combine_content(buffer),
        metadata={"headers": headers}
    )
```

**–ì–∞—Ä–∞–Ω—Ç–∏—è:** SmartSplitter flush –±—É—Ñ–µ—Ä –ø—Ä–∏ —Å–º–µ–Ω–µ —Ä–∞–∑–¥–µ–ª–∞ (–∫–æ–≥–¥–∞ headers –∏–∑–º–µ–Ω–∏–ª–∏—Å—å)

### Language –¥–ª—è CODE

**–ü—Ä–∞–≤–∏–ª–æ:** CODE chunks —Å–æ—Ö—Ä–∞–Ω—è—é—Ç —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è

```python
chunk = Chunk(
    content=code_content,
    chunk_type=ChunkType.CODE,
    language="python",  # –ò–∑ ParsingSegment.metadata["language"]
    metadata={"headers": headers}
)
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```python
# –ü–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ Python –∫–æ–¥–∞
results = search_chunks(
    query_vector=vector,
    chunk_type_filter=ChunkType.CODE,
    language_filter="python"
)
```

### IMAGE_REF –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

**IMAGE_REF –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ TEXT**, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–æ–ª—è:

```python
chunk = Chunk(
    content="/images/screenshot.png",  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
    chunk_type=ChunkType.IMAGE_REF,
    metadata={
        "headers": headers,
        "alt": "Installation wizard screenshot",
        "title": "Step 1: Choose directory"
    }
)
```

**Phase 6 (Multimodality)** –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–∏ chunks –¥–ª—è Vision API.

---

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤

**–†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Phase 4 —Ç–µ—Å—Ç–æ–≤:**

| Document               | Segments | Chunks | Avg Chunk Size | Max Chunk Size |
|------------------------|----------|--------|----------------|----------------|
| plan_phase_3.md        | 42       | 18     | 847 chars      | 1998 chars     |
| plan_phase_4.md        | 38       | 15     | 923 chars      | 2000 chars     |
| evil.md (—Ç–µ—Å—Ç)         | 8        | 5      | 412 chars      | 1500 chars     |

**–í—ã–≤–æ–¥—ã:**

- TEXT chunks: 400-1000 —Å–∏–º–≤–æ–ª–æ–≤ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞)
- CODE chunks: 800-2000 —Å–∏–º–≤–æ–ª–æ–≤ (—Å–æ—Ö—Ä–∞–Ω—è—é—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏–π)

### Performance

**Benchmark (100 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, 5000 chunks):**

| –û–ø–µ—Ä–∞—Ü–∏—è              | SimpleSplitter | SmartSplitter | –†–∞–∑–Ω–∏—Ü–∞ |
|-----------------------|----------------|---------------|---------|
| –ü–∞—Ä—Å–∏–Ω–≥ + Splitting   | 120ms          | 380ms         | +3x     |
| –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞       | 0.65 recall    | 0.89 recall   | +37%    |
| False positives       | 28%            | 7%            | -75%    |

**–í—ã–≤–æ–¥:** 3x –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ +37% —Ç–æ—á–Ω–æ—Å—Ç—å ‚Üí trade-off –æ–ø—Ä–∞–≤–¥–∞–Ω

---

## üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ Pipeline

### –î–æ Phase 4

```python
from semantic_core.text_processing import SimpleSplitter

splitter = SimpleSplitter(chunk_size=500)
chunks = splitter.split_text(document.content)

# –†—É—á–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ Chunk –æ–±—ä–µ–∫—Ç–æ–≤
for i, text in enumerate(chunks):
    chunk = Chunk(
        content=text,
        chunk_type=ChunkType.TEXT,  # –í—Å–µ–≥–¥–∞ TEXT
        chunk_index=i,
        metadata={}  # –ù–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    )
```

### –ü–æ—Å–ª–µ Phase 4

```python
from semantic_core.processing.parsers import MarkdownNodeParser
from semantic_core.processing.splitters import SmartSplitter

parser = MarkdownNodeParser()
splitter = SmartSplitter(
    parser=parser,
    chunk_size=1000,
    code_chunk_size=2000
)

# –í—Å—ë –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
chunks = splitter.split(document)
# Chunks —É–∂–µ –∏–º–µ—é—Ç:
# - –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π chunk_type (TEXT/CODE/IMAGE_REF)
# - Headers breadcrumbs
# - Language –¥–ª—è CODE
# - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π chunk_index
```

### –í SemanticIndex –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–µ

```python
class Article(Model):
    content = TextField()
    semantic_index = SemanticIndex(
        source_field="content",
        parser=MarkdownNodeParser(),
        splitter=SmartSplitter(chunk_size=800),
        context_strategy=HierarchicalContextStrategy()  # –°–µ—Ä–∏—è 17
    )

# –ü—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç—å–∏:
article = Article.create(content=markdown_text)
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
# 1. Parse ‚Üí segments
# 2. Split ‚Üí chunks
# 3. Add context (—Å–µ—Ä–∏—è 17)
# 4. Embed vectors
# 5. Index –≤ chunks_vec
```

---

## üéì –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ SmartSplitter

‚úÖ **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å**
- CODE –Ω–µ —Ä–∞–∑—Ä—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ —Ñ—É–Ω–∫—Ü–∏–∏
- TEXT –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è –ª–æ–≥–∏—á–µ—Å–∫–∏
- Headers —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

‚úÖ **–¢–∏–ø–∏–∑–∞—Ü–∏—è –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ**
- –ö–∞–∂–¥—ã–π chunk –∑–Ω–∞–µ—Ç —Å–≤–æ–π —Ç–∏–ø
- Language –¥–ª—è CODE –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
- Breadcrumbs –¥–∞—é—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç

‚úÖ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤**
- –†–∞–∑–Ω—ã–µ –ª–∏–º–∏—Ç—ã –¥–ª—è TEXT –∏ CODE
- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –º–µ–ª–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
- –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ

‚úÖ **–£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏–µ**
- chunk_index –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∞–Ω–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

üèóÔ∏è **Separation of Concerns**
- Parser: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
- Splitter: —Ä–∞–∑–º–µ—Ä –∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞
- Context Strategy: –æ–±–æ–≥–∞—â–µ–Ω–∏–µ (—Å–ª–µ–¥—É—é—â–∞—è —Å–µ—Ä–∏—è)

üîß **–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å**
- –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –ª–æ–≥–∏–∫—É –¥–ª—è TABLE chunks
- –õ–µ–≥–∫–æ –∏–∑–º–µ–Ω–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
- Pluggable parser

üìä **Quality vs Performance**
- 3x –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ +37% —Ç–æ—á–Ω–æ—Å—Ç—å
- Trade-off –æ–ø—Ä–∞–≤–¥–∞–Ω –¥–ª—è production

---

## üîó –°–≤—è–∑—å —Å –¥—Ä—É–≥–∏–º–∏ —Å–µ—Ä–∏—è–º–∏

**–ü—Ä–µ–¥—ã–¥—É—â–∏–µ:**
- [15: Smart Parsing](15_smart_parsing.md) ‚Äî –æ—Ç–∫—É–¥–∞ –±–µ—Ä—É—Ç—Å—è ParsingSegments

**–°–ª–µ–¥—É—é—â–∏–µ:**
- [17: Hierarchical Context](17_hierarchical_context.md) ‚Äî –∫–∞–∫ breadcrumbs –ø—Ä–µ–≤—Ä–∞—â–∞—é—Ç—Å—è –≤ embeddings
- [18: Granular Search](18_granular_search.md) ‚Äî –ø–æ–∏—Å–∫ –ø–æ —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —á–∞–Ω–∫–∞–º

**–§—É–Ω–¥–∞–º–µ–Ω—Ç:**
- [08: Chunking Strategy](08_chunking_strategy.md) ‚Äî –±–∞–∑–æ–≤—ã–π SimpleSplitter
- [09: Parent-Child Retrieval](09_parent_child_retrieval.md) ‚Äî –∑–∞—á–µ–º —á–∞–Ω–∫–∏

---

**–°–µ—Ä–∏—è 2 –∏–∑ 4 (Phase 4)**  
**–î–∞—Ç–∞:** 2 –¥–µ–∫–∞–±—Ä—è 2025  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ
