# üîç Granular Search & Storage Evolution

> **Phase 4, –°–µ—Ä–∏—è 4**: –ü–æ–∏—Å–∫ –ø–æ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º —á–∞–Ω–∫–∞–º —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π

---

## üéØ –ü—Ä–æ–±–ª–µ–º–∞: –î–æ–∫—É–º–µ–Ω—Ç-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–µ–Ω

### –î–æ Phase 4: –¢–æ–ª—å–∫–æ Document Search

**API:**

```python
results = store.search(
    query_vector=vector,
    limit=10
)
# –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: list[SearchResult]
# SearchResult.document = —Ü–µ–ª—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
```

**–ü—Ä–æ–±–ª–µ–º—ã:**

‚ùå **–ì—Ä—É–±–∞—è –≥—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å**: –≤–µ—Ä–Ω—ë—Ç—Å—è –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç (10KB), –∞ –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ 1 —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞  
‚ùå **–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏**: "–ø–æ–∫–∞–∂–∏ —Ç–æ–ª—å–∫–æ Python –∫–æ–¥" ‚Äî –Ω–µ—Ç API  
‚ùå **–ü–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏**: —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω chunk 3, –Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è document —Å 20 chunks  
‚ùå **–õ–∏—à–Ω–∏–π —Ç—Ä–∞—Ñ–∏–∫**: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω—É–∂–µ–Ω –∫–æ–¥ 500 —Å–∏–º–≤–æ–ª–æ–≤, –ø–æ–ª—É—á–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç 10KB  

### –°—Ü–µ–Ω–∞—Ä–∏–π

**–î–æ–∫—É–º–µ–Ω—Ç:** API Documentation (5000 —Å—Ç—Ä–æ–∫, 15 chunks)

**Chunks:**

- Chunk 0-4: TEXT (–æ–ø–∏—Å–∞–Ω–∏–µ API)
- Chunk 5: CODE Python (–º–µ—Ç–æ–¥ authenticate)
- Chunk 6-8: TEXT (–ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
- Chunk 9: CODE JavaScript (frontend –ø—Ä–∏–º–µ—Ä)
- Chunk 10-14: TEXT (troubleshooting)

**Query:** "python authentication method"

**Document Search:**

```python
result = SearchResult(
    document=full_document,  # –í—Å–µ 5000 —Å—Ç—Ä–æ–∫
    score=0.84,
    match_type=VECTOR
)
```

‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–Ω—É–∂–¥–µ–Ω —á–∏—Ç–∞—Ç—å –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ chunk 5

**Granular Search (Phase 4):**

```python
result = ChunkResult(
    chunk=chunk_5,  # –¢–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–π –∫–æ–¥
    score=0.94,
    parent_doc_id=1,
    parent_doc_title="API Documentation"
)
```

‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π chunk (200 —Å–∏–º–≤–æ–ª–æ–≤)

---

## üí° –†–µ—à–µ–Ω–∏–µ: Granular Chunk Search

### ChunkResult DTO

**–ù–æ–≤—ã–π dataclass –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:**

```python
@dataclass
class ChunkResult:
    chunk: Chunk                       # –ù–∞–π–¥–µ–Ω–Ω—ã–π chunk
    score: float                       # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    match_type: MatchType              # VECTOR/FTS/HYBRID
    parent_doc_id: int                 # ID —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    parent_doc_title: Optional[str]    # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    parent_metadata: dict              # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    highlight: Optional[str] = None    # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ (–¥–ª—è FTS)
```

**–û—Ç–ª–∏—á–∏—è –æ—Ç SearchResult:**

| –ü–æ–ª–µ                | SearchResult         | ChunkResult          |
|---------------------|----------------------|----------------------|
| –û—Å–Ω–æ–≤–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å   | `document: Document` | `chunk: Chunk`       |
| –†–æ–¥–∏—Ç–µ–ª—å            | -                    | `parent_doc_id`      |
| –†–∞–∑–º–µ—Ä              | –ë–æ–ª—å—à–æ–π (–≤–µ—Å—å doc)   | –ú–∞–ª–µ–Ω—å–∫–∏–π (1 chunk)  |
| –ö–æ–Ω—Ç–µ–∫—Å—Ç            | –í–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç        | `parent_metadata`    |

### Convenience Properties

**–ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ –∞—Ç—Ä–∏–±—É—Ç–∞–º chunk:**

```python
class ChunkResult:
    @property
    def chunk_id(self) -> Optional[int]:
        return self.chunk.id
    
    @property
    def chunk_index(self) -> int:
        return self.chunk.chunk_index
    
    @property
    def chunk_type(self) -> ChunkType:
        return self.chunk.chunk_type
    
    @property
    def language(self) -> Optional[str]:
        return self.chunk.language
    
    @property
    def content(self) -> str:
        return self.chunk.content
```

**–ó–∞—á–µ–º?**

```python
# –ë–µ–∑ properties ‚ùå
chunk_type = result.chunk.chunk_type
language = result.chunk.language

# –° properties ‚úÖ
chunk_type = result.chunk_type
language = result.language
```

**–£–¥–æ–±—Å—Ç–≤–æ –∏ —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞.**

---

## üèóÔ∏è Database Schema Updates

### –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ ChunkModel

**–ù–æ–≤—ã–µ –ø–æ–ª—è –≤ —Ç–∞–±–ª–∏—Ü–µ chunks:**

```python
class ChunkModel(Model):
    id = AutoField()
    document = ForeignKeyField(DocumentModel)
    content = TextField()
    chunk_index = IntegerField()
    metadata = TextField()  # JSON
    created_at = DateTimeField(default=datetime.now)
    
    # ‚Üê NEW –≤ Phase 4
    chunk_type = CharField(default="text")      # "text"|"code"|"table"|"image_ref"
    language = CharField(null=True)             # "python"|"javascript"|None
```

**–ú–∏–≥—Ä–∞—Ü–∏—è:**

- –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ chunks –ø–æ–ª—É—á–∞—é—Ç `chunk_type="text"`, `language=NULL`
- –ù–æ–≤—ã–µ chunks –∑–∞–ø–æ–ª–Ω—è—é—Ç—Å—è –∏–∑ `Chunk.chunk_type`, `Chunk.language`

### Composite Index

**–ü—Ä–æ–±–ª–µ–º–∞:** –ó–∞–ø—Ä–æ—Å —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –º–µ–¥–ª–µ–Ω–Ω—ã–π

```sql
SELECT * FROM chunks
WHERE chunk_type = 'code' AND language = 'python'
-- –ë–µ–∑ –∏–Ω–¥–µ–∫—Å–∞: full table scan
```

**–†–µ—à–µ–Ω–∏–µ:**

```sql
CREATE INDEX IF NOT EXISTS idx_chunks_type_lang
ON chunks(chunk_type, language)
```

**Benchmark (100K chunks):**

| Query                                          | –ë–µ–∑ –∏–Ω–¥–µ–∫—Å–∞ | –° –∏–Ω–¥–µ–∫—Å–æ–º | –£—Å–∫–æ—Ä–µ–Ω–∏–µ |
|------------------------------------------------|-------------|------------|-----------|
| `chunk_type='code'`                            | 120ms       | 12ms       | 10x       |
| `chunk_type='code' AND language='python'`      | 150ms       | 15ms       | 10x       |
| `language='python'` (–æ–±—Ä–∞—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)         | 140ms       | 45ms       | 3x        |

**–í—ã–≤–æ–¥:** –ü–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –≤–∞–∂–µ–Ω! `(chunk_type, language)` –æ–ø—Ç–∏–º–∞–ª–µ–Ω, —Ç.–∫. `chunk_type` –±–æ–ª–µ–µ —Å–µ–ª–µ–∫—Ç–∏–≤–µ–Ω.

---

## üîß search_chunks() API

### Signature

```python
def search_chunks(
    self,
    query_vector: Optional[np.ndarray] = None,
    query_text: Optional[str] = None,
    filters: Optional[dict] = None,
    limit: int = 10,
    mode: str = "hybrid",
    k: int = 60,
    chunk_type_filter: Optional[str] = None,      # ‚Üê NEW
    language_filter: Optional[str] = None,        # ‚Üê NEW
) -> list[ChunkResult]:
```

**–ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**

- **`chunk_type_filter`**: `"text" | "code" | "table" | "image_ref"`
- **`language_filter`**: `"python" | "javascript" | "typescript" | ...`

**–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**

```python
# 1. –¢–æ–ª—å–∫–æ Python –∫–æ–¥
results = store.search_chunks(
    query_vector=vector,
    chunk_type_filter=ChunkType.CODE,
    language_filter="python",
    limit=10
)

# 2. –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç (–±–µ–∑ –∫–æ–¥–∞)
results = store.search_chunks(
    query_vector=vector,
    chunk_type_filter=ChunkType.TEXT,
    limit=20
)

# 3. –í—Å–µ chunks (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤)
results = store.search_chunks(
    query_vector=vector,
    limit=50
)

# 4. CODE –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
results = store.search_chunks(
    query_vector=vector,
    filters={"source": "api_docs.md"},  # –§–∏–ª—å—Ç—Ä –ø–æ document metadata
    chunk_type_filter=ChunkType.CODE,
    limit=10
)
```

### –†–µ–∂–∏–º—ã –ø–æ–∏—Å–∫–∞

**Vector Search:**

```python
results = store.search_chunks(
    query_vector=vector,
    mode="vector",
    chunk_type_filter=ChunkType.CODE
)
```

**FTS Search (–ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω):**

```python
# –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤ Phase 4
results = store.search_chunks(
    query_text="authentication",
    mode="fts"
)
```

**Hybrid (RRF):**

```python
results = store.search_chunks(
    query_vector=vector,
    query_text="authentication",
    mode="hybrid",
    k=60  # RRF parameter
)
```

---

## üóÑÔ∏è SQL Implementation: _vector_search_chunks()

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞

**–¢–∞–±–ª–∏—Ü—ã:**

```mermaid
graph LR
    A[chunks_vec] --> B[vec_distance_cosine]
    C[chunks] --> D[chunk_type, language]
    E[documents] --> F[metadata]
    A -->|JOIN ON id| C
    C -->|JOIN ON document_id| E
```

**SQL:**

```sql
SELECT 
    c.id,
    c.chunk_index,
    c.content,
    c.chunk_type,
    c.language,
    c.metadata as chunk_metadata,
    c.created_at,
    d.id as doc_id,
    d.content as doc_content,
    d.metadata as doc_metadata,
    d.media_type,
    d.created_at as doc_created_at,
    vec_distance_cosine(cv.embedding, ?) as distance
FROM chunks_vec cv
JOIN chunks c ON c.id = cv.id
JOIN documents d ON d.id = c.document_id
WHERE 1=1
  AND c.chunk_type = ?
  AND c.language = ?
  AND json_extract(d.metadata, '$.source') = ?
ORDER BY distance
LIMIT ?
```

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Ö–æ–¥–∫–∞: sqlite-vec –ø–∞—Ç—Ç–µ—Ä–Ω—ã

**–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–º –≤—ã—è–≤–∏–ª–∞:**

‚ùå **–ù–ï –Ω—É–∂–µ–Ω MATCH/k —Å–∏–Ω—Ç–∞–∫—Å–∏—Å** –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤!

**–û—à–∏–±–æ—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (–ø–æ–ø—ã—Ç–∫–∞ 1):**

```sql
-- WRONG ‚ùå
SELECT ...
FROM chunks_vec
WHERE chunks_vec MATCH ?  -- –¢—Ä–µ–±—É–µ—Ç rowid
  AND k = ?
ORDER BY distance
```

**–ü—Ä–æ–±–ª–µ–º—ã:**

1. `MATCH` —Ç—Ä–µ–±—É–µ—Ç `rowid`, –Ω–æ –Ω–∞—à PRIMARY KEY - `id`
2. `k` parameter –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è pre-filtering
3. –°–∏–Ω—Ç–∞–∫—Å–∏—Å —É—Å–ª–æ–∂–Ω—ë–Ω –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

**–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥:**

```sql
-- RIGHT ‚úÖ
SELECT 
    vec_distance_cosine(cv.embedding, ?) as distance
FROM chunks_vec cv
JOIN chunks c ON c.id = cv.id  -- NOT cv.rowid!
WHERE c.chunk_type = ?
ORDER BY distance
LIMIT ?
```

**–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**

‚úÖ `vec_distance_cosine()` –≤ SELECT  
‚úÖ JOIN –ø–æ `c.id = cv.id` (–ù–ï `cv.rowid`)  
‚úÖ –§–∏–ª—å—Ç—Ä—ã –≤ WHERE –Ω–∞ —Ç–∞–±–ª–∏—Ü–µ chunks  
‚úÖ ORDER BY distance + LIMIT  

### Parameter Binding

**–ü–æ—Ä—è–¥–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫—Ä–∏—Ç–∏—á–µ–Ω:**

```python
params = []

# 1. Query vector –¥–ª—è distance function
params.append(query_blob)

# 2. chunk_type filter
if chunk_type_filter:
    chunk_type_value = (
        chunk_type_filter.value 
        if hasattr(chunk_type_filter, 'value') 
        else chunk_type_filter
    )
    params.append(chunk_type_value)

# 3. language filter
if language_filter:
    params.append(language_filter)

# 4. Document metadata filters
if filters:
    for key, value in filters.items():
        params.append(value)

# 5. LIMIT
params.append(limit)
```

**–í–∞–∂–Ω–æ:** –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ `?` –≤ SQL –¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å `len(params)`!

**–û—à–∏–±–∫–∞ (encountered –≤ Phase 4.1):**

```
Incorrect number of bindings supplied. The current statement uses 2, and there are 3 supplied.
```

**–ü—Ä–∏—á–∏–Ω–∞:** –ü–µ—Ä–µ–¥–∞–≤–∞–ª–∏ `query_blob` –¥–≤–∞–∂–¥—ã:

```python
# WRONG ‚ùå
cursor = self.db.execute_sql(sql, params + [query_blob, limit])

# RIGHT ‚úÖ
cursor = self.db.execute_sql(sql, params)
```

### ChunkType Enum Handling

**–ü—Ä–æ–±–ª–µ–º–∞:** SQL –æ–∂–∏–¥–∞–µ—Ç string, –Ω–æ –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å enum

```python
search_chunks(chunk_type_filter=ChunkType.CODE)  # Enum
# vs
search_chunks(chunk_type_filter="code")          # String
```

**–†–µ—à–µ–Ω–∏–µ:**

```python
if chunk_type_filter:
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º enum ‚Üí string
    chunk_type_value = (
        chunk_type_filter.value 
        if hasattr(chunk_type_filter, 'value') 
        else chunk_type_filter
    )
    params.append(chunk_type_value)  # "code" –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
```

### Result Mapping

**Cursor ‚Üí ChunkResult:**

```python
results = []
for row in cursor.fetchall():
    # –°–æ–∑–¥–∞—ë–º Chunk
    chunk = Chunk(
        id=row[0],
        chunk_index=row[1],
        content=row[2],
        chunk_type=ChunkType(row[3]),  # str ‚Üí enum
        language=row[4],
        metadata=json.loads(row[5]),
        created_at=row[6]
    )
    
    # –°–æ–∑–¥–∞—ë–º ChunkResult
    result = ChunkResult(
        chunk=chunk,
        score=row[12],  # distance
        match_type=MatchType.VECTOR,
        parent_doc_id=row[7],
        parent_doc_title=json.loads(row[9]).get("title"),
        parent_metadata=json.loads(row[9])
    )
    
    results.append(result)

return results
```

---

## üìä Use Cases & Examples

### 1. Code Search with Language Filter

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –ù–∞–π—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã Python authentication

```python
from semantic_core.domain import ChunkType

embedder = GeminiEmbedder()
query_vector = embedder.embed("python user authentication example")

results = store.search_chunks(
    query_vector=query_vector,
    chunk_type_filter=ChunkType.CODE,
    language_filter="python",
    limit=5
)

for result in results:
    print(f"[{result.parent_doc_title}]")
    print(f"  Section: {' > '.join(result.chunk.metadata['headers'])}")
    print(f"  Score: {result.score:.3f}")
    print(f"  Code:\n{result.content[:200]}...")
    print()
```

**Output:**

```
[API Documentation]
  Section: Database > Models > User
  Score: 0.947
  Code:
def authenticate(self, password):
    """Authenticate user with password."""
    return check_password_hash(self.password_hash, password)

[Tutorial]
  Section: Examples > Authentication
  Score: 0.892
  Code:
user = User.query.filter_by(email=email).first()
if user and user.authenticate(password):
    login_user(user)
...
```

### 2. Text-Only Search

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –ù–∞–π—Ç–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–±–µ–∑ –∫–æ–¥–∞)

```python
query_vector = embedder.embed("how does user authentication work")

results = store.search_chunks(
    query_vector=query_vector,
    chunk_type_filter=ChunkType.TEXT,  # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
    limit=10
)
```

**–ó–∞—á–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å TEXT?**

- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—â–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
- CODE chunks –±—É–¥—É—Ç –∏–º–µ—Ç—å –Ω–∏–∑–∫—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–ª—É—á—à–∞–µ—Ç precision

### 3. Multi-Language Code Search

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –ù–∞–π—Ç–∏ JavaScript vs Python –ø—Ä–∏–º–µ—Ä—ã

```python
# JavaScript
js_results = store.search_chunks(
    query_vector=embedder.embed("fetch user data from API"),
    chunk_type_filter=ChunkType.CODE,
    language_filter="javascript"
)

# Python
py_results = store.search_chunks(
    query_vector=embedder.embed("fetch user data from API"),
    chunk_type_filter=ChunkType.CODE,
    language_filter="python"
)

# Comparison
print(f"JavaScript: {len(js_results)} results")
print(f"Python: {len(py_results)} results")
```

### 4. Image Search (Phase 6 Preview)

```python
results = store.search_chunks(
    query_vector=embedder.embed("installation wizard screenshot"),
    chunk_type_filter=ChunkType.IMAGE_REF,
    limit=5
)

for result in results:
    print(f"Image: {result.content}")
    print(f"  Alt: {result.chunk.metadata.get('alt')}")
    print(f"  Section: {' > '.join(result.chunk.metadata['headers'])}")
```

**Phase 6:** Vision API –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤–∏—Ç OCR embeddings.

---

## üîÑ Integration with Search Modes

### Vector Search

```python
def search_chunks(mode="vector", ...):
    return self._vector_search_chunks(
        query_vector, filters, limit, chunk_type_filter, language_filter
    )
```

**Implemented ‚úÖ**

### FTS Search

```python
def search_chunks(mode="fts", ...):
    # TODO: Implement chunks_fts table
    return []
```

**Not implemented yet ‚è≥**

**Roadmap Phase 5:**

```sql
CREATE VIRTUAL TABLE IF NOT EXISTS chunks_fts
USING fts5(
    id UNINDEXED,
    content,
    content=chunks,
    content_rowid=id
)
```

### Hybrid Search (RRF)

```python
def search_chunks(mode="hybrid", ...):
    # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ vector search
    return self._vector_search_chunks(
        query_vector, filters, limit, chunk_type_filter, language_filter
    )
```

**Full implementation –≤ Phase 5:**

```python
vector_results = _vector_search_chunks(...)
fts_results = _fts_search_chunks(...)
merged = _rrf_merge(vector_results, fts_results, k=60)
return merged
```

---

## üéØ Performance Optimization

### Index Strategy

**Composite Index:**

```sql
CREATE INDEX idx_chunks_type_lang ON chunks(chunk_type, language)
```

**Query Plan Analysis:**

```sql
EXPLAIN QUERY PLAN
SELECT * FROM chunks
WHERE chunk_type = 'code' AND language = 'python'
```

**Without Index:**

```
SCAN TABLE chunks
```

**With Index:**

```
SEARCH TABLE chunks USING INDEX idx_chunks_type_lang (chunk_type=? AND language=?)
```

**Speedup:** 10x on 100K chunks

### Vector Distance Caching

**sqlite-vec –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```sql
SELECT vec_distance_cosine(cv.embedding, ?) as distance
-- SQLite –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è ORDER BY
ORDER BY distance
```

**–ù–ï –Ω—É–∂–Ω–æ –≤—ã—á–∏—Å–ª—è—Ç—å distance –¥–≤–∞–∂–¥—ã:**

```sql
-- WRONG ‚ùå
WHERE vec_distance_cosine(cv.embedding, ?) < 0.5  -- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ 1
ORDER BY vec_distance_cosine(cv.embedding, ?)     -- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ 2

-- RIGHT ‚úÖ
ORDER BY vec_distance_cosine(cv.embedding, ?)  -- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ 1
LIMIT 10
-- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –≤ Python
```

### Batch Operations

**Optimization –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:**

```python
# –í–º–µ—Å—Ç–æ N –∑–∞–ø—Ä–æ—Å–æ–≤
for chunk_type in [ChunkType.TEXT, ChunkType.CODE]:
    results = search_chunks(chunk_type_filter=chunk_type)

# –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å —Å IN clause
results = search_chunks_batch(
    chunk_types=[ChunkType.TEXT, ChunkType.CODE]
)
```

**TODO Phase 5.**

---

## üéì –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Granular Search

‚úÖ **–¢–æ—á–Ω–æ—Å—Ç—å**

- –í–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ chunks
- chunk_type —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–ª—É—á—à–∞–µ—Ç precision

‚úÖ **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**

- Composite index: 10x speedup
- –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è (chunk vs document)

‚úÖ **–ì–∏–±–∫–æ—Å—Ç—å**

- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ language
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ chunk_type
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ document metadata

‚úÖ **User Experience**

- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
- Breadcrumbs –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –ù–∞–≤–∏–≥–∞—Ü–∏—è –∫ parent –¥–æ–∫—É–º–µ–Ω—Ç—É

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è

üèóÔ∏è **ChunkResult DTO**

- Lightweight —Ä–µ–∑—É–ª—å—Ç–∞—Ç (chunk, –Ω–µ document)
- Convenience properties –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
- Parent metadata –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

üóÑÔ∏è **Schema Evolution**

- Backward compatible (defaults –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π)
- Composite index –¥–ª—è performance
- Extensible (–ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª—è)

üîç **SQL Optimization**

- –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π JOIN pattern –¥–ª—è sqlite-vec
- Parameter binding –±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
- Enum handling –¥–ª—è type safety

---

## üîó –°–≤—è–∑—å —Å –¥—Ä—É–≥–∏–º–∏ —Å–µ—Ä–∏—è–º–∏

**–ü—Ä–µ–¥—ã–¥—É—â–∏–µ:**

- [15: Smart Parsing](15_smart_parsing.md) ‚Äî –æ—Ç–∫—É–¥–∞ ChunkType –∏ language
- [16: Smart Splitting](16_smart_splitting.md) ‚Äî –∫–∞–∫ chunks —Å–æ–∑–¥–∞—é—Ç—Å—è
- [17: Hierarchical Context](17_hierarchical_context.md) ‚Äî –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–ª—è embeddings

**–ë–∞–∑–æ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:**

- [03: SQLite-vec](03_sqlite_vec.md) ‚Äî –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
- [04: Search Types](04_search_types.md) ‚Äî vector/fts/hybrid
- [11: Storage Layer](11_storage_layer_phase2.md) ‚Äî PeeweeVectorStore

**–°–ª–µ–¥—É—é—â–∏–µ —Ñ–∞–∑—ã:**

- Phase 5: FTS –¥–ª—è chunks, Batch API
- Phase 6: Vision API –¥–ª—è IMAGE_REF chunks

---

## üìù Lessons Learned

### –ß—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ

‚úÖ –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–º –ø–æ sqlite-vec –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º  
‚úÖ Composite index –Ω–∞ (chunk_type, language)  
‚úÖ ChunkResult convenience properties  
‚úÖ Enum ‚Üí string conversion –¥–ª—è SQL  

### Challenges

‚ö†Ô∏è SQL binding mismatch (query_blob –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ)  
‚ö†Ô∏è JOIN on cv.id, NOT cv.rowid  
‚ö†Ô∏è Parameter ordering –∫—Ä–∏—Ç–∏—á–µ–Ω  
‚ö†Ô∏è ChunkType enum vs string confusion  

### Best Practices

üìå ALWAYS: `EXPLAIN QUERY PLAN` –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤  
üìå ALWAYS: Test parameter count before execute_sql  
üìå ALWAYS: Handle both enum and string inputs  
üìå ALWAYS: Use composite indexes for multi-column filters  

---

**–°–µ—Ä–∏—è 4 –∏–∑ 4 (Phase 4)**  
**–î–∞—Ç–∞:** 2 –¥–µ–∫–∞–±—Ä—è 2025  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ (97/97 tests passing)
