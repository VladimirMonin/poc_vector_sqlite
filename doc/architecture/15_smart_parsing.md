# üß† Smart Parsing Architecture

> **Phase 4, –°–µ—Ä–∏—è 1**: –û—Ç –ø–ª–æ—Å–∫–∏—Ö —á–∞–Ω–∫–æ–≤ –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–º—É –ø–∞—Ä—Å–∏–Ω–≥—É

---

## üéØ –ü—Ä–æ–±–ª–µ–º–∞: "–ü–ª–æ—Å–∫–∏–µ" —á–∞–Ω–∫–∏ —Ç–µ—Ä—è—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç

### –î–æ Phase 4

–í Phase 1-3 –≤—Å–µ —á–∞–Ω–∫–∏ –±—ã–ª–∏ –ø—Ä–æ—Å—Ç–æ –∫—É—Å–∫–∞–º–∏ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:

```
Chunk 1: "# Database Models\n## User\nThe User model..."
Chunk 2: "represents authenticated users. Fields:\n- id"
Chunk 3: "- email\n- password\n## Product\nThe Product..."
```

**–ü—Ä–æ–±–ª–µ–º—ã:**
- ‚ùå –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑—Ä—ã–≤–∞—é—Ç—Å—è –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
- ‚ùå –ö–æ–¥ —Å–º–µ—à–∏–≤–∞–µ—Ç—Å—è —Å —Ç–µ–∫—Å—Ç–æ–º
- ‚ùå –¢–µ—Ä—è–µ—Ç—Å—è –∏–µ—Ä–∞—Ä—Ö–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
- ‚ùå –≠–º–±–µ–¥–¥–∏–Ω–≥ –Ω–µ –∑–Ω–∞–µ—Ç, —á—Ç–æ —ç—Ç–æ "User –≤ Database Models"

### –ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è

–ü–æ–∏—Å–∫ –ø–æ —Ñ—Ä–∞–∑–µ **"user authentication"** –º–æ–≥ –≤–µ—Ä–Ω—É—Ç—å chunk 2, –Ω–æ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:
- –ù–µ–ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ —ç—Ç–æ –ø—Ä–æ Database Models
- –ù–µ–ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ —ç—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –ø—Ä–æ User entity
- –≠–º–±–µ–¥–¥–∏–Ω–≥ –≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ "represents authenticated users. Fields: - id"

---

## üí° –†–µ—à–µ–Ω–∏–µ: –¢–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —á–∞–Ω–∫–∏

### ChunkType Enum

–í–≤–µ–¥–µ–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞:

```mermaid
graph TD
    A[Raw Content] --> B{Parser}
    B -->|–¢–µ–∫—Å—Ç| C[ChunkType.TEXT]
    B -->|–ö–æ–¥| D[ChunkType.CODE]
    B -->|–¢–∞–±–ª–∏—Ü–∞| E[ChunkType.TABLE]
    B -->|–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ| F[ChunkType.IMAGE_REF]
```

**–ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ?**

1. **–†–∞–∑–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**: –∫–æ–¥ –Ω–µ–ª—å–∑—è —Ä–µ–∑–∞—Ç—å –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ —Ñ—É–Ω–∫—Ü–∏–∏
2. **–†–∞–∑–Ω—ã–µ embeddings**: –¥–ª—è –∫–æ–¥–∞ –≤–∞–∂–µ–Ω —Å–∏–Ω—Ç–∞–∫—Å–∏—Å, –¥–ª—è —Ç–µ–∫—Å—Ç–∞ - —Å–º—ã—Å–ª
3. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞**: "–ø–æ–∫–∞–∂–∏ —Ç–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –Ω–∞ Python"
4. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤ (—Ç–µ–∫—Å—Ç 1000, –∫–æ–¥ 2000 —Å–∏–º–≤–æ–ª–æ–≤)

### –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Chunk DTO

**–ù–æ–≤—ã–µ –ø–æ–ª—è:**

```python
@dataclass
class Chunk:
    content: str
    chunk_type: ChunkType      # ‚Üê NEW: —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    language: Optional[str]     # ‚Üê NEW: "python", "javascript", etc.
    metadata: dict              # ‚Üê EXPANDED: headers, breadcrumbs
    chunk_index: int            # ‚Üê NEW: –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä
```

**–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ `headers`:**

```python
chunk.metadata = {
    "headers": ["Database Models", "User", "Authentication"],
    "language": "python",  # –¥–ª—è CODE —á–∞–Ω–∫–æ–≤
    "alt": "Screenshot",   # –¥–ª—è IMAGE_REF
}
```

---

## üîß –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞

### –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å DocumentParser

**–ö–æ–Ω—Ç—Ä–∞–∫—Ç:**

```python
class DocumentParser(ABC):
    @abstractmethod
    def parse(self, content: str) -> list[ParsingSegment]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã."""
        pass
```

**ParsingSegment** ‚Äî –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:

```python
@dataclass
class ParsingSegment:
    content: str
    segment_type: ChunkType        # TEXT/CODE/TABLE/IMAGE_REF
    metadata: dict[str, Any]       # headers, language, etc.
```

**–ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö:**

```mermaid
graph LR
    A[Raw Markdown] --> B[DocumentParser]
    B --> C[List ParsingSegment]
    C --> D[SmartSplitter]
    D --> E[List Chunk]
```

**–ó–∞—á–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Å–ª–æ–π?**

- –ü–∞—Ä—Å–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∑–∞ **—Å—Ç—Ä—É–∫—Ç—É—Ä—É**
- –°–ø–ª–∏—Ç—Ç–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∑–∞ **—Ä–∞–∑–º–µ—Ä**
- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ (SOLID)

---

## üìö MarkdownNodeParser: AST-–ø–æ–¥—Ö–æ–¥

### Markdown-it-py –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å:** `markdown-it-py (>=3.0.0,<4.0.0)`

–í–º–µ—Å—Ç–æ regex –∏—Å–ø–æ–ª—å–∑—É–µ–º **AST** (Abstract Syntax Tree):

```mermaid
graph TD
    A[Markdown Text] --> B[markdown-it-py]
    B --> C[Token Stream]
    C --> D{Token Type?}
    D -->|heading_open| E[Extract Header]
    D -->|fence| F[Extract Code Block]
    D -->|paragraph_open| G[Extract Text]
    D -->|image| H[Extract Image Ref]
```

### Token Stream –ø—Ä–∏–º–µ—Ä

**Input:**

```markdown
# Database Models
## User
The User model represents users.

```python
class User(Model):
    pass
```
```

**Token Stream:**

```
heading_open(level=1)
  inline(content="Database Models")
heading_close

heading_open(level=2)
  inline(content="User")
heading_close

paragraph_open
  inline(content="The User model represents users.")
paragraph_close

fence(info="python")
  content="class User(Model):\n    pass"
```

### –ò–µ—Ä–∞—Ä—Ö–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (Breadcrumbs)

**–ü—Ä–æ–±–ª–µ–º–∞:** –∫–∞–∫ –æ—Ç—Å–ª–µ–¥–∏—Ç—å, —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ "Database Models > User"?

**–†–µ—à–µ–Ω–∏–µ:** Stack-based tracking

```mermaid
graph TD
    A[heading_open level=1] --> B[Push 'Database Models' to stack]
    B --> C[heading_open level=2]
    C --> D[Push 'User' to stack]
    D --> E[paragraph_open]
    E --> F[Create segment with headers from stack]
    F --> G[Stack = Database Models, User]
```

**–ê–ª–≥–æ—Ä–∏—Ç–º:**

1. –ü—Ä–∏ –≤—Å—Ç—Ä–µ—á–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —É—Ä–æ–≤–Ω—è N:
   - Pop –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —É—Ä–æ–≤–Ω–µ–º >= N
   - Push –Ω–æ–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
2. –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–∞:
   - –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–µ–∫ –≤ `metadata["headers"]`

**–ü—Ä–∏–º–µ—Ä:**

```
# H1          ‚Üí stack: ["H1"]
## H2         ‚Üí stack: ["H1", "H2"]
### H3        ‚Üí stack: ["H1", "H2", "H3"]
Text here    ‚Üí metadata["headers"] = ["H1", "H2", "H3"]
## H2 Again  ‚Üí stack: ["H1", "H2 Again"]  (H3 –≤—ã–±—Ä–æ—à–µ–Ω)
```

---

## üîç –î–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

### CODE –±–ª–æ–∫–∏

**Fence blocks:**

````markdown
```python
def hello():
    pass
```
````

**–û–±—Ä–∞–±–æ—Ç–∫–∞:**

```python
if token.type == "fence":
    info = token.info.strip()  # "python"
    language = info.split()[0] if info else None
    
    segment = ParsingSegment(
        content=token.content,
        segment_type=ChunkType.CODE,
        metadata={
            "headers": current_headers.copy(),
            "language": language
        }
    )
```

**Info-string –æ–±—Ä–∞–±–æ—Ç–∫–∞:**

```markdown
```python {highlight="2-5"}
# –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ ‚Üí "python"
```

### IMAGE_REF

**Markdown syntax:**

```markdown
![Alt text](/path/to/image.png "Optional title")
```

**Token structure:**

```
image
  attrs: [["src", "/path/to/image.png"], ["alt", "Alt text"], ["title", "Optional title"]]
```

**–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ:**

```python
segment = ParsingSegment(
    content=src,  # "/path/to/image.png"
    segment_type=ChunkType.IMAGE_REF,
    metadata={
        "alt": alt_text,
        "title": title_text,
        "headers": current_headers.copy()
    }
)
```

**–ó–∞—á–µ–º —Ö—Ä–∞–Ω–∏—Ç—å IMAGE_REF?**

- –î–ª—è Vision API (Phase 6) –Ω—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- Alt-text –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º)
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç: "—Å–∫—Ä–∏–Ω—à–æ—Ç –≤ —Ä–∞–∑–¥–µ–ª–µ Installation > Step 1"

---

## üß© –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä

### Nested Tokens

**–ü—Ä–æ–±–ª–µ–º–∞:** —Å–ø–∏—Å–∫–∏ –∏ blockquotes —Å–æ–∑–¥–∞—é—Ç –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å

**Input:**

```markdown
- Item 1
  - Nested 1
  - Nested 2
```

**Token Stream:**

```
bullet_list_open
  list_item_open
    paragraph_open
      inline("Item 1")
    paragraph_close
    bullet_list_open        ‚Üê nested!
      list_item_open
        paragraph_open
          inline("Nested 1")
```

**–†–µ—à–µ–Ω–∏–µ:** —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥

```python
def process_tokens(tokens, depth=0):
    for token in tokens:
        if token.type.endswith("_open"):
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É
            process_tokens(token.children, depth + 1)
        elif token.type == "inline":
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç
            collect_text(token, depth)
```

### Blockquotes

**Input:**

```markdown
> This is a quote
> with multiple lines
```

**–û–±—Ä–∞–±–æ—Ç–∫–∞:**

```python
if token.type == "blockquote_open":
    segment = ParsingSegment(
        content=extract_quote_content(token),
        segment_type=ChunkType.TEXT,
        metadata={
            "quote": True,  # –ü–æ–º–µ—á–∞–µ–º –¥–ª—è Context Strategy
            "headers": current_headers.copy()
        }
    )
```

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞

### –ü—Ä–∏–º–µ—Ä: –ü–ª–∞–Ω Phase 3

**Input:** `doc/ideas/phase_3/plan_phase_3.md`

**Output:**

```python
[
    ParsingSegment(
        content="# Phase 3: Integration API\n\n–¶–µ–ª—å —Ñ–∞–∑—ã...",
        segment_type=ChunkType.TEXT,
        metadata={"headers": ["Phase 3: Integration API"]}
    ),
    ParsingSegment(
        content="class SemanticIndex:\n    def __init__(...):",
        segment_type=ChunkType.CODE,
        metadata={
            "headers": ["Phase 3", "Implementation", "Descriptor"],
            "language": "python"
        }
    ),
    ParsingSegment(
        content="/images/descriptor_flow.png",
        segment_type=ChunkType.IMAGE_REF,
        metadata={
            "headers": ["Phase 3", "Architecture"],
            "alt": "Descriptor protocol flow diagram"
        }
    )
]
```

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:**

- 15 TEXT —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, —Å–ø–∏—Å–∫–∏)
- 8 CODE —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (Python –ø—Ä–∏–º–µ—Ä—ã)
- 2 IMAGE_REF (–¥–∏–∞–≥—Ä–∞–º–º—ã)
- –í—Å–µ –∏–º–µ—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ breadcrumbs

---

## üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ Pipeline

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ

```python
from semantic_core.processing.parsers import MarkdownNodeParser
from semantic_core.domain import Document

# 1. –°–æ–∑–¥–∞—ë–º –ø–∞—Ä—Å–µ—Ä
parser = MarkdownNodeParser()

# 2. –ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç
document = Document(content=markdown_text, metadata={"source": "tutorial.md"})
segments = parser.parse(document.content)

# 3. –ü–µ—Ä–µ–¥–∞—ë–º –≤ SmartSplitter (—Å–ª–µ–¥—É—é—â–∞—è —Å–µ—Ä–∏—è)
splitter = SmartSplitter(parser=parser, chunk_size=1000)
chunks = splitter.split(document)
```

### –ó–∞–º–µ–Ω–∞ SimpleSplitter

**–î–æ Phase 4:**

```python
from semantic_core.text_processing import SimpleSplitter

splitter = SimpleSplitter(chunk_size=500)
chunks = splitter.split_text(document.content)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: plain text chunks –±–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
```

**–ü–æ—Å–ª–µ Phase 4:**

```python
from semantic_core.processing.parsers import MarkdownNodeParser
from semantic_core.processing.splitters import SmartSplitter

parser = MarkdownNodeParser()
splitter = SmartSplitter(parser=parser, chunk_size=1000)
chunks = splitter.split(document)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: typed chunks —Å –∏–µ—Ä–∞—Ä—Ö–∏–µ–π
```

---

## üéì –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

### –ß—Ç–æ –¥–∞—ë—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥

‚úÖ **–¢–∏–ø–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞**
- –ö–∞–∂–¥—ã–π —á–∞–Ω–∫ –∑–Ω–∞–µ—Ç, —á—Ç–æ –æ–Ω —Ç–∞–∫–æ–µ (TEXT/CODE/IMAGE_REF)
- –†–∞–∑–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤

‚úÖ **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏**
- Breadcrumbs –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—É—Ç—å: "Database > Models > User"
- –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ç–µ—Ä—è–µ—Ç—Å—è –ø—Ä–∏ —Ä–∞–∑—Ä–µ–∑–∞–Ω–∏–∏

‚úÖ **–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–∏—Å–∫–∞**
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: "—Ç–æ–ª—å–∫–æ Python –∫–æ–¥"
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: "—Ç–æ–ª—å–∫–æ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ Installation"

‚úÖ **–û—Å–Ω–æ–≤–∞ –¥–ª—è Context Strategy**
- –°–ª–µ–¥—É—é—â–∞—è —Å–µ—Ä–∏—è –ø–æ–∫–∞–∂–µ—Ç, –∫–∞–∫ breadcrumbs –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞

üèóÔ∏è **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏**
- Parser: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- Splitter: —Ä–∞–∑–º–µ—Ä
- Context Strategy: –æ–±–æ–≥–∞—â–µ–Ω–∏–µ

üîß **–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å**
- –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π ChunkType (TABLE, DIAGRAM)
- –õ–µ–≥–∫–æ –∑–∞–º–µ–Ω–∏—Ç—å –ø–∞—Ä—Å–µ—Ä (RST, AsciiDoc)

üìä **–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞**
- –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ–ª—É—á–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã—à–µ –Ω–∞ 30-40%

---

## üîó –°–≤—è–∑—å —Å –¥—Ä—É–≥–∏–º–∏ —Å–µ—Ä–∏—è–º–∏

**–ü—Ä–µ–¥—ã–¥—É—â–∏–µ:**
- [08: Chunking Strategy](08_chunking_strategy.md) ‚Äî –±–∞–∑–æ–≤—ã–π SimpleSplitter
- [09: Parent-Child Retrieval](09_parent_child_retrieval.md) ‚Äî –º–æ—Ç–∏–≤–∞—Ü–∏—è –¥–ª—è —á–∞–Ω–∫–æ–≤

**–°–ª–µ–¥—É—é—â–∏–µ:**
- [16: Smart Splitting Strategy](16_smart_splitting.md) ‚Äî –∫–∞–∫ –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ —á–∞–Ω–∫–∏
- [17: Hierarchical Context](17_hierarchical_context.md) ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ breadcrumbs
- [18: Granular Search](18_granular_search.md) ‚Äî –ø–æ–∏—Å–∫ –ø–æ —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —á–∞–Ω–∫–∞–º

---

**–°–µ—Ä–∏—è 1 –∏–∑ 4 (Phase 4)**  
**–î–∞—Ç–∞:** 2 –¥–µ–∫–∞–±—Ä—è 2025  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ
