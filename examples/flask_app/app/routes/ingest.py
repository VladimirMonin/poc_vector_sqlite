"""Ingest routes ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏.

Blueprints:
    ingest_bp: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤, —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —É–¥–∞–ª–µ–Ω–∏–µ.

Endpoints:
    GET /ingest ‚Äî –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∑–∫–∏
    POST /ingest/upload ‚Äî –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
    GET /documents ‚Äî –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    POST /documents/<id>/delete ‚Äî –£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    POST /documents/<id>/reindex ‚Äî –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
"""

from pathlib import Path

from flask import (
    Blueprint,
    current_app,
    render_template,
    request,
    redirect,
    url_for,
    flash,
    jsonify,
    send_file,
    abort,
)

from app.services.upload_service import UploadService
from semantic_core.domain import Document
from semantic_core.infrastructure.storage.peewee.models import (
    DocumentModel,
    ChunkModel,
)
from semantic_core.utils.logger import get_logger

logger = get_logger("flask_app.routes.ingest")

ingest_bp = Blueprint("ingest", __name__)

# –ü–æ—Ä–æ–≥ –¥–ª—è async processing
ASYNC_THRESHOLD = 5


def _get_upload_service() -> UploadService:
    """–ü–æ–ª—É—á–∏—Ç—å UploadService –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    upload_dir = Path(current_app.instance_path) / "uploads"
    return UploadService(upload_dir=upload_dir)


def _get_document_stats(doc_id: int) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    chunks = ChunkModel.select().where(ChunkModel.document_id == doc_id)

    stats = {
        "total": 0,
        "text": 0,
        "code": 0,
        "image": 0,
        "audio": 0,
        "video": 0,
        "pending": 0,
    }

    for chunk in chunks:
        stats["total"] += 1
        chunk_type = chunk.chunk_type
        if chunk_type == "text":
            stats["text"] += 1
        elif chunk_type == "code":
            stats["code"] += 1
        elif chunk_type == "image_ref":
            stats["image"] += 1
        elif chunk_type == "audio_ref":
            stats["audio"] += 1
        elif chunk_type == "video_ref":
            stats["video"] += 1

        if chunk.embedding_status == "pending":
            stats["pending"] += 1

    return stats


@ingest_bp.route("/ingest")
def upload_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤.

    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç drag-n-drop —Ñ–æ—Ä–º—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.
    """
    core = current_app.extensions.get("semantic_core")

    return render_template(
        "ingest.html",
        core_available=core is not None,
    )


@ingest_bp.route("/ingest/upload", methods=["POST"])
def upload_files():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è.

    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç multiple files, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ uploads/,
    –∑–∞–ø—É—Å–∫–∞–µ—Ç ingest() –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ ingest_image() –¥–ª—è –º–µ–¥–∏–∞.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã:
        - –î–æ–∫—É–º–µ–Ω—Ç—ã: .md, .markdown, .txt
        - –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: .png, .jpg, .jpeg, .gif, .webp
        - –ê—É–¥–∏–æ: .mp3, .wav, .ogg (–±—É–¥—É—â–µ–µ)
        - –í–∏–¥–µ–æ: .mp4, .webm (–±—É–¥—É—â–µ–µ)

    Returns:
        Redirect –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å flash-—Å–æ–æ–±—â–µ–Ω–∏–µ–º.
    """
    core = current_app.extensions.get("semantic_core")
    if not core:
        flash("SemanticCore –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á.", "danger")
        return redirect(url_for("ingest.upload_page"))

    files = request.files.getlist("files")
    if not files or all(f.filename == "" for f in files):
        flash("–§–∞–π–ª—ã –Ω–µ –≤—ã–±—Ä–∞–Ω—ã", "warning")
        return redirect(url_for("ingest.upload_page"))

    upload_service = _get_upload_service()
    uploaded_files: dict[str, Path] = {}
    text_files: list[Path] = []  # .md, .markdown, .txt
    image_files: list[Path] = []  # .png, .jpg, .jpeg, .gif, .webp
    audio_files: list[Path] = []  # .mp3, .wav, .ogg, .m4a, .flac
    video_files: list[Path] = []  # .mp4, .webm, .mov, .avi
    errors: list[str] = []

    # –†–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    TEXT_EXTENSIONS = {".md", ".markdown", ".txt"}
    IMAGE_EXTENSIONS = {".png", ".jpg", ".jpeg", ".gif", ".webp"}
    AUDIO_EXTENSIONS = {".mp3", ".wav", ".ogg", ".m4a", ".flac"}
    VIDEO_EXTENSIONS = {".mp4", ".webm", ".mov", ".avi"}

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    for file in files:
        if file.filename:
            result = upload_service.save_file(file.stream, file.filename)
            if result.success:
                uploaded_files[result.original_name] = result.path
                ext = result.path.suffix.lower()
                if ext in TEXT_EXTENSIONS:
                    text_files.append(result.path)
                elif ext in IMAGE_EXTENSIONS:
                    image_files.append(result.path)
                elif ext in AUDIO_EXTENSIONS:
                    audio_files.append(result.path)
                elif ext in VIDEO_EXTENSIONS:
                    video_files.append(result.path)
            else:
                errors.append(f"{result.original_name}: {result.error}")

    if errors:
        for error in errors:
            flash(error, "danger")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º (sync/async)
    total_files = len(text_files) + len(image_files) + len(audio_files) + len(video_files)
    mode = "async" if total_files >= ASYNC_THRESHOLD else "sync"
    logger.info(
        f"üì§ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(files)} —Ñ–∞–π–ª–æ–≤ "
        f"(text={len(text_files)}, images={len(image_files)}, "
        f"audio={len(audio_files)}, video={len(video_files)}), mode={mode}"
    )

    ingested_docs = 0
    ingested_images = 0
    ingested_audio = 0
    ingested_video = 0

    # === –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã (.md, .markdown, .txt) ===
    for text_path in text_files:
        try:
            # –î–ª—è Markdown ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –º–µ–¥–∏–∞
            if text_path.suffix.lower() in (".md", ".markdown"):
                content = upload_service.process_markdown_paths(
                    text_path,
                    {Path(name).name: path for name, path in uploaded_files.items()},
                )
            else:
                # –î–ª—è .txt ‚Äî –ø—Ä–æ—Å—Ç–æ —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                content = text_path.read_text(encoding="utf-8")

            # –°–æ–∑–¥–∞—ë–º –¥–æ–∫—É–º–µ–Ω—Ç
            doc = Document(
                content=content,
                metadata={
                    "title": text_path.stem.replace("_", " ").title(),
                    "source": str(text_path),
                    "source_type": "upload",
                },
            )

            # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
            core.ingest(doc, mode=mode)
            ingested_docs += 1

        except Exception as e:
            logger.error(f"üî• –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {text_path}: {e}")
            flash(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {text_path.name}: {e}", "danger")

    # === –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Vision API ===
    for image_path in image_files:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ image_analyzer
            if core.image_analyzer is None:
                logger.warning(f"‚ö†Ô∏è ImageAnalyzer –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º {image_path.name}")
                flash(f"‚ö†Ô∏è {image_path.name}: Vision API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω", "warning")
                continue

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Vision API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            logger.info(f"üñºÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path.name}")
            core.ingest_image(str(image_path), mode=mode)
            ingested_images += 1

        except Exception as e:
            logger.error(f"üî• –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            flash(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {image_path.name}: {e}", "danger")

    # === –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Audio API ===
    for audio_path in audio_files:
        try:
            if core.audio_analyzer is None:
                logger.warning(f"‚ö†Ô∏è AudioAnalyzer –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º {audio_path.name}")
                flash(f"‚ö†Ô∏è {audio_path.name}: Audio API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω", "warning")
                continue

            logger.info(f"üéµ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—É–¥–∏–æ: {audio_path.name}")
            core.ingest_audio(str(audio_path), mode=mode)
            ingested_audio += 1

        except Exception as e:
            logger.error(f"üî• –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∞—É–¥–∏–æ {audio_path}: {e}")
            flash(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {audio_path.name}: {e}", "danger")

    # === –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Video API ===
    for video_path in video_files:
        try:
            if core.video_analyzer is None:
                logger.warning(f"‚ö†Ô∏è VideoAnalyzer –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º {video_path.name}")
                flash(f"‚ö†Ô∏è {video_path.name}: Video API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω", "warning")
                continue

            logger.info(f"üé¨ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ: {video_path.name}")
            core.ingest_video(str(video_path), mode=mode)
            ingested_video += 1

        except Exception as e:
            logger.error(f"üî• –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤–∏–¥–µ–æ {video_path}: {e}")
            flash(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {video_path.name}: {e}", "danger")

    # === –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ ===
    total_ingested = ingested_docs + ingested_images + ingested_audio + ingested_video
    if total_ingested > 0:
        parts = []
        if ingested_docs > 0:
            parts.append(f"{ingested_docs} –¥–æ–∫—É–º–µ–Ω—Ç(–æ–≤)")
        if ingested_images > 0:
            parts.append(f"{ingested_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        if ingested_audio > 0:
            parts.append(f"{ingested_audio} –∞—É–¥–∏–æ")
        if ingested_video > 0:
            parts.append(f"{ingested_video} –≤–∏–¥–µ–æ")

        message = f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {', '.join(parts)}"
        if mode == "async":
            message += " (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —Ñ–æ–Ω–µ)"

        flash(message, "success")
    elif not errors:
        flash("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏", "warning")

    return redirect(url_for("ingest.documents_page"))


@ingest_bp.route("/documents")
def documents_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —á–∞–Ω–∫–∞—Ö.
    """
    core = current_app.extensions.get("semantic_core")

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    documents = []
    for doc in DocumentModel.select().order_by(DocumentModel.created_at.desc()):
        stats = _get_document_stats(doc.id)

        # metadata –º–æ–∂–µ—Ç –±—ã—Ç—å dict –∏–ª–∏ —Å—Ç—Ä–æ–∫–æ–π (JSON) –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä—Å–∏–∏
        meta = doc.metadata
        if isinstance(meta, str):
            import json

            try:
                meta = json.loads(meta)
            except (json.JSONDecodeError, TypeError):
                meta = {}

        documents.append(
            {
                "id": doc.id,
                "title": meta.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
                if isinstance(meta, dict)
                else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è",
                "source": meta.get("source", "‚Äî") if isinstance(meta, dict) else "‚Äî",
                "created_at": doc.created_at,
                "stats": stats,
                "has_pending": stats["pending"] > 0,
            }
        )

    return render_template(
        "documents.html",
        documents=documents,
        core_available=core is not None,
    )


@ingest_bp.route("/documents/<int:doc_id>")
def document_detail(doc_id: int):
    """–î–µ—Ç–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –≤—Å–µ –µ–≥–æ —á–∞–Ω–∫–∏.
    """
    import json

    core = current_app.extensions.get("semantic_core")

    doc = DocumentModel.get_or_none(DocumentModel.id == doc_id)
    if not doc:
        flash("–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", "warning")
        return redirect(url_for("ingest.documents_page"))

    # –ü–∞—Ä—Å–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta = doc.metadata
    if isinstance(meta, str):
        try:
            meta = json.loads(meta)
        except (json.JSONDecodeError, TypeError):
            meta = {}

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    chunks = list(
        ChunkModel.select()
        .where(ChunkModel.document_id == doc_id)
        .order_by(ChunkModel.chunk_index)
    )

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–µ–¥–∏–∞ –∏–∑ chunk_type –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞ (–Ω–∞–¥—ë–∂–Ω–µ–µ —á–µ–º metadata)
    # –ë–∞–≥: CLI –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç media_type –≤ metadata –¥–æ–∫—É–º–µ–Ω—Ç–∞
    CHUNK_TYPE_TO_MEDIA = {
        "image_ref": "image",
        "audio_ref": "audio",
        "video_ref": "video",
        "text": "text",
        "code": "text",
    }
    first_chunk = chunks[0] if chunks else None
    media_type = CHUNK_TYPE_TO_MEDIA.get(first_chunk.chunk_type, "text") if first_chunk else "text"

    media_icons = {
        "text": "bi-file-text",
        "image": "bi-image",
        "audio": "bi-music-note",
        "video": "bi-camera-video",
    }

    return render_template(
        "document_detail.html",
        document=doc,
        meta=meta,
        chunks=chunks,
        media_type=media_type,
        media_icon=media_icons.get(media_type, "bi-file-earmark"),
        core_available=core is not None,
    )


@ingest_bp.route("/documents/<int:doc_id>/delete", methods=["POST"])
def delete_document(doc_id: int):
    """–£–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏ –≤—Å–µ –µ–≥–æ —á–∞–Ω–∫–∏.

    HTMX endpoint ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏.
    """
    core = current_app.extensions.get("semantic_core")
    if not core:
        return jsonify({"error": "Core –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}), 500

    try:
        deleted = core.delete(doc_id)
        logger.info(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω –¥–æ–∫—É–º–µ–Ω—Ç {doc_id}, {deleted} –∑–∞–ø–∏—Å–µ–π")

        # –î–ª—è HTMX ‚Äî –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç —É–¥–∞–ª—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç
        if request.headers.get("HX-Request"):
            return "", 200

        flash(f"–î–æ–∫—É–º–µ–Ω—Ç —É–¥–∞–ª—ë–Ω ({deleted} –∑–∞–ø–∏—Å–µ–π)", "success")
        return redirect(url_for("ingest.documents_page"))

    except Exception as e:
        logger.error(f"üî• –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id}: {e}")
        if request.headers.get("HX-Request"):
            return jsonify({"error": str(e)}), 500
        flash(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}", "danger")
        return redirect(url_for("ingest.documents_page"))


@ingest_bp.route("/documents/<int:doc_id>/reindex", methods=["POST"])
def reindex_document(doc_id: int):
    """–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç.

    –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏ –∏ —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–µ.
    """
    core = current_app.extensions.get("semantic_core")
    if not core:
        flash("Core –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", "danger")
        return redirect(url_for("ingest.documents_page"))

    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        doc_model = DocumentModel.get_or_none(DocumentModel.id == doc_id)
        if not doc_model:
            flash("–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", "warning")
            return redirect(url_for("ingest.documents_page"))

        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        source = doc_model.metadata.get("source") if doc_model.metadata else None
        if not source or not Path(source).exists():
            flash("–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", "warning")
            return redirect(url_for("ingest.documents_page"))

        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        content = Path(source).read_text(encoding="utf-8")

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
        core.delete(doc_id)

        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
        doc = Document(
            content=content,
            metadata=doc_model.metadata or {},
        )
        core.ingest(doc)

        flash("–î–æ–∫—É–º–µ–Ω—Ç –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω", "success")

    except Exception as e:
        logger.error(f"üî• –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {doc_id}: {e}")
        flash(f"–û—à–∏–±–∫–∞: {e}", "danger")

    return redirect(url_for("ingest.documents_page"))


@ingest_bp.route("/media/<int:doc_id>")
def serve_media(doc_id: int):
    """–û—Ç–¥–∞—Ç—å –º–µ–¥–∏–∞ —Ñ–∞–π–ª –¥–æ–∫—É–º–µ–Ω—Ç–∞.

    –ß–∏—Ç–∞–µ—Ç –ø—É—Ç—å –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –æ—Ç–¥–∞—ë—Ç —Ñ–∞–π–ª.
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏ —Ç–∏–ø —Ñ–∞–π–ª–∞.
    """
    import json
    import mimetypes

    doc = DocumentModel.get_or_none(DocumentModel.id == doc_id)
    if not doc:
        abort(404)

    # –ü–∞—Ä—Å–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta = doc.metadata
    if isinstance(meta, str):
        try:
            meta = json.loads(meta)
        except (json.JSONDecodeError, TypeError):
            meta = {}

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    source = meta.get("source", "")
    if not source:
        abort(404)

    file_path = Path(source)
    
    # –ï—Å–ª–∏ –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –∏—â–µ–º –æ—Ç –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
    if not file_path.is_absolute():
        # root_path = examples/flask_app/app, –Ω—É–∂–Ω–æ 3 —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö –¥–æ poc_vector_sqlite
        project_root = Path(current_app.root_path).parent.parent.parent
        file_path = project_root / source
    
    if not file_path.exists():
        abort(404)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º MIME type
    mime_type, _ = mimetypes.guess_type(str(file_path))
    if not mime_type:
        mime_type = "application/octet-stream"

    return send_file(
        file_path,
        mimetype=mime_type,
        as_attachment=False,
    )
