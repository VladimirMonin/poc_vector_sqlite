"""Ð¡ÐµÑ€Ð²Ð¸Ñ Ñ‡Ð°Ñ‚Ð° Ñ RAG-Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸ÐµÐ¹.

ÐžÑ€ÐºÐµÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÑ‚ RAGEngine Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ñ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼Ð¸.
Ð£Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÐµÐ¹ Ñ‡Ð°Ñ‚Ð° Ñ‡ÐµÑ€ÐµÐ· ChatSessionModel.

Classes:
    ChatService: Ð¤Ð°ÑÐ°Ð´ Ð´Ð»Ñ RAG-Ñ‡Ð°Ñ‚Ð° Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÐµÐ¹.
    ChatResponse: DTO Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ‡Ð°Ñ‚Ð°.
    SourceItem: DTO Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°.

Usage:
    service = ChatService(core, llm, cache, db)
    response = service.ask("ÐšÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð³Ð¸Ð±Ñ€Ð¸Ð´Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº?", session_id=session_id)
"""

import json
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Optional

from peewee import Database

from semantic_core.core.rag import RAGEngine, RAGResult
from semantic_core.interfaces.chat_history import ChatMessage
from semantic_core.utils.logger import get_logger

from app.models.chat import ChatSessionModel, ChatMessageModel

if TYPE_CHECKING:
    from semantic_core.pipeline import SemanticCore
    from semantic_core.interfaces.llm import BaseLLMProvider
    from app.services.cache_service import QueryCacheService

logger = get_logger("flask_app.chat")


@dataclass
class SourceItem:
    """Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.

    Attributes:
        index: Ð˜Ð½Ð´ÐµÐºÑ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ° (1, 2, 3...).
        title: Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°.
        chunk_type: Ð¢Ð¸Ð¿ Ñ‡Ð°Ð½ÐºÐ° (text, code, etc.).
        score: Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ.
        content_preview: ÐŸÑ€ÐµÐ²ÑŒÑŽ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°.
        doc_id: ID Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð° Ð´Ð»Ñ ÑÑÑ‹Ð»ÐºÐ¸.
    """

    index: int
    title: str
    chunk_type: str
    score: float
    content_preview: str
    doc_id: int


@dataclass
class ChatResponse:
    """ÐžÑ‚Ð²ÐµÑ‚ Ñ‡Ð°Ñ‚Ð° Ñ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼Ð¸.

    Attributes:
        answer: Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚.
        sources: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð².
        session_id: ID ÑÐµÑÑÐ¸Ð¸.
        message_id: ID ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.
        tokens_used: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ‚Ð¾ÐºÐµÐ½Ñ‹ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.
        total_tokens: ÐžÐ±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² ÑÐµÑÑÐ¸Ð¸.
        has_sources: ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð»Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸.
    """

    answer: str
    sources: list[SourceItem]
    session_id: str
    message_id: int
    tokens_used: Optional[int] = None
    total_tokens: int = 0
    has_sources: bool = True


class ChatService:
    """Ð¡ÐµÑ€Ð²Ð¸Ñ RAG-Ñ‡Ð°Ñ‚Ð° Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÐµÐ¹.

    ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚:
    - RAGEngine Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
    - ChatSessionModel Ð´Ð»Ñ Ð¿ÐµÑ€ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸
    - QueryCacheService Ð´Ð»Ñ ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²

    Attributes:
        rag: RAGEngine Ð´Ð»Ñ Retrieval-Augmented Generation.
        cache: ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÑÑˆ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð².
        db: Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ chat Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.

    Example:
        >>> service = ChatService(core=core, llm=llm, cache=cache, database=db)
        >>> response = service.ask("Ð§Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ RAG?", session_id=None)
        >>> print(response.answer)
        >>> print([s.title for s in response.sources])
    """

    def __init__(
        self,
        core: "SemanticCore",
        llm: "BaseLLMProvider",
        database: Database,
        cache: Optional["QueryCacheService"] = None,
        context_chunks: int = 5,
    ):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐµÑ€Ð²Ð¸ÑÐ°.

        Args:
            core: SemanticCore Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°.
            llm: LLM Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸.
            database: Peewee Ð±Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ….
            cache: ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÑÑˆ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð².
            context_chunks: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‡Ð°Ð½ÐºÐ¾Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°.
        """
        self.rag = RAGEngine(
            core=core,
            llm=llm,
            context_chunks=context_chunks,
        )
        self.cache = cache
        self.db = database

        # ÐŸÑ€Ð¸Ð²ÑÐ·Ñ‹Ð²Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ðº Ð±Ð°Ð·Ðµ
        ChatSessionModel._meta.database = database
        ChatMessageModel._meta.database = database

        # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
        database.create_tables([ChatSessionModel, ChatMessageModel], safe=True)

        logger.info(
            "ChatService initialized",
            llm_model=llm.model_name,
            context_chunks=context_chunks,
            cache_enabled=cache is not None,
        )

    def ask(
        self,
        question: str,
        session_id: Optional[str] = None,
        search_mode: str = "hybrid",
        temperature: float = 0.7,
    ) -> ChatResponse:
        """Ð—Ð°Ð´Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ RAG-Ð¾Ñ‚Ð²ÐµÑ‚.

        Args:
            question: Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.
            session_id: ID ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ ÑÐµÑÑÐ¸Ð¸ (None Ð´Ð»Ñ Ð½Ð¾Ð²Ð¾Ð¹).
            search_mode: Ð ÐµÐ¶Ð¸Ð¼ Ð¿Ð¾Ð¸ÑÐºÐ° (hybrid/vector/fts).
            temperature: Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸.

        Returns:
            ChatResponse Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼Ð¸.

        Raises:
            ValueError: Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿ÑƒÑÑ‚Ð¾Ð¹.
        """
        if not question or not question.strip():
            raise ValueError("Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÑƒÑÑ‚Ñ‹Ð¼")

        question = question.strip()

        logger.info(
            "ðŸ’¬ Chat question",
            question_length=len(question),
            session_id=session_id,
            search_mode=search_mode,
        )

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð»Ð¸ ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ ÑÐµÑÑÐ¸ÑŽ
        session = self._get_or_create_session(session_id)

        # Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ â€” ÑƒÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
        if session.message_count == 0:
            session.set_title_from_question(question)

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        ChatMessageModel.add_user_message(session, question)

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ RAG
        history = self._build_history(session)

        # ÐšÑÑˆÐ¸Ñ€ÑƒÐµÐ¼ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ cache
        if self.cache:
            try:
                self.cache.get_or_create_embedding(question)
            except Exception as e:
                logger.warning(f"Cache error: {e}")

        # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ RAG
        try:
            rag_result = self.rag.ask(
                query=question,
                search_mode=search_mode,  # type: ignore
                temperature=temperature,
                history=history if history else None,
            )
        except Exception as e:
            logger.error(f"ðŸ”¥ RAG error: {e}")
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÑƒ ÐºÐ°Ðº Ð¾Ñ‚Ð²ÐµÑ‚
            error_msg = f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð°: {str(e)}"
            msg = ChatMessageModel.add_assistant_message(
                session,
                error_msg,
                sources_json=None,
                tokens_used=None,
            )
            return ChatResponse(
                answer=error_msg,
                sources=[],
                session_id=session.session_id,
                message_id=msg.id,
                has_sources=False,
            )

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸
        sources = self._extract_sources(rag_result)
        sources_json = json.dumps([s.__dict__ for s in sources], ensure_ascii=False)

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚
        msg = ChatMessageModel.add_assistant_message(
            session,
            rag_result.answer,
            sources_json=sources_json,
            tokens_used=rag_result.total_tokens,
        )

        # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² ÑÐµÑÑÐ¸Ð¸
        total_tokens = self.get_session_total_tokens(session.session_id)

        logger.info(
            "âœ… Chat response generated",
            session_id=session.session_id,
            sources_count=len(sources),
            tokens=rag_result.total_tokens,
            total_tokens=total_tokens,
        )

        return ChatResponse(
            answer=rag_result.answer,
            sources=sources,
            session_id=session.session_id,
            message_id=msg.id,
            tokens_used=rag_result.total_tokens,
            total_tokens=total_tokens,
            has_sources=len(sources) > 0,
        )

    def get_session(self, session_id: str) -> Optional[ChatSessionModel]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ Ð¿Ð¾ ID.

        Args:
            session_id: UUID ÑÐµÑÑÐ¸Ð¸.

        Returns:
            Ð¡ÐµÑÑÐ¸Ñ Ð¸Ð»Ð¸ None.
        """
        try:
            return ChatSessionModel.get(ChatSessionModel.session_id == session_id)
        except ChatSessionModel.DoesNotExist:
            return None

    def get_session_messages(self, session_id: str) -> list[ChatMessageModel]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²ÑÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ÑÐµÑÑÐ¸Ð¸.

        Args:
            session_id: UUID ÑÐµÑÑÐ¸Ð¸.

        Returns:
            Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð² Ñ…Ñ€Ð¾Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼ Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ.
        """
        session = self.get_session(session_id)
        if not session:
            return []

        return list(
            ChatMessageModel.select()
            .where(ChatMessageModel.session == session)
            .order_by(ChatMessageModel.created_at)
        )

    def get_recent_sessions(self, limit: int = 10) -> list[ChatSessionModel]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÐµÑÑÐ¸Ð¸.

        Args:
            limit: ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ ÑÐµÑÑÐ¸Ð¹.

        Returns:
            Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐµÑÑÐ¸Ð¹, Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ updated_at DESC.
        """
        return list(
            ChatSessionModel.select()
            .where(ChatSessionModel.is_active == True)
            .order_by(ChatSessionModel.updated_at.desc())
            .limit(limit)
        )

    def clear_session(self, session_id: str) -> bool:
        """ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÑÐµÑÑÐ¸Ð¸ (soft delete).

        Ð”ÐµÐ°ÐºÑ‚Ð¸Ð²Ð¸Ñ€ÑƒÐµÑ‚ ÑÐµÑÑÐ¸ÑŽ Ð²Ð¼ÐµÑÑ‚Ð¾ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ.

        Args:
            session_id: UUID ÑÐµÑÑÐ¸Ð¸.

        Returns:
            True ÐµÑÐ»Ð¸ ÑÐµÑÑÐ¸Ñ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð¸ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð°.
        """
        session = self.get_session(session_id)
        if not session:
            return False

        session.is_active = False
        session.save()

        logger.info(f"ðŸ—‘ï¸ Session cleared: {session_id}")
        return True

    def delete_message(self, message_id: int) -> Optional[str]:
        """Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¸Ð· Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸.

        Args:
            message_id: ID ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.

        Returns:
            session_id ÐµÑÐ»Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾, None ÐµÑÐ»Ð¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾.
        """
        try:
            message = ChatMessageModel.get_by_id(message_id)
            session = message.session
            session_id = session.session_id
            message.delete_instance()
            session.touch()
            logger.info(f"ðŸ—‘ï¸ Message deleted: {message_id}")
            return session_id
        except ChatMessageModel.DoesNotExist:
            return None

    def get_session_total_tokens(self, session_id: str) -> int:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² ÑÐµÑÑÐ¸Ð¸.

        Args:
            session_id: UUID ÑÐµÑÑÐ¸Ð¸.

        Returns:
            Ð¡ÑƒÐ¼Ð¼Ð° Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð²ÑÐµÑ… assistant-ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹.
        """
        session = self.get_session(session_id)
        if not session:
            return 0

        from peewee import fn

        result = (
            ChatMessageModel.select(fn.SUM(ChatMessageModel.tokens_used))
            .where(
                (ChatMessageModel.session == session)
                & (ChatMessageModel.tokens_used.is_null(False))
            )
            .scalar()
        )
        return result or 0

    def delete_session(self, session_id: str) -> bool:
        """ÐŸÐ¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ Ñ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÑÐ¼Ð¸.

        Args:
            session_id: UUID ÑÐµÑÑÐ¸Ð¸.

        Returns:
            True ÐµÑÐ»Ð¸ ÑÐµÑÑÐ¸Ñ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð°.
        """
        session = self.get_session(session_id)
        if not session:
            return False

        # CASCADE ÑƒÐ´Ð°Ð»Ð¸Ñ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
        session.delete_instance()

        logger.info(f"ðŸ—‘ï¸ Session deleted: {session_id}")
        return True

    def _get_or_create_session(self, session_id: Optional[str]) -> ChatSessionModel:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð¸Ð»Ð¸ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¾Ð²ÑƒÑŽ ÑÐµÑÑÐ¸ÑŽ.

        Args:
            session_id: UUID ÑÐµÑÑÐ¸Ð¸ Ð¸Ð»Ð¸ None.

        Returns:
            ChatSessionModel.
        """
        if session_id:
            session = self.get_session(session_id)
            if session:
                return session
            logger.warning(f"Session not found: {session_id}, creating new")

        return ChatSessionModel.create_new()

    def _build_history(self, session: ChatSessionModel) -> list[ChatMessage]:
        """Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ñ‡Ð°Ñ‚Ð° Ð´Ð»Ñ RAG.

        Args:
            session: Ð¡ÐµÑÑÐ¸Ñ Ñ‡Ð°Ñ‚Ð°.

        Returns:
            Ð¡Ð¿Ð¸ÑÐ¾Ðº ChatMessage Ð´Ð»Ñ RAGEngine.
        """
        messages = (
            ChatMessageModel.select()
            .where(ChatMessageModel.session == session)
            .order_by(ChatMessageModel.created_at)
            .limit(20)  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
        )

        history = []
        for msg in messages:
            role = "user" if msg.is_user() else "assistant"
            history.append(ChatMessage(role=role, content=msg.content))  # type: ignore

        return history

    def _extract_sources(self, rag_result: RAGResult) -> list[SourceItem]:
        """Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð¸Ð· RAG Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°.

        Args:
            rag_result: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ RAGEngine.ask().

        Returns:
            Ð¡Ð¿Ð¸ÑÐ¾Ðº SourceItem Ð´Ð»Ñ UI.
        """
        sources = []

        for i, chunk in enumerate(rag_result.sources, 1):
            # ÐŸÑ€ÐµÐ²ÑŒÑŽ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
            content = chunk.content
            if len(content) > 150:
                content = content[:147] + "..."

            sources.append(
                SourceItem(
                    index=i,
                    title=chunk.parent_doc_title or f"Doc #{chunk.parent_doc_id}",
                    chunk_type=chunk.chunk_type.value,
                    score=chunk.score,
                    content_preview=content,
                    doc_id=chunk.parent_doc_id,
                )
            )

        return sources


__all__ = ["ChatService", "ChatResponse", "SourceItem"]
