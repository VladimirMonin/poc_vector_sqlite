"""CLI –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—á–µ—Ä–µ–¥—è–º–∏.

–ö–æ–º–∞–Ω–¥—ã:
    status: –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–µ–π (text/media).
    flush: –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç pending —á–∞–Ω–∫–∏ –≤ Batch API.
    retry: –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ—Ç failed –∑–∞–¥–∞—á–∏.
"""

import json
from typing import Optional

import typer
from rich.console import Console
from rich.table import Table

from semantic_core.utils.logger import get_logger

logger = get_logger(__name__)
console = Console()

queue_cmd = typer.Typer(
    name="queue",
    help="üì¶ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥—è–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏.",
    no_args_is_help=True,
)


def _get_text_stats() -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—á–µ—Ä–µ–¥–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤.

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—á—ë—Ç—á–∏–∫–∞–º–∏ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º.
    """
    from semantic_core.infrastructure.storage.peewee.models import (
        ChunkModel,
        EmbeddingStatus,
    )

    return {
        "pending": ChunkModel.select()
        .where(ChunkModel.embedding_status == EmbeddingStatus.PENDING.value)
        .count(),
        "processing": ChunkModel.select()
        .where(
            (ChunkModel.embedding_status == EmbeddingStatus.PENDING.value)
            & (ChunkModel.batch_job.is_null(False))
        )
        .count(),
        "ready": ChunkModel.select()
        .where(ChunkModel.embedding_status == EmbeddingStatus.READY.value)
        .count(),
        "failed": ChunkModel.select()
        .where(ChunkModel.embedding_status == EmbeddingStatus.FAILED.value)
        .count(),
    }


def _get_media_stats() -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—á–µ—Ä–µ–¥–∏ –º–µ–¥–∏–∞ –∑–∞–¥–∞—á.

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—á—ë—Ç—á–∏–∫–∞–º–∏ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º.
    """
    from semantic_core.infrastructure.storage.peewee.models import MediaTaskModel
    from semantic_core.domain.media import TaskStatus

    return {
        "pending": MediaTaskModel.select()
        .where(MediaTaskModel.status == TaskStatus.PENDING.value)
        .count(),
        "processing": MediaTaskModel.select()
        .where(MediaTaskModel.status == TaskStatus.PROCESSING.value)
        .count(),
        "completed": MediaTaskModel.select()
        .where(MediaTaskModel.status == TaskStatus.COMPLETED.value)
        .count(),
        "failed": MediaTaskModel.select()
        .where(MediaTaskModel.status == TaskStatus.FAILED.value)
        .count(),
    }


def _render_stats_table(title: str, stats: dict, status_map: dict) -> Table:
    """–°–æ–∑–¥–∞—Ç—å Rich —Ç–∞–±–ª–∏—Ü—É —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π.

    Args:
        title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã.
        stats: –°–ª–æ–≤–∞—Ä—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.
        status_map: –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞—Ç—É—Å ‚Üí (emoji, –Ω–∞–∑–≤–∞–Ω–∏–µ).

    Returns:
        Rich Table –¥–ª—è –≤—ã–≤–æ–¥–∞.
    """
    table = Table(title=title, show_header=True, header_style="bold")
    table.add_column("Status", style="cyan")
    table.add_column("Count", justify="right")

    for key, (emoji, label) in status_map.items():
        count = stats.get(key, 0)
        table.add_row(f"{emoji} {label}", str(count))

    return table


@queue_cmd.command("status")
def queue_status() -> None:
    """üìä –ü–æ–∫–∞–∑–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–µ–π.

    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ—á–µ—Ä–µ–¥—è–º:
    - Text Embeddings (Batch API)
    - Media Analysis (Local Queue)
    """
    from semantic_core.cli.app import get_cli_context

    ctx = get_cli_context()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
    try:
        core = ctx.get_core()
    except Exception as e:
        if ctx.json_output:
            console.print_json(json.dumps({"error": str(e)}))
        else:
            console.print(f"[red]‚ùå –û—à–∏–±–∫–∞:[/red] {e}")
        raise typer.Exit(1)

    logger.debug("Getting queue stats")

    try:
        text_stats = _get_text_stats()
        media_stats = _get_media_stats()
    except Exception as e:
        if ctx.json_output:
            console.print_json(json.dumps({"error": str(e)}))
        else:
            console.print(f"[red]‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:[/red] {e}")
        raise typer.Exit(1)

    if ctx.json_output:
        output = {
            "text_embeddings": text_stats,
            "media": media_stats,
        }
        console.print_json(json.dumps(output))
        return

    # Rich output
    console.print()
    console.print("[bold]üì¶ Queue Status[/bold]")
    console.print()

    # Text embeddings table
    text_map = {
        "pending": ("üîµ", "Pending"),
        "processing": ("üü°", "Processing"),
        "ready": ("üü¢", "Ready"),
        "failed": ("üî¥", "Failed"),
    }
    text_table = _render_stats_table(
        "Text Embeddings (Batch API)",
        text_stats,
        text_map,
    )
    console.print(text_table)
    console.print()

    # Media table
    media_map = {
        "pending": ("üîµ", "Pending"),
        "processing": ("üü°", "Processing"),
        "completed": ("üü¢", "Completed"),
        "failed": ("üî¥", "Failed"),
    }
    media_table = _render_stats_table(
        "Media Analysis (Local Queue)",
        media_stats,
        media_map,
    )
    console.print(media_table)
    console.print()

    # Tip
    total_pending = text_stats.get("pending", 0) + media_stats.get("pending", 0)
    if total_pending > 0:
        console.print(
            "[dim]üí° Tip: Run 'semantic worker run-once' to process pending tasks[/dim]"
        )


@queue_cmd.command("flush")
def queue_flush(
    min_size: int = typer.Option(
        0,
        "--min-size",
        "-m",
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è —Å force).",
    ),
    force: bool = typer.Option(
        True,
        "--force/--no-force",
        "-f",
        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–∞–∂–µ –º–∞–ª–µ–Ω—å–∫–∏–π –±–∞—Ç—á.",
    ),
) -> None:
    """üöÄ –û—Ç–ø—Ä–∞–≤–∏—Ç—å pending —á–∞–Ω–∫–∏ –≤ Batch API.

    –°–æ–∑–¥–∞—ë—Ç batch job –¥–ª—è –≤—Å–µ—Ö pending text chunks.
    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —á–∞–Ω–∫–∏ (--force).
    """
    from semantic_core.cli.app import get_cli_context

    ctx = get_cli_context()

    try:
        core = ctx.get_core()
    except Exception as e:
        if ctx.json_output:
            console.print_json(json.dumps({"error": str(e)}))
        else:
            console.print(f"[red]‚ùå –û—à–∏–±–∫–∞:[/red] {e}")
        raise typer.Exit(1)

    if not ctx.json_output:
        console.print("[bold]üì¶ Flushing text embedding queue...[/bold]")

    logger.info("Flushing queue", min_size=min_size, force=force)

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ batch_manager
        if not hasattr(core, "batch_manager") or core.batch_manager is None:
            msg = "BatchManager –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á–∏."
            if ctx.json_output:
                console.print_json(json.dumps({"error": msg}))
            else:
                console.print(f"[yellow]‚ö†Ô∏è {msg}[/yellow]")
            raise typer.Exit(1)

        batch_id = core.batch_manager.flush_queue(min_size=min_size, force=force)

        if batch_id:
            text_stats = _get_text_stats()
            pending = text_stats.get("pending", 0) + text_stats.get("processing", 0)

            if ctx.json_output:
                console.print_json(
                    json.dumps(
                        {
                            "success": True,
                            "batch_id": batch_id,
                            "pending_after": pending,
                        }
                    )
                )
            else:
                console.print(f"[green]‚úÖ Created batch:[/green] {batch_id[:8]}...")
                if pending > 0:
                    console.print(f"   Remaining in queue: {pending}")
        else:
            if ctx.json_output:
                console.print_json(
                    json.dumps(
                        {
                            "success": True,
                            "batch_id": None,
                            "message": "No pending chunks to flush",
                        }
                    )
                )
            else:
                console.print("[dim]‚ÑπÔ∏è No pending chunks to flush[/dim]")

    except Exception as e:
        logger.error_with_context("Flush failed", e)
        if ctx.json_output:
            console.print_json(json.dumps({"error": str(e)}))
        else:
            console.print(f"[red]‚ùå –û—à–∏–±–∫–∞:[/red] {e}")
        raise typer.Exit(1)


@queue_cmd.command("retry")
def queue_retry(
    task_type: str = typer.Option(
        "all",
        "--type",
        "-t",
        help="–¢–∏–ø –∑–∞–¥–∞—á: text, media, all.",
    ),
) -> None:
    """üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å failed –∑–∞–¥–∞—á–∏.

    –°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å failed –∑–∞–¥–∞—á –Ω–∞ pending –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    """
    from semantic_core.cli.app import get_cli_context
    from semantic_core.infrastructure.storage.peewee.models import (
        ChunkModel,
        MediaTaskModel,
        EmbeddingStatus,
    )
    from semantic_core.domain.media import TaskStatus

    ctx = get_cli_context()

    try:
        core = ctx.get_core()
    except Exception as e:
        if ctx.json_output:
            console.print_json(json.dumps({"error": str(e)}))
        else:
            console.print(f"[red]‚ùå –û—à–∏–±–∫–∞:[/red] {e}")
        raise typer.Exit(1)

    if task_type not in ("all", "text", "media"):
        if ctx.json_output:
            console.print_json(
                json.dumps(
                    {"error": f"Invalid type: {task_type}. Use: all, text, media"}
                )
            )
        else:
            console.print(
                f"[red]‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø:[/red] {task_type}. "
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: all, text, media"
            )
        raise typer.Exit(1)

    if not ctx.json_output:
        console.print("[bold]üîÑ Retrying failed tasks...[/bold]")

    logger.info("Retrying failed tasks", task_type=task_type)

    text_retried = 0
    media_retried = 0

    try:
        # Retry text chunks
        if task_type in ("all", "text"):
            text_retried = (
                ChunkModel.update(
                    embedding_status=EmbeddingStatus.PENDING.value,
                    batch_job=None,
                    error_message=None,
                )
                .where(ChunkModel.embedding_status == EmbeddingStatus.FAILED.value)
                .execute()
            )

            logger.info("Text chunks retried", count=text_retried)

        # Retry media tasks
        if task_type in ("all", "media"):
            media_retried = (
                MediaTaskModel.update(
                    status=TaskStatus.PENDING.value,
                    error_message=None,
                )
                .where(MediaTaskModel.status == TaskStatus.FAILED.value)
                .execute()
            )

            logger.info("Media tasks retried", count=media_retried)

        if ctx.json_output:
            console.print_json(
                json.dumps(
                    {
                        "success": True,
                        "text_retried": text_retried,
                        "media_retried": media_retried,
                    }
                )
            )
        else:
            console.print(f"   Text chunks: {text_retried} ‚Üí PENDING")
            console.print(f"   Media tasks: {media_retried} ‚Üí PENDING")

            total = text_retried + media_retried
            if total > 0:
                console.print("[green]‚úÖ Ready for reprocessing[/green]")
            else:
                console.print("[dim]‚ÑπÔ∏è No failed tasks to retry[/dim]")

    except Exception as e:
        logger.error_with_context("Retry failed", e)
        if ctx.json_output:
            console.print_json(json.dumps({"error": str(e)}))
        else:
            console.print(f"[red]‚ùå –û—à–∏–±–∫–∞:[/red] {e}")
        raise typer.Exit(1)


__all__ = ["queue_cmd"]
