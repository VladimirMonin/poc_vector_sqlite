"""–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ–¥–∏–∞-–¥–∞–Ω–Ω—ã–º–∏.

–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç —Ä–∞–∑—Ä–æ–∑–Ω–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ (summary, transcript, OCR) –∏–∑ –ë–î
–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ DTO –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ UI –∏ RAG.

–ö–ª–∞—Å—Å—ã:
    MediaService
        –°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ–¥–∏–∞-–¥–∞–Ω–Ω—ã–º–∏.
"""

import json
from pathlib import Path
from typing import Optional, TYPE_CHECKING

from peewee import DoesNotExist

from semantic_core.domain import (
    Document,
    Chunk,
    ChunkType,
    MediaDetails,
    TimelineItem,
    MediaType,
)
from semantic_core.infrastructure.storage.peewee.models import (
    DocumentModel,
    ChunkModel,
)
from semantic_core.utils.logger import get_logger

if TYPE_CHECKING:
    from semantic_core.infrastructure.gemini.image_analyzer import GeminiImageAnalyzer
    from semantic_core.infrastructure.gemini.audio_analyzer import GeminiAudioAnalyzer
    from semantic_core.infrastructure.gemini.video_analyzer import GeminiVideoAnalyzer
    from semantic_core.interfaces import BaseSplitter, BaseVectorStore
    from semantic_core.config import SemanticConfig

logger = get_logger(__name__)


class MediaService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ–¥–∏–∞-–¥–∞–Ω–Ω—ã–º–∏.
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —á–∞–Ω–∫–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–æ–ª—è–º–∏ (summary, transcript, OCR)
    –≤ –µ–¥–∏–Ω–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ MediaDetails.
    
    –¢–∞–∫–∂–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ reprocess_document() –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤ —Å –Ω–æ–≤—ã–º–∏ custom_instructions (Phase 14.3.3).
    
    –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
        >>> service = MediaService(
        ...     image_analyzer=image_analyzer,
        ...     audio_analyzer=audio_analyzer,
        ...     video_analyzer=video_analyzer,
        ...     splitter=splitter,
        ...     store=store,
        ...     config=config,
        ... )
        >>> 
        >>> # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        >>> details = service.get_media_details("doc-123")
        >>> print(details.summary)
        >>> 
        >>> # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –Ω–æ–≤—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏
        >>> service.reprocess_document(
        ...     document_id="doc-123",
        ...     custom_instructions="Extract technical terms",
        ... )
    """
    
    def __init__(
        self,
        image_analyzer: Optional["GeminiImageAnalyzer"] = None,
        audio_analyzer: Optional["GeminiAudioAnalyzer"] = None,
        video_analyzer: Optional["GeminiVideoAnalyzer"] = None,
        splitter: Optional["BaseSplitter"] = None,
        store: Optional["BaseVectorStore"] = None,
        config: Optional["SemanticConfig"] = None,
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaService.
        
        Args:
            image_analyzer: –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–¥–ª—è reprocess_document).
            audio_analyzer: –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∞—É–¥–∏–æ (–¥–ª—è reprocess_document).
            video_analyzer: –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≤–∏–¥–µ–æ (–¥–ª—è reprocess_document).
            splitter: –°–ø–ª–∏—Ç—Ç–µ—Ä –¥–ª—è MediaPipeline (–¥–ª—è reprocess_document).
            store: –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤ (–¥–ª—è reprocess_document).
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è SemanticCore (–¥–ª—è MediaPipeline).
        
        Note:
            –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ get_media_details() / get_timeline() / get_chunks_by_role()
            –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤: MediaService().
            
            –î–ª—è reprocess_document() —Ç—Ä–µ–±—É—é—Ç—Å—è –≤—Å–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
        """
        self.image_analyzer = image_analyzer
        self.audio_analyzer = audio_analyzer
        self.video_analyzer = video_analyzer
        self.splitter = splitter
        self.store = store
        self.config = config
    
    def get_media_details(
        self,
        document_id: str,
        include_transcript: bool = True,
        include_ocr: bool = True,
    ) -> MediaDetails:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–µ.
        
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏ –≤—Å–µ –µ–≥–æ —á–∞–Ω–∫–∏, –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ —Ä–æ–ª—è–º,
        —Å–æ–±–∏—Ä–∞–µ—Ç timeline —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏.
        
        Args:
            document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å—Ç—Ä–æ–∫–∞).
            include_transcript: –í–∫–ª—é—á–∞—Ç—å –ª–∏ transcript —á–∞–Ω–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
            include_ocr: –í–∫–ª—é—á–∞—Ç—å –ª–∏ OCR —á–∞–Ω–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
        
        Returns:
            MediaDetails —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
        
        Raises:
            ValueError: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–º.
        
        Examples:
            >>> details = service.get_media_details("abc-123")
            >>> details = service.get_media_details(
            ...     "abc-123",
            ...     include_ocr=False  # –¢–æ–ª—å–∫–æ summary + transcript
            ... )
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –ë–î
        try:
            doc_model = DocumentModel.get_by_id(document_id)
        except DoesNotExist:
            raise ValueError(f"Document {document_id} not found")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –º–µ–¥–∏–∞-—Ñ–∞–π–ª
        if doc_model.media_type not in ("image", "audio", "video"):
            raise ValueError(
                f"Document {document_id} is not a media file "
                f"(media_type={doc_model.media_type})"
            )
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        chunks_query = (
            ChunkModel.select()
            .where(ChunkModel.document == doc_model.id)
            .order_by(ChunkModel.chunk_index)
        )
        
        # –†–∞–∑–¥–µ–ª—è–µ–º —á–∞–Ω–∫–∏ –ø–æ —Ä–æ–ª—è–º
        summary_chunk = None
        transcript_chunks = []
        ocr_chunks = []
        timeline_items = []
        
        for chunk_model in chunks_query:
            # –ü–∞—Ä—Å–∏–º metadata
            metadata = json.loads(chunk_model.metadata)
            role = metadata.get("role", "")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ORM –º–æ–¥–µ–ª—å –≤ domain Chunk
            chunk = self._chunk_model_to_domain(chunk_model)
            
            if role == "summary":
                summary_chunk = chunk
            elif role == "transcript" and include_transcript:
                transcript_chunks.append(chunk)
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ timeline –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–π–º–∫–æ–¥
                if "start_seconds" in metadata:
                    timeline_items.append(
                        TimelineItem(
                            chunk_id=str(chunk.id),
                            start_seconds=metadata["start_seconds"],
                            content_preview=chunk.content[:100],
                            role="transcript",
                            chunk_type=chunk.chunk_type.value,
                        )
                    )
            elif role == "ocr" and include_ocr:
                ocr_chunks.append(chunk)
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ timeline –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–π–º–∫–æ–¥
                if "start_seconds" in metadata:
                    timeline_items.append(
                        TimelineItem(
                            chunk_id=str(chunk.id),
                            start_seconds=metadata["start_seconds"],
                            content_preview=chunk.content[:100],
                            role="ocr",
                            chunk_type=chunk.chunk_type.value,
                        )
                    )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ summary chunk
        if summary_chunk is None:
            raise ValueError(
                f"Document {document_id} has no summary chunk (role='summary')"
            )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ summary metadata
        summary_metadata = summary_chunk.metadata
        keywords = summary_metadata.get("keywords", [])
        duration_seconds = summary_metadata.get("duration_seconds")
        participants = summary_metadata.get("participants")
        action_items = summary_metadata.get("action_items")
        
        # –°–∫–ª–µ–∏–≤–∞–µ–º transcript chunks –≤ –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç
        full_transcript = None
        if transcript_chunks:
            full_transcript = "\n\n".join(c.content for c in transcript_chunks)
        
        # –°–∫–ª–µ–∏–≤–∞–µ–º OCR chunks –≤ –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç
        full_ocr_text = None
        if ocr_chunks:
            full_ocr_text = "\n\n".join(c.content for c in ocr_chunks)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º timeline –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        timeline = sorted(timeline_items, key=lambda x: x.start_seconds) if timeline_items else None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º MediaDetails
        return MediaDetails(
            document_id=document_id,
            media_path=Path(doc_model.source),
            media_type=doc_model.media_type,
            summary=summary_chunk.content,
            keywords=keywords,
            full_transcript=full_transcript,
            transcript_chunks=transcript_chunks,
            full_ocr_text=full_ocr_text,
            ocr_chunks=ocr_chunks,
            timeline=timeline,
            duration_seconds=duration_seconds,
            participants=participants,
            action_items=action_items,
        )
    
    def get_timeline(
        self,
        document_id: str,
        role_filter: Optional[str] = None,
    ) -> list[TimelineItem]:
        """–ü–æ–ª—É—á–∞–µ—Ç timeline –¥–ª—è –º–µ–¥–∏–∞-–ø–ª–µ–µ—Ä–∞.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —á–∞–Ω–∫–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏.
        
        Args:
            document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞.
            role_filter: –§–∏–ª—å—Ç—Ä –ø–æ —Ä–æ–ª–∏ ("transcript" | "ocr" | None –¥–ª—è –≤—Å–µ—Ö).
        
        Returns:
            –°–ø–∏—Å–æ–∫ TimelineItem, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ start_seconds.
        
        Raises:
            ValueError: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.
        
        Examples:
            >>> # –í—Å–µ —á–∞–Ω–∫–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
            >>> timeline = service.get_timeline("doc-123")
            >>> # –¢–æ–ª—å–∫–æ transcript
            >>> timeline = service.get_timeline("doc-123", role_filter="transcript")
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç (–ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ)
        try:
            DocumentModel.get_by_id(document_id)
        except DoesNotExist:
            raise ValueError(f"Document {document_id} not found")
        
        # –ü–æ–ª—É—á–∞–µ–º —á–∞–Ω–∫–∏
        chunks_query = (
            ChunkModel.select()
            .where(ChunkModel.document == document_id)
            .order_by(ChunkModel.chunk_index)
        )
        
        timeline_items = []
        
        for chunk_model in chunks_query:
            metadata = json.loads(chunk_model.metadata)
            role = metadata.get("role", "")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ role –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if role_filter and role != role_filter:
                continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —á–∞–Ω–∫–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
            if "start_seconds" in metadata:
                timeline_items.append(
                    TimelineItem(
                        chunk_id=str(chunk_model.id),
                        start_seconds=metadata["start_seconds"],
                        content_preview=chunk_model.content[:100],
                        role=role,
                        chunk_type=chunk_model.chunk_type,
                    )
                )
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        return sorted(timeline_items, key=lambda x: x.start_seconds)
    
    def get_chunks_by_role(
        self,
        document_id: str,
        role: str,
    ) -> list[Chunk]:
        """–ü–æ–ª—É—á–∞–µ—Ç —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π —Ä–æ–ª—å—é.
        
        Args:
            document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞.
            role: –†–æ–ª—å —á–∞–Ω–∫–æ–≤ ("summary" | "transcript" | "ocr").
        
        Returns:
            –°–ø–∏—Å–æ–∫ Chunk —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ä–æ–ª—å—é, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ chunk_index.
        
        Raises:
            ValueError: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.
        
        Examples:
            >>> # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ transcript —á–∞–Ω–∫–∏
            >>> chunks = service.get_chunks_by_role("doc-123", "transcript")
            >>> # –ü–æ–ª—É—á–∏—Ç—å summary
            >>> summary = service.get_chunks_by_role("doc-123", "summary")[0]
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç (–ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ)
        try:
            DocumentModel.get_by_id(document_id)
        except DoesNotExist:
            raise ValueError(f"Document {document_id} not found")
        
        # –ü–æ–ª—É—á–∞–µ–º —á–∞–Ω–∫–∏
        chunks_query = (
            ChunkModel.select()
            .where(ChunkModel.document == document_id)
            .order_by(ChunkModel.chunk_index)
        )
        
        result_chunks = []
        
        for chunk_model in chunks_query:
            metadata = json.loads(chunk_model.metadata)
            if metadata.get("role") == role:
                chunk = self._chunk_model_to_domain(chunk_model)
                result_chunks.append(chunk)
        
        return result_chunks
    
    def _chunk_model_to_domain(self, chunk_model: ChunkModel) -> Chunk:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç ORM –º–æ–¥–µ–ª—å ChunkModel –≤ domain Chunk.
        
        Args:
            chunk_model: ORM –º–æ–¥–µ–ª—å —á–∞–Ω–∫–∞.
        
        Returns:
            Domain –æ–±—ä–µ–∫—Ç Chunk.
        """
        metadata = json.loads(chunk_model.metadata)
        
        return Chunk(
            content=chunk_model.content,
            chunk_index=chunk_model.chunk_index,
            chunk_type=ChunkType(chunk_model.chunk_type),
            language=chunk_model.language,
            embedding=None,  # –ù–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏)
            parent_doc_id=chunk_model.document.id,
            metadata=metadata,
            id=chunk_model.id,
            created_at=chunk_model.created_at,
        )
    
    def reprocess_document(
        self,
        document_id: str,
        custom_instructions: Optional[str] = None,
    ) -> Document:
        """–ü–æ–≤—Ç–æ—Ä–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏–∞-—Ñ–∞–π–ª —Å –Ω–æ–≤—ã–º–∏ custom_instructions.
        
        Phase 14.3.3: SRP-compliant –º–µ—Ç–æ–¥ –¥–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞.
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç Document –∏–∑ –ë–î (–ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏ media_type)
        2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç media_path –∏–∑ Document.metadata["source"]
        3. –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –º–µ–¥–∏–∞-—á–∞–Ω–∫–∏ (—Ä–æ–ª–∏: summary, transcript, ocr)
        4. –ü–æ–≤—Ç–æ—Ä–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —á–µ—Ä–µ–∑ Gemini —Å custom_instructions
        5. –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ —á–µ—Ä–µ–∑ MediaPipeline
        6. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —á–∞–Ω–∫–∏ –≤ –ë–î —á–µ—Ä–µ–∑ store.save()
        
        Args:
            document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏.
            custom_instructions: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è Gemini.
                –ü—Ä–∏–º–µ—Ä—ã:
                - "Focus on technical terms and code snippets"
                - "Extract medical terminology"
                - "Identify speaker names and timestamps"
        
        Returns:
            –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π Document —Å –Ω–æ–≤—ã–º–∏ —á–∞–Ω–∫–∞–º–∏.
        
        Raises:
            ValueError: –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–µ –º–µ–¥–∏–∞-—Ñ–∞–π–ª, –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
            FileNotFoundError: –ï—Å–ª–∏ –º–µ–¥–∏–∞-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ –∏–∑ metadata["source"].
        
        Examples:
            >>> # –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å –Ω–æ–≤—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏
            >>> service.reprocess_document(
            ...     document_id="doc-123",
            ...     custom_instructions="Extract medical terms",
            ... )
            >>> 
            >>> # –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
            >>> service.reprocess_document("doc-123")
        
        Note:
            –¢—Ä–µ–±—É–µ—Ç –Ω–∞–ª–∏—á–∏—è analyzers, splitter, store –∏ config –≤ __init__.
            –£–¥–∞–ª—è–µ—Ç –í–°–ï —Å—Ç–∞—Ä—ã–µ –º–µ–¥–∏–∞-—á–∞–Ω–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö.
        """
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        if not all([self.splitter, self.store, self.config]):
            raise ValueError(
                "MediaService.reprocess_document() requires splitter, store, and config. "
                "Initialize MediaService with these dependencies."
            )
        
        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –ë–î
        try:
            doc_model = DocumentModel.get_by_id(document_id)
        except DoesNotExist:
            raise ValueError(f"Document {document_id} not found")
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º media_type
        media_type_str = doc_model.media_type
        if media_type_str not in ("image", "audio", "video"):
            raise ValueError(
                f"Document {document_id} is not a media file "
                f"(media_type={media_type_str})"
            )
        
        media_type = MediaType(media_type_str)  # ‚Üê –ë–ï–ó .upper(), —Ç.–∫. "audio"/"video"/"image"
        
        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º media_path –∏–∑ metadata
        doc_metadata = json.loads(doc_model.metadata)
        media_path_str = doc_metadata.get("source")
        
        if not media_path_str:
            raise ValueError(
                f"Document {document_id} has no 'source' in metadata. "
                "Cannot determine media file path."
            )
        
        media_path = Path(media_path_str)
        
        if not media_path.exists():
            raise FileNotFoundError(
                f"Media file not found: {media_path}. "
                f"Document {document_id} references missing file."
            )
        
        logger.info(
            f"üîÑ Reprocessing document {document_id}",
            media_path=str(media_path),
            media_type=media_type_str,
            has_custom_instructions=bool(custom_instructions),
        )
        
        # 5. –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –º–µ–¥–∏–∞-—á–∞–Ω–∫–∏
        deleted_count = self._delete_media_chunks(document_id)
        logger.debug(
            f"Deleted {deleted_count} old media chunks",
            document_id=document_id,
        )
        
        # 6. –í—ã–±–∏—Ä–∞–µ–º analyzer –ø–æ media_type
        analyzer = self._get_analyzer_for_media_type(media_type)
        
        if analyzer is None:
            raise ValueError(
                f"No analyzer available for media_type={media_type_str}. "
                "Initialize MediaService with image_analyzer/audio_analyzer/video_analyzer."
            )
        
        # 7. –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini
        analysis = analyzer.analyze(
            media_path=media_path,
            custom_instructions=custom_instructions,
        )
        
        logger.debug(
            "Media analysis completed",
            document_id=document_id,
            analysis_keys=list(analysis.keys()),
        )
        
        # 8. –°–æ–∑–¥–∞—ë–º Document –¥–ª—è MediaPipeline
        document = Document(
            content=str(media_path),
            metadata=doc_metadata,
            media_type=media_type,
            id=document_id,
        )
        
        # 9. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ —á–µ—Ä–µ–∑ MediaPipeline
        new_chunks = self._build_chunks_via_pipeline(
            document=document,
            media_path=media_path,
            analysis=analysis,
            media_type=media_type,
        )
        
        logger.info(
            f"Created {len(new_chunks)} new chunks",
            document_id=document_id,
            chunk_roles=[c.metadata.get("role") for c in new_chunks],
        )
        
        # 10. –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫–∏ –≤ document
        document.chunks = new_chunks
        
        # 11. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î (–±–µ–∑ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ‚Äî –≤–µ–∫—Ç–æ—Ä—ã –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã batch-–ø—Ä–æ—Ü–µ—Å—Å–æ–º)
        # store.save() –æ–±–Ω–æ–≤–∏—Ç —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        self.store.save(document)
        
        logger.info(
            f"‚úÖ Document {document_id} reprocessed successfully",
            chunk_count=len(new_chunks),
        )
        
        return document
    
    def _delete_media_chunks(self, document_id: str) -> int:
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ –º–µ–¥–∏–∞-—á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ä–æ–ª–∏: summary, transcript, ocr).
        
        Args:
            document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞.
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.
        """
        chunks_query = ChunkModel.select().where(
            ChunkModel.document == document_id
        )
        
        deleted_count = 0
        for chunk_model in chunks_query:
            metadata = json.loads(chunk_model.metadata)
            role = metadata.get("role", "")
            
            if role in ("summary", "transcript", "ocr"):
                chunk_model.delete_instance()
                deleted_count += 1
        
        return deleted_count
    
    def _get_analyzer_for_media_type(
        self, media_type: MediaType
    ) -> Optional["GeminiImageAnalyzer | GeminiAudioAnalyzer | GeminiVideoAnalyzer"]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç analyzer –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ media_type.
        
        Args:
            media_type: –¢–∏–ø –º–µ–¥–∏–∞ (IMAGE/AUDIO/VIDEO).
        
        Returns:
            –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π analyzer –∏–ª–∏ None.
        """
        if media_type == MediaType.IMAGE:
            return self.image_analyzer
        elif media_type == MediaType.AUDIO:
            return self.audio_analyzer
        elif media_type == MediaType.VIDEO:
            return self.video_analyzer
        else:
            return None
    
    def _build_chunks_via_pipeline(
        self,
        document: Document,
        media_path: Path,
        analysis: dict,
        media_type: MediaType,
    ) -> list[Chunk]:
        """–°–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫–∏ —á–µ—Ä–µ–∑ MediaPipeline.
        
        Args:
            document: Document –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
            media_path: –ü—É—Ç—å –∫ –º–µ–¥–∏–∞-—Ñ–∞–π–ª—É.
            analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç Gemini.
            media_type: –¢–∏–ø –º–µ–¥–∏–∞ (IMAGE/AUDIO/VIDEO).
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö Chunk.
        """
        from semantic_core.core.media_context import MediaContext
        from semantic_core.core.media_pipeline import MediaPipeline
        from semantic_core.processing.steps import SummaryStep, TranscriptionStep, OCRStep
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º chunk_type –ø–æ media_type
        chunk_type_map = {
            MediaType.IMAGE: ChunkType.IMAGE_REF,
            MediaType.AUDIO: ChunkType.AUDIO_REF,
            MediaType.VIDEO: ChunkType.VIDEO_REF,
        }
        chunk_type = chunk_type_map[media_type]
        
        # –°–æ–∑–¥–∞—ë–º MediaContext
        context = MediaContext(
            media_path=media_path,
            document=document,
            analysis=analysis,
            chunks=[],
            base_index=0,
            services={
                "chunk_type": chunk_type,
                "fallback_metadata": {},
            },
        )
        
        # –°–æ–∑–¥–∞—ë–º pipeline —Å–æ –≤—Å–µ–º–∏ —à–∞–≥–∞–º–∏
        pipeline = MediaPipeline(
            steps=[
                SummaryStep(),
                TranscriptionStep(
                    splitter=self.splitter,
                    default_chunk_size=self.config.media.chunk_sizes.transcript_chunk_size,
                    enable_timecodes=self.config.media.processing.enable_timecodes,
                ),
                OCRStep(
                    splitter=self.splitter,
                    default_chunk_size=self.config.media.chunk_sizes.ocr_text_chunk_size,
                    parser_mode=self.config.media.processing.ocr_parser_mode,
                ),
            ]
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º pipeline
        final_context = pipeline.build_chunks(context)
        
        return final_context.chunks
