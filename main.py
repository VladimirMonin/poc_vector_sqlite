"""
Playground –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Parent-Child –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞.

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ë–î —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —á–∞–Ω–∫–æ–≤
2. –ó–∞–≥—Ä—É–∑–∫—É —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ doc/architecture/
3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –Ω–∞—Ä–µ–∑–∫—É –Ω–∞ —á–∞–Ω–∫–∏ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º
4. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —á–∞–Ω–∫–∞–º —Å –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π –ø–æ —Ä–æ–¥–∏—Ç–µ–ª—è–º
5. –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–ª–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
6. –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ —Å RRF
"""

from pathlib import Path

from semantic_core import (
    init_database,
    EmbeddingGenerator,
    SimpleTextSplitter,
    save_note_with_chunks,
    vector_search_chunks,
    fulltext_search_parents,
    hybrid_search_rrf,
)
from semantic_core.database import create_vector_table, create_fts_table
from domain.models import Note, NoteChunk, Category, Tag, NoteTag


def initialize_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ë–î –∏ —Å–æ–∑–¥–∞–µ—Ç –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è Parent-Child –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã."""
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")

    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
    db = init_database()
    db.connect()

    # –°–æ–∑–¥–∞–µ–º –æ–±—ã—á–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
    db.create_tables([Category, Tag, Note, NoteChunk, NoteTag], safe=True)

    # –°–æ–∑–¥–∞–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
    # –í–µ–∫—Ç–æ—Ä—ã —Ç–µ–ø–µ—Ä—å —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ NoteChunk, –∞ –Ω–µ –≤ Note!
    create_vector_table(NoteChunk, vector_column="embedding")
    # FTS –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–∞ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π —Ç–∞–±–ª–∏—Ü–µ Note
    create_fts_table(Note, text_columns=["title", "content"])

    print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≥–æ—Ç–æ–≤–∞!")
    print("   ‚Üí Note (parent) - –¥–ª—è –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print("   ‚Üí NoteChunk (child) - –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞\n")
    return db


def seed_data():
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç –ë–î —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏–∑ doc/architecture/."""
    print("üå± –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ doc/architecture/...")

    # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    cat_docs = Category.create(name="–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    generator = EmbeddingGenerator()
    splitter = SimpleTextSplitter(
        chunk_size=1000,  # ~250 —Ç–æ–∫–µ–Ω–æ–≤
        overlap=200,      # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        threshold=100     # –û–∫–Ω–æ –ø–æ–∏—Å–∫–∞ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏
    )

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ markdown —Ñ–∞–π–ª—ã
    docs_dir = Path("doc/architecture")
    md_files = sorted(docs_dir.glob("*.md"))

    total_chunks = 0

    for md_file in md_files:
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        content = md_file.read_text(encoding="utf-8")
        title = md_file.stem.replace("_", " ").title()

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏
        note_data = {
            "title": title,
            "content": content,
            "category": cat_docs,
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞—Ä–µ–∑–∫–æ–π
        note = save_note_with_chunks(
            note_model=Note,
            chunk_model=NoteChunk,
            note_data=note_data,
            splitter=splitter,
            generator=generator,
        )

        chunks_count = note.chunks.count()
        total_chunks += chunks_count
        
        print(f"  ‚úì {note.title[:40]:40} | {len(content):>6} —Å–∏–º–≤–æ–ª–æ–≤ | {chunks_count:>2} —á–∞–Ω–∫–æ–≤")

    print(f"\n‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(md_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Å–æ–∑–¥–∞–Ω–æ {total_chunks} —á–∞–Ω–∫–æ–≤")
    print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞: {sum(len(f.read_text()) for f in md_files) / len(md_files):.0f} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {total_chunks / len(md_files):.1f}\n")


def test_vector_search():
    """–¢–µ—Å—Ç 1: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —á–∞–Ω–∫–∞–º —Å –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π."""
    print("üîç –¢–µ—Å—Ç 1: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ (–ø–æ —á–∞–Ω–∫–∞–º)")
    print("–ó–∞–ø—Ä–æ—Å: '–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫?'\n")

    results = vector_search_chunks(
        parent_model=Note,
        chunk_model=NoteChunk,
        query="–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫?",
        limit=3
    )

    print(f"–ù–∞–π–¥–µ–Ω–æ: {len(results)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    for i, (note, distance) in enumerate(results, 1):
        chunks_count = note.chunks.count()
        print(f"  {i}. {note.title[:50]:50} | {chunks_count:>2} —á–∞–Ω–∫–æ–≤ | distance: {distance:.4f}")
    print()


def test_fulltext_search():
    """–¢–µ—Å—Ç 2: –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ä–æ–¥–∏—Ç–µ–ª—è–º."""
    print("üîé –¢–µ—Å—Ç 2: –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ (–ø–æ –ø–æ–ª–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º)")
    print("–ó–∞–ø—Ä–æ—Å: 'Gemini API'\n")

    results = fulltext_search_parents(
        parent_model=Note,
        query="Gemini API",
        limit=3
    )

    print(f"–ù–∞–π–¥–µ–Ω–æ: {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    for i, (note, rank) in enumerate(results, 1):
        print(f"  {i}. {note.title[:50]:50} | BM25: {rank:.4f}")
    print()


def test_chunk_details():
    """–¢–µ—Å—Ç 3: –ü—Ä–æ—Å–º–æ—Ç—Ä —á–∞–Ω–∫–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    print("üìÑ –¢–µ—Å—Ç 3: –î–µ—Ç–∞–ª–∏ –Ω–∞—Ä–µ–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
    note = Note.select().first()
    
    if not note:
        print("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n")
        return
    
    print(f"–î–æ–∫—É–º–µ–Ω—Ç: {note.title}")
    print(f"–†–∞–∑–º–µ—Ä: {len(note.content)} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"–ß–∞–Ω–∫–æ–≤: {note.chunks.count()}\n")
    
    if note.chunks.count() > 0:
        print("–ü–µ—Ä–≤—ã–µ 3 —á–∞–Ω–∫–∞:")
        for chunk in note.chunks.order_by(NoteChunk.chunk_index).limit(3):
            preview = chunk.content[:80].replace("\n", " ")
            print(f"  [{chunk.chunk_index}] {preview}...")
    else:
        print("–ß–∞–Ω–∫–æ–≤ –Ω–µ—Ç (–¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã)")
    print()


def test_hybrid_search():
    """–¢–µ—Å—Ç 4: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ —Å RRF."""
    print("‚ö° –¢–µ—Å—Ç 4: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (RRF: –≤–µ–∫—Ç–æ—Ä—ã + FTS)")
    print("–ó–∞–ø—Ä–æ—Å: '—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–æ–¥–µ–ª—å'\n")

    results = hybrid_search_rrf(
        parent_model=Note,
        chunk_model=NoteChunk,
        query="—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–æ–¥–µ–ª—å",
        limit=5
    )

    print(f"–ù–∞–π–¥–µ–Ω–æ: {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–æ –ø–æ RRF)")
    for i, (note, rrf_score) in enumerate(results, 1):
        chunks_count = note.chunks.count()
        print(f"  {i}. {note.title[:45]:45} | {chunks_count:>2} —á–∞–Ω–∫–æ–≤ | RRF: {rrf_score:.4f}")
    print()


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Parent-Child –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã."""
    print("=" * 70)
    print("üöÄ POC: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å Parent-Child –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π")
    print("   SQLite + Vec + Gemini + Chunking")
    print("=" * 70)
    print()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    db = initialize_database()

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    if Note.select().count() == 0 or NoteChunk.select().count() == 0:
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        if Note.select().count() > 0:
            print("‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ —á–∞–Ω–∫–æ–≤, –æ—á–∏—â–∞–µ–º...\n")
            NoteTag.delete().execute()
            NoteChunk.delete().execute()
            Note.delete().execute()
            Tag.delete().execute()
            Category.delete().execute()
        
        seed_data()
    else:
        notes_count = Note.select().count()
        chunks_count = NoteChunk.select().count()
        print(f"‚ÑπÔ∏è  –ë–∞–∑–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç {notes_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ {chunks_count} —á–∞–Ω–∫–æ–≤\n")

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    test_vector_search()
    test_fulltext_search()
    test_chunk_details()
    test_hybrid_search()

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("=" * 70)
    print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    total_notes = Note.select().count()
    total_chunks = NoteChunk.select().count()
    avg_chunks = total_chunks / total_notes if total_notes > 0 else 0
    
    print(f"   –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_notes}")
    print(f"   –ß–∞–Ω–∫–æ–≤: {total_chunks}")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ —á–∞–Ω–∫–æ–≤/–¥–æ–∫—É–º–µ–Ω—Ç: {avg_chunks:.1f}")
    print("=" * 70)
    print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!")
    print("=" * 70)

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
    db.close()


if __name__ == "__main__":
    main()
